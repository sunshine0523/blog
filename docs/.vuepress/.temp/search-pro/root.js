export default "{\"documentCount\":96,\"nextId\":96,\"documentIds\":{\"0\":\"v-586d9498\",\"1\":\"v-586d9498#_1-介绍\",\"2\":\"v-586d9498#_2-预训练方法\",\"3\":\"v-586d9498#_2-1-训练数据\",\"4\":\"v-586d9498#_2-2-训练详情\",\"5\":\"v-586d9498#a-2-1-额外的预训练信息之与llama-1的变化内容介绍-p-46\",\"6\":\"v-586d9498#预训练超参设置\",\"7\":\"v-586d9498#预训练tokenizer\",\"8\":\"v-586d9498#_2-3-评测\",\"9\":\"v-586d9498#_3-fine-tuning\",\"10\":\"v-586d9498#_3-1-supervised-fine-tuning-sft\",\"11\":\"v-586d9498#_3-2-rlhf\",\"12\":\"v-586d9498#_3-2-1-人类偏好数据收集\",\"13\":\"v-586d9498#_3-2-2-奖励建模\",\"14\":\"v-586d9498#_3-2-3-迭代微调\",\"15\":\"v-586d9498#_3-3-多轮一致性的指令\",\"16\":\"v-586d9498#_3-4-rlhf结果\",\"17\":\"v-586d9498#_3-4-1-基于模型的评估\",\"18\":\"v-586d9498#_3-4-2-人类评价\",\"19\":\"v-369323c1\",\"20\":\"v-369323c1#_2-1-tensorflow-extended\",\"21\":\"v-369323c1#_2-2-airflow\",\"22\":\"v-369323c1#_2-3-kubeflow-全面工具集、偏训练-⭐\",\"23\":\"v-369323c1#_2-4-mlflow-监控、模型再部署、性能监控-⭐\",\"24\":\"v-369323c1#_2-5-azure-devops-pipelines\",\"25\":\"v-369323c1#_2-6-azure-ml\",\"26\":\"v-369323c1#_3-1-comet-ml\",\"27\":\"v-369323c1#_3-2-weights-biases-wandb-监控-⭐\",\"28\":\"v-369323c1#_3-3-prefect-工作流管理-⭐\",\"29\":\"v-369323c1#_3-4-metaflow\",\"30\":\"v-369323c1#_3-5-pachyderm\",\"31\":\"v-369323c1#_3-6-data-version-control-dvc-版本控制-⭐\",\"32\":\"v-369323c1#_3-7-bentoml-模型部署与管理-⭐\",\"33\":\"v-369323c1#_3-8-cortex-模型部署与管理-⭐\",\"34\":\"v-369323c1#_3-9-evidently-监控-⭐\",\"35\":\"v-369323c1#_3-10-censius-ai\",\"36\":\"v-369323c1#_4-1-hydrosphere-性能监控\",\"37\":\"v-369323c1#_5-1-autokeras-自动化机器学习\",\"38\":\"v-31927cf5\",\"39\":\"v-31927cf5#一、主要研究点\",\"40\":\"v-31927cf5#二、transformer\",\"41\":\"v-31927cf5#_2-1-序列转换模型\",\"42\":\"v-31927cf5#_2-2-注意力机制\",\"43\":\"v-31927cf5#_2-3-transformer模型\",\"44\":\"v-31927cf5#三、bert\",\"45\":\"v-31927cf5#_3-1-bert与transformer\",\"46\":\"v-31927cf5#_3-2-input-embedding\",\"47\":\"v-31927cf5#_3-3-预训练bert\",\"48\":\"v-31927cf5#四、t5和gpt\",\"49\":\"v-31927cf5#_4-1-t5模型\",\"50\":\"v-31927cf5#_4-2-gpt模型\",\"51\":\"v-31927cf5#五、glm\",\"52\":\"v-31927cf5#_5-1-自回归填空\",\"53\":\"v-31927cf5#_5-2-二维位置编码\",\"54\":\"v-31927cf5#_5-3-glm与transformer\",\"55\":\"v-31927cf5#六、p-tuning-v2\",\"56\":\"v-31927cf5#_6-1-提示微调\",\"57\":\"v-31927cf5#_6-2-p-tuning-v2\",\"58\":\"v-31927cf5#参考文献\",\"59\":\"v-ee3a5d5c\",\"60\":\"v-ee3a5d5c#参考资料\",\"61\":\"v-29d238c2\",\"62\":\"v-29d238c2#_1-介绍\",\"63\":\"v-29d238c2#_2-retentive-networks\",\"64\":\"v-29d238c2#_2-1-retention\",\"65\":\"v-29d238c2#_2-2-gated-multi-scale-retention\",\"66\":\"v-29d238c2#_2-3-❇️retention网络的整体架构\",\"67\":\"v-29d238c2#_3-实验\",\"68\":\"v-7f6d871a\",\"69\":\"v-7f6d871a#一、封装\",\"70\":\"v-7f6d871a#使用封装的优点\",\"71\":\"v-7f6d871a#二、继承\",\"72\":\"v-7f6d871a#谨慎继承\",\"73\":\"v-7f6d871a#三、多态\",\"74\":\"v-7f6d871a#多态的实现条件\",\"75\":\"v-7f6d871a#实现多态的方法\",\"76\":\"v-7f6d871a#实例分析\",\"77\":\"v-5473213a\",\"78\":\"v-5473213a#解决过程\",\"79\":\"v-4f486762\",\"80\":\"v-89132eea\",\"81\":\"v-19bcdf96\",\"82\":\"v-19bcdf96#解答\",\"83\":\"v-7f42d4f6\",\"84\":\"v-7bd923b8\",\"85\":\"v-18f2355e\",\"86\":\"v-012daa49\",\"87\":\"v-012daa49#题目描述\",\"88\":\"v-012daa49#解答\",\"89\":\"v-012daa49#关于system-arraycopy-的介绍\",\"90\":\"v-7449895b\",\"91\":\"v-8daa1a0e\",\"92\":\"v-14c69af4\",\"93\":\"v-c1f0fcce\",\"94\":\"v-764ee4e0\",\"95\":\"v-31987621\"},\"fieldIds\":{\"h\":0,\"t\":1,\"c\":2},\"fieldLength\":{\"0\":[3,5],\"1\":[2,35],\"2\":[2,25],\"3\":[3,5],\"4\":[2,18],\"5\":[7,46],\"6\":[1,15],\"7\":[1,13],\"8\":[3,2],\"9\":[3,11],\"10\":[7,43],\"11\":[3],\"12\":[4,20],\"13\":[3,145],\"14\":[3,167],\"15\":[2,99],\"16\":[3],\"17\":[4,28],\"18\":[4,44],\"19\":[1,20],\"20\":[4,29],\"21\":[2,14],\"22\":[6,47],\"23\":[7,35],\"24\":[5,19],\"25\":[4,16],\"26\":[4,16],\"27\":[7,21],\"28\":[4,28],\"29\":[3,9],\"30\":[3,34],\"31\":[8,28],\"32\":[5,28],\"33\":[5,24],\"34\":[5,30],\"35\":[4,18],\"36\":[5,55],\"37\":[5,14],\"38\":[3,33],\"39\":[2,85],\"40\":[2],\"41\":[3,38],\"42\":[2,41],\"43\":[3,169],\"44\":[2,39],\"45\":[3,54],\"46\":[4,27],\"47\":[2,76],\"48\":[2,5],\"49\":[3,35],\"50\":[3,54],\"51\":[2,43],\"52\":[3,104],\"53\":[3,30],\"54\":[3,28],\"55\":[4,49],\"56\":[3,27],\"57\":[5,90],\"58\":[1,303],\"59\":[1],\"60\":[1,13],\"61\":[2,31],\"62\":[2,68],\"63\":[3,45],\"64\":[3,135],\"65\":[5,60],\"66\":[3,47],\"67\":[2],\"68\":[3,1],\"69\":[2,11],\"70\":[1,5],\"71\":[2,40],\"72\":[1,7],\"73\":[2,35],\"74\":[1,10],\"75\":[1,8],\"76\":[1,48],\"77\":[3,10],\"78\":[1,42],\"79\":[1,4],\"80\":[5,275],\"81\":[2,34],\"82\":[1,14],\"83\":[2,72],\"84\":[2,70],\"85\":[3,65],\"86\":[6,2],\"87\":[1,65],\"88\":[1,16],\"89\":[3,79],\"90\":[1],\"91\":[1],\"92\":[1],\"93\":[1],\"94\":[3],\"95\":[1]},\"averageFieldLength\":[2.916666666666668,44.830921630931115],\"storedFields\":{\"0\":{\"h\":\"LLaMA 2 论文笔记\",\"t\":[\"该论文篇幅巨大，非常详细地介绍了LLaMA 2的预训练和微调过程，本篇笔记对其内容进行简要记录。论文链接\"]},\"1\":{\"h\":\"1 介绍\",\"t\":[\"LLaMA 2共包括两大版本：预训练模型LLaMA 2和基于它的微调模型LLaMA 2-Chat。共有7B 13B 34B 70B四种参数规模。\",\"LLaMA 2，是LLaMA 1的升级版本，在多个公开可获得数据上进行训练。相比LLaMA 1，LLaMA 2预训练的语料库增加了40%，上下文长度（即可接受的输入长度）增加一倍（最多支持4K token)，并且采用了分组查询注意力（grouped-query，后续有介绍）机制。\",\"LLaMA 2-Chat是基于LLaMA 2预训练模型微调得来的，后续有详细介绍。\",\"在第2节，本文介绍LLaMA 2的预训练方法；在第3节，本文介绍LLaMA 2-Chat的微调方法；\"]},\"2\":{\"h\":\"2 预训练方法\",\"t\":[\"LLaMA 2的预训练特性如下：\",\"LLaMA 2基本还是采用LLaMA 1的训练方法：LLaMA 1论文链接\",\"优化的自回归Transformer（归一化、激活函数等有变化，下面有介绍）\",\"具体而言，LLaMA 2执行了更稳健的数据清理，更新了数据混合，对总token进行了40%以上的训练，将上下文长度增加了一倍，并使用分组查询注意力（GQA）来提高LLaMA 2的推理可扩展性\",\"（2T = 2 trillion = 2万亿）\"]},\"3\":{\"h\":\"2.1 训练数据\",\"t\":[\"LLaMA 2的训练数据来自混合后的公开数据，共在2T token上进行训练。\"]},\"4\":{\"h\":\"2.2 训练详情\",\"t\":[\"预训练的设置和模型架构和LLaMA 1基本一致：\",\"Transformer架构\",\"归一化 RMSNorm\",\"激活函数 SwiGLU\",\"旋转位置Embedding RoPE rotary positional embeddings，这个现在都在用，包括GLM\",\"与LLaMA 1差异：增加了上下文长度、增加了GQA\"]},\"5\":{\"h\":\"A.2.1 额外的预训练信息之与LLaMA 1的变化内容介绍 p.46\",\"t\":[\"上下文长度 更长的上下文长度可以让模型处理更多信息，这可以让模型支持记住更多对话历史信息、更多的总结任务、理解更长的文本\",\"Grouped-Query Attention 自回归解码的标准做法是缓存序列中先前token的key（K）和value（V）对，从而加快注意力计算。然而，随着context window或batch size的增加，与多头注意力（MHA）模型中的KV缓存大小相关的内存成本显著增长。对于KV缓存大小成为瓶颈的大型模型，可以在多个头之间共享key和value预测，而不会导致性能大幅下降。可以使用具有单个KV投影的原始多查询格式(MQA)或具有8KV投影的分组查询注意力(GQA)变体。基于消融结果和易于缩放推断，对于34B和70B Llama 2模型，LLaMA 2选择使用GQA而不是MQA。\",\"额外发现：一个多卡并行训练的论文：Training multi-billion parameter language models using model parallelism\"]},\"6\":{\"h\":\"预训练超参设置\",\"t\":[\"AdamW优化器 β1=0.9，β2=0.95，eps=10e-5\",\"余弦学习率，warmup 2000 steps\",\"将最终学习率降低到峰值学习率的10%\",\"使用0.1的权重衰减和1.0的梯度剪裁\"]},\"7\":{\"h\":\"预训练Tokenizer\",\"t\":[\"使用与LLaMA 1相同的标记器；它采用了字节对编码（BPE）算法，使用了来自SentencePiece的实现。与LLaMA 1一样，将所有数字拆分为单个数字，并使用字节分解未知的UTF-8字符。总词汇大小为32k个标记。\"]},\"8\":{\"h\":\"2.3 评测\",\"t\":[\"评测结果如下：\"]},\"9\":{\"h\":\"3. Fine-tuning\",\"t\":[\"LLaMA 2-Chat基于LLaMA 2微调而来，包括指令微调和RLHF\",\"本节报告了使用监督微调以及初始和迭代奖励建模和RLHF进行的实验和发现。\",\"提出一种新技术，Ghost Attention (GAtt)，用于帮助控制多轮对话流\"]},\"10\":{\"h\":\"3.1 Supervised Fine-Tuning (SFT)\",\"t\":[\"开始：用公开可获得的指令微调数据，和LLaMA 1一致，使用了 Scaling Instruction-Finetuned Language Models\",\"公开的指令微调数据质量参差不齐，首先就是要收集大量的高质量SFT数据，如下图：\",\"高质量指令微调数据，即使是少量的，也可以让结果很好。万级别的好的数据足够了，Meta总共收集了27540个好数据。\",\"对于监督微调，使用了余弦学习率，LR=2e-5，权重衰减=0.1，batch size = 64，sequence lenght = 4096\",\"对于微调过程，每个样本都包含一个提示和一个答案。为了确保模型序列长度正确填充，作者将训练集中的所有提示和答案连接起来。使用一个特殊的令牌来分隔提示段和应答段。作者使用自回归目标，并从用户提示中消除令牌的损失，因此，作者只对回答令牌进行反向传播。最后，作者对模型进行了2个epochs的微调。\"]},\"11\":{\"h\":\"3.2 RLHF\"},\"12\":{\"h\":\"3.2.1 人类偏好数据收集\",\"t\":[\"与其他方案相比，作者选择了二进制比较协议，主要是因为它使作者能够最大限度地提高收集到的提示的多样性。作者的注释过程如下。作者要求注释器首先编写一个提示，然后根据提供的标准在两个采样的模型响应之间进行选择。为了最大限度地提高多样性，从两个不同的模型变量中对给定提示的两个响应进行采样，并改变温度超参数。除了给参与者一个被迫的选择之外，作者还要求注释者标注他们更喜欢自己选择的回答而不是选择的程度：要么他们的选择明显更好，要么更好，要么稍微好一点，要么好到可以忽略不计/不确定。\",\"（就是给个输入，然后有两种输出，看哪个更符合标准）\",\"用到的一些人类偏好开源数据集\"]},\"13\":{\"h\":\"3.2.2 奖励建模\",\"t\":[\"奖励建模就是拿一个模型的结果和它相关的Prompt作为输入，然后输出一个分数来表明这个结果的质量（有用性、安全性等），用这个分数，就可以在RLHF中优化模型了\",\"为了训练奖励模型，作者将收集的成对人类偏好数据转换为二元排名标签格式（即选择和拒绝），并强制选择的响应比对应的响应具有更高的分数。作者使用了二元排名损失：\",\"where rθ(x, y) is the scalar score output for prompt x and completion y with model weights θ. yc is the preferred response that annotators choose and yr is the rejected counterpart.\",\"在这种二元排名损失的基础上，作者进一步修改它，如第3.2.1节所示，利用这些信息来明确教导奖励模型为具有更多差异的世代分配更多不一致的分数可能是有用的。为此，作者在损失中进一步添加了一个margin成分：\",\"where the margin m(r) is a discrete function of the preference rating. Naturally, we use a large margin for pairs with distinct responses, and a smaller one for those with similar responses (shown in Table 27). We found this margin component can improve Helpfulness reward model accuracy especially on samples where two responses are more separable. More detailed ablation and analysis can be found in Table 28 in Appendix A.3.3.\",\"奖励建模的训练详情。LLaMA 2-Chat在训练数据上训练一个epoch。在早期的实验中，发现训练时间过长会导致过度拟合。LLaMA 2-Chat使用与基本模型相同的优化器参数。70B参数LLaMA 2-Chat的最大学习率为5×10−6，其余参数为1×10−5。学习率按余弦学习率计划降低，降至最大学习率的10%。 LLaMA 2-chat使用占总步数3%的warm-up，最少5 steps。有效batch大小固定为512对，即每batch 1024行。\",\"奖励建模的结果。在每一batch用于奖励建模的人类偏好注释上，都拿出1000个例子作为测试集来评估模型(这个都是可以学习的地方，按他的来)。作者将相应测试集的所有提示的并集分别称为“Meta Helpfulness”和“Meta Safety”。总体而言，这个奖励模型优于所有base-line，包括GPT-4。\",\"当作者在表8中按偏好评级对分数进行分组时，我们可以看到“明显更好”的测试集，并随着比较对变得更加相似而逐渐退化（例如，“稍微好一点”）。当在两个相似的模型反应之间做出决定时，由于注释者的主观性和他们对可能区分反应的细微细节的依赖，学习对人类偏好进行建模将变得具有挑战性。作者强调，对于提高LLaMA 2-Chat的性能，更明显的响应的准确性最为重要。与相似对相比，在更明显的反应上，人类偏好注释一致率也更高。\"]},\"14\":{\"h\":\"3.2.3 迭代微调\",\"t\":[\"作者通过两个主要的算法来探索RLHF微调：\",\"近端策略优化(Proximal Policy Optimization, PPO)，论文链接，该算法是RLHF文献的标准。\",\"拒绝采样微调(Rejection Sampling fine-tuning)，作者对模型中的K个输出进行采样，并用我们的奖励选择最佳候选者，这与Constitutional AI: Harmlessness from AI Feedback保持一致。Residual Energy-Based Models for Text Generation也提出了同样的LLM重新排序策略，其中奖励被视为能量函数。在这里，作者更进一步，使用选定的输出进行梯度更新。对于每个Prompt，获得最高奖励分数的样本被视为新的金标准。与Discriminative Adversarial Search for Abstractive Summarization类似，然后作者在新的一组排序样本上微调模型，以增强奖励。\",\"这两个强化学习(RL)算法的主要不同：\",\"广度。在拒绝采样中，该模型为给定提示探索K个样本，而对PPO只进行一次生成。\",\"深度。在PPO中，在步骤t的训练期间，样本是前一步骤的梯度更新后从t−1更新的模型策略的函数。在拒绝采样微调中，在应用类似于SFT的微调之前，作者在给定模型的初始策略的情况下对所有输出进行采样，以收集新的数据集。然而，由于作者应用了迭代模型更新，两种RL算法之间的基本差异就不那么明显了。\",\"拒绝采样的介绍。作者只对最大的70B LLaMA 2-Chat进行拒绝采样。所有较小的模型都根据较大模型的拒绝采样数据进行微调，从而将较大模型的能力提取到较小的模型中。在每个迭代过程，作者从最新的模型中对每个Prompt采样K个答案，作者为每个样本打分，给出实验时可访问的最佳奖励模型，然后为给定提示选择最佳答案。\",\"作者在图7中说明了拒绝采样的好处。最大曲线和中值曲线之间的增量可以解释为对最佳输出进行微调的潜在增益。正如预期的那样，这个增量随着样本的增加而增加，因为最大值增加（即，更多的样本，产生良好轨迹的机会更多），而中值保持不变。探索和作者能在样本中获得的最大回报之间有着直接的联系。温度参数对勘探也起着重要作用，因为更高的温度使作者能够对更多样的输出进行采样。\",\"在图8中，作者报告了LLaMA 2-Chat-SFT（左）和LLaMA 2-Chat-RLHF（右），N个样本（其中N∈[1，…，100]）在不同温度下的最大回报曲线。可以观察到，在迭代模型更新过程中，最佳温度不是恒定的：RLHF对重新缩放温度有直接影响。对于LLaMA 2-Chat-RLHF，当在10到100个输出之间采样时，最佳温度为T∈[1.2，1.3]。因此，在有限的计算预算下，有必要逐步重新调整温度。请注意，对于每个模型，这种温度重新缩放都会发生恒定数量的步骤，并且总是从每个新RLHF版本的基本模型开始。\",\"PPO介绍。对于所有模型，作者使用AdamW优化器，其中β1=0.9，β2=0.95，eps=10−5。使用0.1的权重衰减(weight decay)、1.0的梯度剪裁(gradient clipping)和10e−6的恒定学习率(lr) 对于每个PPO迭代，我们使用512的批量大小(batch size)、0.2的PPO剪辑阈值、64的小批量大小(mini-batch size)，并且每个小批量采取一个梯度步骤(step)。对于7B和13B模型，我们设置β=0.01（KL惩罚），对于34B和70B模型，设置β=0.005。\",\"作者为所有模型进行了200到400次迭代的训练，并对延迟的提示进行了评估，以提前停止。70B模型上的PPO每次迭代平均耗时≈330秒。为了快速进行大批量训练，作者使用PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel。这在使用O（1）正向或反向传播时是有效的，但在生成过程中会导致很大的减慢（≈20×），即使在使用大批量和KV缓存时也是如此。作者能够通过在生成之前将模型权重合并到每个节点一次，然后在生成之后释放内存，恢复训练循环的其余部分来缓解这种情况。\"]},\"15\":{\"h\":\"3.3 多轮一致性的指令\",\"t\":[\"在对话设置中，一些指示应适用于所有的对话轮数中，例如，简洁地回应，或“扮演”某个公众人物。然而，在初始版本的RLHF模型中，LLaMA 2-Chat会忘记指示，如下图左侧（右侧是使用GAtt优化后的结果）：\",\"为了解决这些限制，作者提出了Ghost Attention（GAtt），这是一种受上下文蒸馏，Constitutional AI: Harmlessness from AI Feedback启发的非常简单的方法，它可以破解微调数据，以帮助在多阶段过程中集中注意力。GAtt允许对多轮进行对话控制，如图9（右）所示。\",\"Gatt方法。假设可以访问两个人（例如，用户和助手）之间的多回合对话数据集，该数据集具有消息列表[u1，a1，…，un，an]，其中un和an分别对应于回合n的用户和助手消息。然后定义了一个指令，inst，应该贯穿在整个对话中。例如，inst可以是“扮演...”。然后可以将此指令综合连接到会话的所有用户消息。\",\"接下来可以使用最新的RLHF模型对这些合成数据进行采样。现在有了一个上下文对话和样本，可以在类似于拒绝采样的过程中对模型进行微调。可以在除第一个回合外的所有回合中放弃它，而不是用指令来增加所有上下文对话回合，但这会导致系统消息（即最后一个回合之前的所有中间辅助消息）与样本在训练时间不匹配。为了解决这个可能影响训练的问题，只需将前几轮中的所有token（包括助手的消息）的loss设置为0。\",\"对于训练指令，作者创建了一些综合约束条件：爱好（“你喜欢例如网球”）、语言（“用例如法语说话”）或公众人物（“扮演例如拿破仑”）。为了获得兴趣爱好和公众人物的列表，作者要求LLaMA 2-Chat生成它，以避免教学和模型知识之间的不匹配（例如，要求模型扮演训练中没有遇到的人）。为了使指令更加复杂和多样化，作者通过随机组合上述约束来构建最终指令。在为训练数据构建最终系统消息时，作者也会在一半的时间内修改原始指令，使其不那么冗长，例如，“从现在起始终充当拿破仑”-> “人物：拿破仑。”这些步骤生成了一个SFT数据集，可以在该数据集上微调LLaMA 2-Chat。\",\"为了说明GAtt如何在微调过程中帮助重塑注意力，作者在下图中显示了模型的最大注意力激活。每个图的左侧对应系统信息（“Act as Oscar Wilde，扮演奥斯卡·王尔德”）。我们可以看到，与没有GAtt的模型（左）相比，配备GAtt的型号（右）在对话的大部分时间里保持了对系统消息的大量注意力激活。（？差别很大吗）\"]},\"16\":{\"h\":\"3.4 RLHF结果\"},\"17\":{\"h\":\"3.4.1 基于模型的评估\",\"t\":[\"模型的进展。图11报告了作者针对安全和帮助轴的不同SFT和RLHF版本的进展，通过Meta内部的安全和帮助奖励模型进行测量。在这组评估中，RLHF-V3之后的两个轴上都优于ChatGPT（无害和有用>50%）。尽管前面提到了使用Meta的奖励作为逐点衡量标准的相关性，但可以说，它可能偏向于LLaMA 2-Chat。因此，为了进行公平的比较，作者使用GPT-4额外计算最终结果，以评估哪一代是优选的。ChatGPT和LLaMA 2-Chat输出在GPT-4提示中出现的顺序是随机交换的，以避免任何偏差。正如预期的那样，支持LLaMA 2-Chat的胜率不那么明显，尽管我们最新的LLaMA 2-Chat获得了超过60%的胜率。\"]},\"18\":{\"h\":\"3.4.2 人类评价\",\"t\":[\"人类评价通常被认为是评判自然语言生成模型（包括对话模型）的黄金标准。为了评估主要模型版本的质量，作者要求人类评估人员对其有用性和安全性进行评分。作者将LLaMA 2-Chat模型与开源模型（Falcon，MPT ，Vicuna）以及4000多个单回合和多回合提示的闭源模型（ChatGPT和PaLM）进行了比较。对于ChatGPT，作者使用gpt-3.5-turbo-0301型号。对于PaLM，作者使用chat-bison-001模型。\",\"结果如图12所示，LLaMA 2-Chat模型在单回合和多回合提示上都显著优于开源模型。特别是，LLaMA 2-Chat 7B模型在60%的提示上优于MPT-7B-Chat。LLaMA 2-Chat 34B与同等尺寸的Vicuna-33B和Falcon 40B型号相比，总体胜率超过75%。 最大的LLaMA 2-Chat模型与ChatGPT具有竞争力。LLaMA 2-Chat 70B模型相对于ChatGPT的胜率为36%，平局率为31.5%。在我们的提示集上，LLaMA 2-Chat 70B模型在很大程度上优于PaLM bison聊天模型。\"]},\"19\":{\"h\":\"MLOps\",\"t\":[\"MLOps是一门工程学科，旨在统一 ML 系统开发（dev）和 ML 系统部署（ops），以标准化过程生产高性能模型的持续交付。知乎\",\"Machine Learning Operations (MLOps) overview definition and architecture这篇论文中介绍了11个MLOps相关工具，下面挑选开源的和Azure商用的进行总结：\"]},\"20\":{\"h\":\"2.1 TensorFlow Extended\",\"t\":[\"类别：开源\",\"TFX 是一种基于 TensorFlow 的 Google 生产级机器学习 (ML) 平台。该平台提供了一个配置框架和众多共享库，用来集成定义、启动和监控机器学习系统所需的常见组件。TFX 是一个端到端平台，用于部署生产环境机器学习流水线。TensorFlow Extended（TFX）是一个配置框架，为端到端ML管道的每个任务提供库。例如，有数据验证、数据分布检查、模型训练和模型服务。\",\"相关链接：https://tensorflow.google.cn/tfx?hl=zh-cn\"]},\"21\":{\"h\":\"2.2 Airflow\",\"t\":[\"类别：开源\",\"Airflow是一种任务和工作流程编排工具，也可以用于ML工作流程编排。它还可用于编排数据工程作业。任务可以根据有向无环图（DAGs）来执行。\",\"相关链接：https://airflow.apache.org/\"]},\"22\":{\"h\":\"2.3 Kubeflow（全面工具集、偏训练） ⭐\",\"t\":[\"用途：全面、偏训练\",\"类别：开源\",\"Kubeflow是一个基于kubernetes的机器学习工具集，本身没有任何功能，靠的是其丰富的工具。 Kubeflow主要是为了简化在kubernetes上面运行机器学习任务的流程， 最终希望能够实现一套完整可用的流水线，来实现机器学习从数据到模型的一整套端到端的过程。 Kubeflow是一个基于kubernetes的端到端ML平台。每个Kubeflow组件都被包装到一个容器中，并由Kubernetes协调。此外，ML工作流管道中的每个任务都用一个容器来处理。 Kubeflow项目致力于在Kubernetes上部署机器学习（ML）工作流，简单，可移植和可扩展。我们的目标不是重新创建其他服务，而是提供一种直接的方法，将ML的最佳开源系统部署到不同的基础设施。无论你在哪里运行Kubernetes，你都应该能够运行Kubeflow。 Kubeflow 主要关注于训练的过程， 对于其他方面，则应该找寻更为合适的框架或者平台。\",\"相关链接：https://www.kubeflow.org/\",\"相关链接：https://www.bilibili.com/video/BV1G14y1972C\",\"相关链接：https://developer.aliyun.com/article/784044\",\"相关链接：https://zhuanlan.zhihu.com/p/55840115\"]},\"23\":{\"h\":\"2.4 MLflow（监控、模型再部署、性能监控） ⭐\",\"t\":[\"类别：开源\",\"类型：监控、模型再部署、性能监控\",\"MLflow是一个ML平台，它允许端到端管理ML生命周期。它提供了一个高级的实验跟踪功能、一个模型注册表和模型服务组件。MLflow是一个开源工具，可帮助您管理机器学习生命周期的核心部分。它通常用于实验跟踪，但您也可以将其用于再现性，部署和模型注册。您可以使用CLI、Python、R、Java和REST API管理机器学习实验和模型元数据。 MLflow是机器学习工程师通过实验、部署和测试来管理机器学习生命周期的开源平台。当您想要跟踪机器学习模型的性能时，MLflow就派上用场了。它就像一个仪表盘，在这里你可以：\",\"相关链接：https://mlflow.org/\",\"相关链接：https://zhuanlan.zhihu.com/p/161641400\"]},\"24\":{\"h\":\"2.5 Azure DevOps Pipelines\",\"t\":[\"类别：商用\",\"Azure DevOps管道是一个CI/CD自动化工具，以促进构建、测试和交付步骤。它还允许人们调度和管理一个ML管道的不同阶段。\",\"相关链接：https://learn.microsoft.com/zh-cn/azure/devops/pipelines/?view=azure-devops\"]},\"25\":{\"h\":\"2.6 Azure ML\",\"t\":[\"类别：商用\",\"微软的Azure结合了Azure DevOps管道和Azure ML，提供了一个端到端ML平台。\",\"在https://www.datacamp.com/blog/top-mlops-tools中提到了一些其他的MLOps的工具，下面挑选介绍：\"]},\"26\":{\"h\":\"3.1 Comet ML\",\"t\":[\"Comet ML是一个跟踪、比较、解释和优化机器学习模型和实验的平台。您可以将其与任何机器学习库一起使用，例如Scikit-learn，Pytorch，TensorFlow和HuggingFace。\",\"相关链接：https://www.comet.com/site/\"]},\"27\":{\"h\":\"3.2 Weights & Biases(wandb) （监控）⭐\",\"t\":[\"用途：监控\",\"Weights & Biases是一个用于实验跟踪、数据和模型版本控制、超参数优化和模型管理的机器学习平台。此外，您可以使用它来记录工件（数据集、模型、依赖关系、管道和结果）并可视化数据集（音频、视觉、文本和表格）。\",\"相关链接：https://wandb.ai/site\"]},\"28\":{\"h\":\"3.3 Prefect（工作流管理） ⭐\",\"t\":[\"用途：工作流管理\",\"Prefect是一个现代化的数据堆栈，用于监控、协调和编排应用程序之间的工作流。它是一个开源的轻量级工具，专为端到端机器学习pipeline而构建。您可以使用Prefect Orion UI或Prefect Cloud作为数据库。Prefect Orion UI是一个开源、本地托管的编排引擎和API服务器。它为您提供了对本地Prefect Orion实例和工作流的深入了解。Prefect Cloud是一个托管服务，可让您可视化流程、流程运行和部署。此外，您还可以管理帐户、工作区和团队协作。\",\"相关链接：https://www.prefect.io/\"]},\"29\":{\"h\":\"3.4 Metaflow\",\"t\":[\"用途：工作流管理\",\"Metaflow是一个强大的，久经考验的工作流管理工具，用于数据科学和机器学习项目。它是为数据科学家构建的，因此他们可以专注于构建模型，而不是担心MLOps工程。\"]},\"30\":{\"h\":\"3.5 Pachyderm\",\"t\":[\"用途：版本控制（没有看出具体用途）\",\"Pachyderm通过Kubernetes上的数据版本化、沿袭和端到端管道自动化数据转换。您可以与任何数据（图像，日志，视频，CSV），任何语言（Python，R，SQL，C/C++）以及任何规模（PB数据，数千个作业）集成。就像Git一样，你可以使用类似的语法来版本化你的数据。在Pachyderm中，对象的最高级别是Repository，您可以使用Commit、Branches、File、History和Provenance来跟踪和版本化数据集。\",\"相关链接：https://www.pachyderm.com/\"]},\"31\":{\"h\":\"3.6 Data Version Control (DVC) （版本控制）⭐\",\"t\":[\"用途：版本控制，可对数据、模型等进行版本控制\",\"Data Version Control是一个开源的、流行的机器学习项目工具。它与Git无缝协作，为您提供代码、数据、模型、元数据和管道版本控制。DVC不仅仅是一个数据跟踪和版本控制工具。您可以使用它：实验跟踪（模型指标、参数、版本控制）。创建、可视化和运行机器学习管道。部署和协作的工作流。数据和模型注册表。使用CML持续集成和部署机器学习。\",\"相关链接：https://dvc.org/\"]},\"32\":{\"h\":\"3.7 BentoML（模型部署与管理） ⭐\",\"t\":[\"用途：模型部署与管理\",\"BentoML使机器学习应用程序的发布变得更简单、更快。它是一个Python优先的工具，用于在生产中部署和维护API。它通过运行并行推理和自适应批处理来扩展强大的优化功能，并提供硬件加速。BentoML的交互式集中式仪表板可以在部署机器学习模型时轻松组织和监控。最好的部分是它可以与各种机器学习框架一起使用，例如Keras，ONNX，LightGBM，Pytorch和Scikit-learn。简而言之，BentoML为模型部署、服务和监控提供了完整的解决方案。\",\"相关链接：https://www.bentoml.com/\",\"相关链接：https://github.com/bentoml/bentoml\",\"相关链接：https://zhuanlan.zhihu.com/p/495814838\"]},\"33\":{\"h\":\"3.8 Cortex（模型部署与管理） ⭐\",\"t\":[\"用途：模型部署与管理\",\"Cortex允许您在生产环境中部署、管理和扩展机器学习模型。它是一个开源、灵活、多框架的模型服务和监控工具。Cortex扩展到Docker，Kubernetes，TensorFlow Serving，TorchServe和其他ML库。它通过提供可扩展的端点来管理负载。此外，您可以在单个API端点上部署多个模型，并且它支持用于保护API的自动扩展功能。它是一个MLOps工具，赠款您完全控制模型管理操作。\",\"相关链接：https://www.cortex.dev/\"]},\"34\":{\"h\":\"3.9 Evidently（监控） ⭐\",\"t\":[\"用途：监控\",\"开源Python库，用于在开发、验证和生产过程中监控ML模型。它检查数据和模型质量、数据漂移、目标漂移以及回归和分类性能。Evidently有三个主要组成部分：测试（批量模型检查）：用于执行结构化数据和模型质量检查。报告（交互式仪表板）：交互式数据漂移、模型性能和目标虚拟化。实时监控（Real-time monitoring）：监控来自已部署ML服务的数据和模型指标。\",\"相关链接：https://www.evidentlyai.com/\",\"相关链接：https://zhuanlan.zhihu.com/p/398651743\"]},\"35\":{\"h\":\"3.10 Censius AI\",\"t\":[\"模型监控（与Wandb类似）\",\"相关链接：https://censius.ai/\",\"在https://www.projectpro.io/article/best-mlops-tools-/574提到了大部分上述已有的工具，此外，还提到了一个工具：\"]},\"36\":{\"h\":\"4.1 Hydrosphere（性能监控）\",\"t\":[\"用途：性能监控（它的功能之一）\",\"Hydrosphere是一个用于在生产环境中部署、版本控制和监控机器学习模型的平台。它与语言和框架无关，支持所有主要的编程语言和框架- Python，Java，Tensorflow，Pytorch等。其组件Hydrosphere Monitoring在监控机器学习模型部署方面发挥着最关键的作用，以下是其其他关键功能： 跟踪模型性能：Hydrosphere Monitoring检查数据的变化，跟踪已部署的ML模型的性能，并在数据问题发生时向用户发送通知。 易于理解的推论：Hydrosphere提供了模型预测的简单摘要，并且不需要用户查看模型结构。此外，Hydrosphere对贡献发生变化的时间给出了明确的解释，这有助于快速了解数据出了什么问题并设计下一个行动计划。 框架不可知服务：用户可以在开源Hydrosphere Serving集群的帮助下实现、检查点和扩展机器学习模型。此外，Hydrosphere允许用户提供在任何框架中开发的模型，并通过gRPC，REST或Kafka流将它们链接起来。 简单方便：Hydrosphere SDK支持部署新训练的模型或与已部署的模型链接，并使用户能够通过监控和可解释性分析进行检查。Hydrosphere还提供与当前机器学习流程的快速合并。\",\"相关链接：https://docs.hydrosphere.io/\",\"https://neptune.ai/blog/best-open-source-mlops-tools和https://neptune.ai/blog/mlops-tools-platforms-landscape非常丰富地介绍了MLOps Tools，这里补充一些介绍：\"]},\"37\":{\"h\":\"5.1 AutoKeras（自动化机器学习）\",\"t\":[\"用途：自动化机器学习\",\"AutoKeras是一个用于自动机器学习（AutoML）的开源库。使用AutoML框架，您可以自动处理原始数据，选择机器学习模型，并优化学习算法的超参数。\",\"相关链接：http://autokeras.com/\"]},\"38\":{\"h\":\"从BERT到GLM，NLP经历了什么？\",\"t\":[\"2022年底，ChatGPT悄然进入大众的视线，受到了业内人士和广大群众的注意。ChatGPT的成功不是偶然的，是其总结前人经验、反复打磨多年才得以形成的。本篇文章将顺着现代自然语言处理方法和模型的脉络，即Transformer[1]、BERT[2]、T5[3]、GPT[4]、GLM[5]和P-Tuning v2[6]几个方面来介绍。其中Transformer是一种全新的序列转换模型，BERT、T5、GPT和GLM均为预训练语言模型，P-Tuning v2是一种对预训练语言模型进行高效微调的方法。通过以上几个部分，本篇文章对现代语言模型的学习的全过程：即结构、训练和微调均进行了介绍。其中因为内容相对重复，本篇文章对T5和GPT进行简要介绍。\"]},\"39\":{\"h\":\"一、主要研究点\",\"t\":[\"在ChatGPT大火之后，各种语言模型层出不穷，比如百度的文心、讯飞的星火等。但是语言模型的研究并不是最近才兴起的。早在2017年，Google Brain就发布了一个全新的序列转换模型—Transformer，后续的语言模型，基本上都与Transformer有着千丝万缕的联系。2018年，Google公开了以Transformer作为基础的语言模型BERT，轰动一时。BERT的基础模型有110M参数，在当年属于标准大小，但是其自然语言理解能力非常强。2019年，Google公开了T5模型，该模型号称是“全能模型”，即所有的自然语言理解任务都可划分为“文本到文本”的任务，T5基础模型参数量为220M，但是最大的T5模型达到了11B，是BERT_base的100倍大小。这绝对可以称之为“大模型”了。\",\"BERT和T5都是Google的精彩操作，而另一边的OpenAI也不甘落后，2018年， GPT-1公开，其参数量有117M；2019年，GPT-2公开，其参数量有1.5B；而2020年，GPT-3公布，其参数量已经达到了175B。\",\"放眼国内，清华大学在语言模型上研究较早。2021年，清华大学语言模型GLM发布，意为通用语言模型(General Language Model)。目前，最大的GLM参数量已经达到了130B。\",\"基本已经可以确定的是，小模型（低于10B参数）的能力不是很强，所以语言模型方向模型参数规模越来越大，百亿、千亿、万亿模型都不足为奇。然而，抛开预训练不谈，在如此大的规模下，大部分个人和团队都已经没有能力去做模型的全参数微调了。因此，国内外研究者先后提出了P-Tuning[7]、Prefix-Tuning[8]、P-Tuning v2[6]、Prompt Tuning[9]和LoRA[10]等部分参数微调方法。本篇文章选择了清华大学的P-Tuning v2，该方法微调效果可以与全参数微调媲美，但是微调参数量仅为全参数微调的3%左右。\",\"本篇文章会对上述模型和技术进行简要介绍，该脉络基本涉及了现代语言模型学习的全过程。\"]},\"40\":{\"h\":\"二、Transformer\"},\"41\":{\"h\":\"2.1 序列转换模型\",\"t\":[\"一个序列转换(Sequence-to-Sequence, Seq2Seq)模型一般包括一个编码器(Encoder)和一个解码器(Decoder)，如图2-1。序列转换模型并不是Transformer首次提出的。在Transformer之前，序列转换模型一般由循环神经网络(RNN)或卷积神经网络(CNN)作为编码器和解码器。然而无论是RNN也好，CNN也罢，它们都足够复杂，导致序列转换模型的效率不高。后来，有的学者尝试将注意力机制(Attention Mechanism)引入序列转换模型[11]，让序列转换模型的效率得以一定的提升。不过它们仍然没有脱离RNN或者CNN。\",\"图2-1 序列转换模型\",\"而Transformer，彻底抛弃了复杂的RNN和CNN，只依赖于注意力机制，这也是Transformer成功的关键。在介绍Transformer之前，我们首先讨论一下注意力机制。\"]},\"42\":{\"h\":\"2.2 注意力机制\",\"t\":[\"注意力机制(Attention Mechanism)是人们在机器学习模型中嵌入的一种特殊结构，用来自动学习和计算输入数据对输出数据的贡献大小。在注意力机制中，我们往往会讨论Q、K、V，它们分别代表Query、Key、Value。注意力机制就是给定一个Query，经过一系列的Key来获取Value，从而得到Attention Score。如图2-2。\",\"图2-2 注意力机制\",\"实际上，计算Attention Score的过程如下：首先，由Query和Key做向量比对，得到Query和Key的相似度，然后归一化相似度，并用相似度与Key所对应的Value做矩阵运算并求和，得到Attention Score。注意力机制公式如下：\",\"下面我们来介绍自注意力机制。自注意力机制是注意力机制的一种。在自注意力机制中，注意力集中在上述公式中Source的内部元素，如图2-3。而在计算方式上，与传统注意力机制完全相同。在Transformer中，自注意力机制得到了应用，因为Transformer需要判断序列中词与词之间的关系强度，自注意力机制正符合这一点。\",\"图2-3 自注意力机制示例\"]},\"43\":{\"h\":\"2.3 Transformer模型\",\"t\":[\"Transformer是Seq2Seq的全新尝试，其抛弃了RNN和CNN作为Encoder和Decoder，采用了注意力机制，提高了Seq2Seq的效率。\",\"图2‑4 Transformer模型\",\"Transformer模型整体结构如图2-4。其结构可以分为输入输出嵌入向量、位置编码、Encoder模块、Decoder模块等。\",\"对输入、输出进行向量化(Embedding)已经是广为应用的做法，其比独热编码(One-Hot)拥有更加优秀的能力，这里不再赘述。下面我们讨论位置编码。\",\"位置编码 。因为Transformer抛弃了RNN和CNN，这样，如果不经过特殊处理，Transformer没有办法表示序列的顺序。但是，序列的顺序中往往蕴含着一些重要信息，比如：\",\"I do not like the story of the movie, but I do like the cast.\",\"I do like the story of the movie, but I do not like the cast.\",\"上述两个句子序列的词完全相同，只不过是某些词的顺序不同。如果不考虑词在序列中的位置，那么Encoder会认为这两个序列完全相同。因此，选择一种合适的方式表示词在序列中的顺序非常重要。\",\"一个好的位置编码方案需要满足以下几个条件：1.它能为每个时间步输出一个独一无二的编码；2.不同长度的句子之间，任何两个时间步之间的距离应该保持一致；3.模型应该能毫不费力地泛化更长的句子，它的值应该是有界的；4.它必须是确定性的。\",\"位置编码可以通过训练得到，也可以通过公式计算得到。Transformer中的位置编码采用公式计算得到，公式如下：\",\"Transformer的位置编码简单但是有创新性。该编码不是一个单一的数值，而是包含句子中特定位置信息的d维向量（d_model即隐层维数）。此外，该编码没有整合进模型，而是用这个向量让每个词具有它在句子序列中的位置信息，即通过注入词的顺序信息来增强模型的输入。最后，采用三角函数来作为位置编码公式，对于相对位置的计算更加方便，因为三角函数具有周期性。\",\"Encoder 。Transformer的编码器结构如图2-5。可以看到，Encoder部分由N个Encoder单元构成。在Transformer中，N=6。一个Encoder单元，由一个多头注意力机制(Multi-Head Attention)和一个前馈网络(Feed Forward)构成。在多头注意力机制和前馈网络完成后，会计算残差和(Add)并正规化(Norm)。首先，我们来讨论多头注意力机制。\",\"图2-5 Encoder结构图\",\"在2.2节中，我们对注意力机制有了初步了解。在这里，我们进一步讨论Transformer中应用的注意力机制。Transformer中对注意力机制的体现在多头注意力机制。而多头注意力机制是由缩放点积注意力机制(Scaled Dot-Product Attention)构成，它是注意力机制的一种，其计算过程与注意力机制一致，其计算公式如下：\",\"缩放点积注意力机制在做完Query和Key的点积之后，会进行一个缩放，即除以d的开方。之所以要缩放，是因为对于输入的d大值，会导致Query和Key的点积非常大，这样会导致SoftMax产生非常小的值，为了抵消这个效果，缩放点击注意力机制会进行一个缩放。\",\"多头注意力机制如图2-6。Transformer认为，将模型分为多个头，形成多个子空间，可以让模型去关注不同方面的信息。多头注意力机制就是将缩放点积注意力机制的过程做h次，再把输出合并起来。多头注意力机制的公式如下：\",\"图2-6 多头注意力机制\",\"Encoder单元中的另一个部分是一个前馈网络。Transformer在这里设计的前馈网络比较简单，为一个两层的多层感知机，第一层有一个ReLU激活函数，第二层为一个线性变换。公式如下：\",\"Decoder 。Transformer的Decoder和Encoder十分相似。Decoder中Decoder单元数N=6，与Encoder一致。Decoder和Encoder最大的区别，是Decoder单元中多了一层Masked Multi-Head Attention。\",\"什么是Masked Multi-Head Attention？其实Multi-Head Attention和上述的一致。但是单纯的Multi-Head Attention是双向的，也就是某个词既可以看到它之后的词，也可以看到它之前的词。\",\"但是在解码阶段，模型需要做的是通过已经有的信息来预测下一个位置会出现什么，如果此时模型知道了某个词之后的信息，模型就失去了“预测”，相当于看到了未来的信息。这是我们不希望发生的。所以，在解码阶段，我们希望自注意力机制是“单向”的，所以这里就用了Masked自注意力机制，组织模型看到将要预测的信息。\",\"Decoder中的Multi-Head Attention的K V是Encoder的输出计算的。\",\"至此，Transformer的模型结构已经介绍完成。Transformer对后来语言模型的影响十分深远，后续的语言模型，基本上都采用了Transformer或者基于Transformer修改的模型。\"]},\"44\":{\"h\":\"三、BERT\",\"t\":[\"Transformer是一个Seq2Seq模型，但并不是一个实际的语言模型。而首个将Transformer应用到实际语言模型中的，正是BERT。BERT全称Bidirectional Encoder Representations from Transformers。从全称中可以看出，BERT是一个双向编码模型，并且和Transformer有关。下面我们来介绍一下BERT。\",\"我们知道，GPT是一个自回归(Autoregression)语言模型，即，当前的Token只能看到它和它之前的Token，而不能看到它之后的Token。BERT在当时的条件下认为，这限制了预训练，特别是微调的能力。模型应该是双向的才好。因此，BERT诞生了，一个双向编码语言模型。\",\"当然，在现在看来，我们无法评价自回归(Autoregression)模型和自编码(Autoencoder)模型，或者说单向模型和双向模型谁好谁坏，它们各有优缺点。比如，自回归语言模型更加适合自然语言生成任务，而自编码模型更加适合自然语言理解任务。\"]},\"45\":{\"h\":\"3.1 BERT与Transformer\",\"t\":[\"BERT并没有把Transformer拿来直接用，而是只用到了Encoder部分。如图3-1，为BERT模型的结构图，其中蓝色阴影部分，就是Transformer的Encoder部分。可以看出，Transformer的Encoder模块，也是BERT的核心。\",\"图3-1 BERT模型结构图\",\"BERT只用了Transformer的Encoder部分，并且相对Transformer来说，BERT对Encoder进行了一些修改。其主要的修改如下：1.在Transformer的介绍中我们提到过，Transformer的Encoder层是由N=6的单元构成的。在BERT中，BERT_base N = 12 BERT_large N = 24。2.在Transformer中，注意力机制体现在模型中是多头注意力机制，Transformer中多头注意力机制是由h = 8，即8个缩放点积注意力叠加而成。在BERT中，BERT_base h = 12，BERT_large h = 16。3.在Transformer中，d = 512，在BERT中，BERT_base d = 768，BERT_large d = 1024。这个d其实就是模型最大能接受的Token长度。4.Embedding部分有了一些调整，多了一个Segment Embedding，Positional Embedding也有调整。我们将在下面介绍这一部分。\",\"这样看来，BERT_base的参数规模是110M，BERT_large的参数规模是340M。虽然把这个模型放到现在看起来规模不大，但是在当时，大家的参数量还没有那么夸张。\"]},\"46\":{\"h\":\"3.2 Input Embedding\",\"t\":[\"BERT相对Transformer来说，对Input Embedding部分做了一些修改，增加了一个Segment Embedding。这个是什么呢？由于BERT的主要目的是构建一个通用的预训练模型，因此难免需要兼顾到各种NLP任务场景下的输入。因此Segment Embedding的作用便是用来区分输入序列中的不同序列，其本质就是通过一个普通的词嵌入来区分每一个序列所处的位置。例如在NSP任务中，那么对于任意一个序列的每一位置都将用同一个向量来进行表示，即此时Segment词表的长度为2。\",\"此外，BERT对Positional Embedding也有调整。Transformer中的位置编码，是由三角函数计算出来的，而BERT的位置编码，是训练出来的。\",\"最终的Input Embedding，是这三个嵌入式张量的和：\",\"图3-2 BERT Input Embedding\"]},\"47\":{\"h\":\"3.3 预训练BERT\",\"t\":[\"BERT的预训练没有采用传统的自左向右或者自右向左语言模型来训练BERT，而是采用的MLM，即Masked Language Model。那么具体是怎么做的呢？\",\"MLM会随机地遮住输入的某些Token，比如：\",\"Input: 今天天气真好呀！\",\"MLM: 今天天气真[MASK]呀！\",\"遮住之后，MLM的要做的事就是根据上下文来预测被遮住的Token应该是什么，是“好”，还是“坏”？这些都是根据上下文，来计算概率的。也就是在这里，可以体现出BERT是双向模型，因为这里的上下文，既包括Token左边的，也包括Token右边的。MLM根据整个句子信息来推断被遮住的Token。\",\"根据经验，一般会MASK掉句子的15%的Token来进行训练，效果比较好（BERT的论文中没有提为什么是15%，T5论文中有对比实验，证明了15%是效果最好的）。不过，如果这15%全部把输入的Token替换成[MASK]，可能会有一个问题：这会造成预训练和微调之间产生一个不匹配的情况，因为在微调的过程中，[MASK]并不会出现，这样预测的概率可能不准确。为了解决这个问题，BERT把这15%中的80%用[MASK]替换，10%不变，10%随机替换为其他Token。\",\"接下来我们来介绍BERT中另外一个部分，Next Sentence Prediction。很多下游任务，比如问题回答、自然语言推理等，都要基于多个句子之间的关系，这个关系是没有办法被语言模型直接捕获到的。为了解决这个问题，BERT在预训练中加入了NSP。NSP是一个二分类下句预测任务。具体地，对于每个样本来说都是由A和B两句话构成，其中的情况B确实为A的下一句话（标签为IsNext），另外的的情况是B为语料中其它的随机句子（标签为NotNext），然后模型来预测B是否为A的下一句话。NSP的位置在BERT模型图中有所体现。\",\"在实验中，BERT的效果遥遥领先于同期其他语言模型，取得了喜人的成绩。这里我们不做过多介绍。\"]},\"48\":{\"h\":\"四、T5和GPT\",\"t\":[\"T5，特别是GPT，其能力大家有目共睹。本篇文章中将简单对其进行介绍。\"]},\"49\":{\"h\":\"4.1 T5模型\",\"t\":[\"T5，是Transfer Text-to-Text Transformer的简写。Transfer来自Transfer Learning，预训练模型基本上属于这个范畴，Transformer即我们在第二节中提到的，那么什么是Text-to-Text？它是T5提出的一个统一框架，用于将所有的自然语言处理(NLP)任务都转化为文本到文本(Text-to-Text)任务。\",\"图4‑1 T5模型\",\"比如，自然语言处理中常见的翻译任务，在T5模型中，只需要在给模型输入的部分加上前缀：“给我从英语翻译成汉语”，然后再加上要翻译的内容即可。通过这样的方式，就可以将NLP任务都转成Text-to-Text的形式，这样，就可以用同样的模型、同样的损失函数、同样的训练过程、同样的解码过程来完成所有的NLP任务。本文对T5模型的介绍就到这里，更多内容可以阅读原论文。\"]},\"50\":{\"h\":\"4.2 GPT模型\",\"t\":[\"说到GPT(Generative Pre-Training)语言模型，大家首先想起的一定是ChatGPT。ChatGPT是基于GPT-3.5的对话聊天机器人，其能力大家有目共睹。其成功的关键在于超大的参数规模(1750亿)和超多的预训练语料，这是普通公司和个人难以承受的。本篇文章将回到最初的GPT，来讨论GPT的基本结构。\",\"GPT模型与BERT模型不同。BERT模型是自编码模型，而GPT模型是自回归模型。自回归模型对自然语言生成有着天然的优势。不过与BERT、T5模型相同，GPT同样也抛弃了传统的RNN和CNN，转而采用Transformer结构。与BERT不同的是，GPT采用的不是Transformer的Encoder部分，而是其Decoder部分。\",\"GPT的核心部分是N=12的Transformer Decoder结构，如图4-2。\",\"图4-2 GPT模型结构\",\"同样，GPT也并没有将Transformer的Decoder拿过来直接用，而是做了一些修改。Transformer的Decoder结构中，包含了Masked Multi Self Attention和Multi Self Attention，在GPT中，只保留了Masked Multi Self Attention。其余基本没有变化。\",\"如今，GPT已经迎来了第四个大版本，GPT-4。其参数规模进一步增大，能力进一步增强，更是拥有了理解图像的能力。AI的能力在逐步增强。\"]},\"51\":{\"h\":\"五、GLM\",\"t\":[\"在国内，清华大学发布的GLM(General Language Model)应该是效果比较不错的一个模型。当然，其优良的效果源于其创新的思想和持续的研究。\",\"GLM意为通用语言模型，其通用性体现在哪里？我们知道，预训练语言模型可以分为三种：自回归模型(e.g. GPT[4])、自编码模型(e.g. BERT[2])、编码-解码模型(e.g. RoRERTa[12])。它们各有各的擅长之处。比如自回归模型擅长自然语言生成任务，而自编码模型擅长自然语言理解任务。在GLM之前，也有研究人员尝试将上述三种模型结合[13]，以胜任多种自然语言处理任务，不过因为自回归和自编码在模型结构上相差太多，所以效果不是很好（在现在看，GPT似乎有能力处理自然语言理解和自然语言生成任务，不过在当时的条件下并没有很出色的能力）。\",\"同样，GLM也尝试能够同时处理自然语言理解和自然语言生成等多种NLP任务。不同于之前研究的简单结合，GLM创新地应用了自回归填空思想。下面，我们来介绍GLM中的自回归填空思想。\"]},\"52\":{\"h\":\"5.1 自回归填空\",\"t\":[\"GLM模型应用了名为自回归填空(Autoregressive Blank Infilling)的思想。我们给定一个文本序列[x~1~, …, x ~n~ ]，在其中采用多个文本域{s ~1~ , …, s ~m~ }，其中每个文本域s~i ~都对应x中的连续Token [s ~i,1~ ,…,s ~i,li~ ]，而每一个文本域都会被一个单独的Token [MASK]所替代。也许通过文字描述比较难以理解。我们可以看图5-1：\",\"图5-1 GLM自回归填空示意图之一\",\"在图5-1(a)中，可以看到我们给定的文本序列为[x~1~, …, x~6~]，在文本序列中采样的文本域为{s ~1~ , s ~2~ }，其中s~1~对应着[x ~3~ ]，s~2~对应着[x ~5~ , x ~6~ ]（图中含有色块部分）。在图5-1(b)中可以看到，GLM把s~1~和s~2~对应的x部分替换为一个[MASK] Token，而与BERT等Masked不同，GLM没有选择直接丢失这些x，而是将其放到了Part B部分。\",\"GLM随机Masked掉一些文本，其实在BERT中也是这样做的，我们称之为Masked Language Model(MLM)。只不过，在BERT中，一般Masked掉的是一个词，而GLM中可能会Masked掉连续的多个字。个人猜测，可能是因为在中文中，一个字可能意义不如多个字组成的意义大（如“玩”和“玩笑”可能差别很大），所以Masked掉多个字，可能效果会更好一些。GLM随机Masked掉的比例为15%，沿用了BERT和T5的Masked的比例，这个比例在T5模型的论文中证明，为效果最好的。\",\"对于Masked掉的词，GLM采用自回归的方式尝试还原它们，即“自回归填空”，公式如下：\",\"其中x~corrupt~就是partA，即带MASK部分的句子，s~z<i~指的是partB的部分，不过看到它只用了z<i的部分，也就是单向的，即自回归的。不过考虑到span之间可能也有关系，所以s~z~的顺序是随机打乱的。如图5-2。\",\"在这里也可以看出，GLM预测的条件比BERT多了一个partB。在BERT中，MASK掉的15%的输入，其中只有80%被[MASK]替代，而另外10%不变，10%随机变为其他Token，BERT通过这种方式来保留一些被Masked的原始信息。但是GLM没有这样做，GLM把Masked掉的信息全部保留在了partB，这样可以进一步提高预测能力。不过partA是看不到partB的，partB可以自回归地看到已经走过的partB和全部的partA。\",\"图5-2 GLM自回归填空示意图二\"]},\"53\":{\"h\":\"5.2 二维位置编码\",\"t\":[\"在Transformer中，位置编码采用了三角函数计算的方式得到；在BERT中，位置编码采用了预训练的方式训练而得。GLM仍然是以Transformer为基础的结构，自然也没有原生的表示位置信息的能力，所以，也只能够通过位置编码的形式来获取位置信息。\",\"与Transformer和BERT的一维位置编码不同，GLM采用了二维位置编码。\",\"通过上一节的介绍我们知道，GLM把输入的文本分为两个部分：partA和partB。所谓二维编码，即对partA部分和partB部分都进行编码。如图5-3。\",\"图5-3 GLM二维编码\",\"对于Position 1，表示词在partA中的位置，Position 2表示被Masked的词在partB中的位置，如果Position 2 = 0，表示非Masked的词。\"]},\"54\":{\"h\":\"5.3 GLM与Transformer\",\"t\":[\"上述我们也提到，GLM同样是基于Transformer的结构，不过与BERT、T5一样，GLM同样对Transformer的结构进行了修改。GLM同样只使用了Transformer的Encoder部分，并且做了以下修改：1.重新调整了LN和残差连接的顺序。2.对于Token的预测输出用的是单个的线形层。3.将激活函数由ReLU调整为GeLUs，因为GeLUs效果更好。\",\"至此，GLM的基本结构已经介绍完毕。四个基于Transformer的预训练语言模型也已经介绍完毕。它们整体相似，但是都有自己的创新点。相信在未来，会有更多更好的语言模型诞生。但是，为了适应下游任务，对于预训练好的语言模型，往往需要经过下游数据进行微调后才可更好的发挥它的能力。下面一节，我们介绍微调相关技术。\"]},\"55\":{\"h\":\"六、P-Tuning v2\",\"t\":[\"训练语言模型的成本是巨大的，往往小的企业或者个人应用的，都是在一个良好的预训练语言模型上进行微调。从前，预训练语言模型的方式只有全参数微调(Fine-Tuning)，全参数微调效果相对较好，可以让微调后的预训练模型在处理下游任务时得到良好的效果。但是全参数微调的设备需求仍然很大，比如，对于GLM-130B进行全参数微调，需要10台DGX A100服务器，设备就需要千万级别。这对很多企业和个人仍然是不能接受的。\",\"为了减少微调的设备等资源的消耗，研究者着手设计部分参数微调的方法，包括P-Tuning[7]、Prefix-Tuning[8]、Prompt-Tuning[9]、LoRA[10]和P-Tuning v2[6]。但是，P-Tuning、Prefix-Tuning虽然实现了部分参数调优，让微调的资源消耗降下来了，但是其性能仍然不如全参数微调。LoRA同样也是一种部分参数微调的方法，其在挖掘语言模型的潜在能力上有着不错的成绩，并且其资源消耗极低，受到了大家的关注。LoRA在文生图领域应用广泛。\",\"Prompt-Tuning和P-Tuning v2基本上是同一时期发布的，它们均基于Prefix-Tuning进行了修改和优化，结构基本一致。这里，我们选择P-Tuning v2进行介绍。\"]},\"56\":{\"h\":\"6.1 提示微调\",\"t\":[\"上述我们介绍P-Tuning v2属于部分参数微调，更准确地说，P-Tuning v2应该属于提示微调(Prompt Tuning)。提示微调只用一个冻结的语言模型来微调连续的提示，大大减少了训练时的存储和内存使用。\",\"提示微调冻结了预训练模型的所有参数，并使用自然语言提示来查询语言模型。比如，对于情感分析问题，我们可以将样本与提示“这部电影是[MASK]”串联起来，要求预训练语言模型预测被Masked的标注。然后，我们可以使用“好”与“坏”是被Masked标注的预测概率来预测样本的标签。提示微调完全不需要训练，只需要存储一份模型参数。\"]},\"57\":{\"h\":\"6.2 P-Tuning v2\",\"t\":[\"P-Tuning v2并不是一个全新的方法，其事实上是将文本生成的Prefix-Tuning技术适配到自然语言理解任务中，其主要结果如下：1.仅精调0.1%参数量（固定语言模型(LM)参数），在330M到10B参数规模的语言模型上，均取得和Fine-Tuning相似的性能。2.将Prompt-Tuning技术首次拓展到序列标注等复杂自然语言理解(NLU)任务上。\",\"P-Tuning v2的关键所在就是引入了Prefix-Tuning。Prefix-Tuning最开始应用在自然语言生成(NLG)，由[Prefix, x, y]三部分构成，如图6-1。Prefix为前缀，\",\"图6-1 Prefix-Tuning示意图\",\"x为输入，y为输出。Prefix-Tuning将预训练LM参数固定，Prefix参数进行微调，它不仅只在Embedding层进行微调，而是在每一层都进行微调。\",\"P-Tuning v2实际上就是Prefix-Tuning，如图6-2(b)。在Prefix部分，每一层Transformer的Embedding输入都需要被微调，这一点是不同于P-Tuning的，在P-Tuning中，只有第一层Embedding才需要被微调。这样看来，P-Tuning v2可以微调的参数变多了，假设Prefix部分由50个Token组成，那么P-Tuning v2共有50*12=600个参数需要微调。可微调的参数多了，效果自然也会好一些。\",\"图6-2 P-Tuning与P-Tuning v2\",\"此外，P-Tuning v2还包括以下改进：1.移除了Reparamerization加速训练方式；2.采用了多任务学习优化：基于多任务数据集的Prompt进行预训练，然后再适配下游任务；3.舍弃了词汇Mapping的Verbalizer的使用，重新利用[CLS]和字符标签，跟全参数微调一样利用CLS或者Token的输出做NLU，以增强通用性，可以适配到序列标注任务。\",\"与GLM一样，P-Tuning v2也是清华大学发布的，那么自然GLM原生地支持P-Tuning v2，并且更推荐使用P-Tuning v2对GLM进行微调。上述我们介绍，对GLM-130B进行全参数微调，需要10台DGX A100，而如果改为使用P-Tuning v2进行微调，近似性能下可以将设备减少为1台DGX A100。而对GLM进行微调同样还可以使用LoRA，虽然所需设备与P-Tuning v2几乎一致，但是其性能并没有P-Tuning v2好。\"]},\"58\":{\"h\":\"参考文献\",\"t\":[\"[1] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems, pages 6000–6010.\",\"[2] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL 2019, pages 4171–4186.\",\"[3] Raffel Colin, Shazeer Noam, Roberts Adam, Lee Katherine, Narang Sharan, Matena Michael, Zhou Yanqi, Li Wei, and Liu Peter J.. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res. 21, 140 (2020), 1–67. http://jmlr.org/papers/v21/20-074.html.\",\"[4] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018a. Improving Language Understanding by Generative Pre-Training.\",\"[5] Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. 2021. All nlp tasks are generation tasks: A general pretraining framework. arXiv preprint arXiv:2103.10360.\",\"[6] Liu, X. et al. P-tuning: prompt tuning can be comparable to fine-tuning universally across scales and tasks. In Proc. the 60th Annual Meeting of the Association for Computational Linguistics. 2, 61–68 (2022).\",\"[7] Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. 2021. Gpt understands, too. arXiv:2103.10385.\",\"[8] Xiang Lisa Li and Percy Liang. 2021. Prefixtuning: Optimizing continuous prompts for generation. arXiv preprint arXiv:2101.00190.\",\"[9] Lester Brian, Al-Rfou Rami, and Constant Noah. 2021. The power of scale for parameter-efficient prompt tuning. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’21), Moens Marie-Francine, Huang Xuanjing, Specia Lucia, and Yih Scott Wen-tau (Eds.). Association for Computational Linguistics, 3045–3059\",\"[10] Hu, E.J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., Chen, W.: Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685 (2021)\",\"[11] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention model. In Empirical Methods in Natural Language Processing, 2016.\",\"[12] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A Robustly Optimized BERT Pretraining Approach. arXiv e-prints.\",\"[13] Hangbo Bao, Li Dong, Furu Wei, Wenhui Wang, Nan Yang,\\nXiaodong Liu, Yu Wang, Jianfeng Gao, Songhao Piao, Ming Zhou, and Hsiao-Wuen\\nHon. 2020. Unilmv2: Pseudo-masked language models for unified language model\\npre-training. In ICML 2020,volume 119, pages 642–652.\"]},\"59\":{\"h\":\"在Apple芯片上微调GLM模型\"},\"60\":{\"h\":\"参考资料\",\"t\":[\"https://github.com/THUDM/ChatGLM-6B/issues/977\\n该issue讨论了GLM在Apple芯片上微调的内容，但是最终似乎并没有成功。用CPU可以，但是用MPS会失败。\"]},\"61\":{\"h\":\"RetNet 论文笔记\",\"t\":[\"RETNET（全称Retentive Network），是微软研究院和清华大学推出的大语言模型(LLM)基本架构。从论文题目可以看出，RETNET在LLM上要优于Transformer，同时实现了平行训练、低耗费推理和良好表现三大特性。RETNET的理论来源是连接循环和注意力，提出了对序列模型的记忆力机制，这支持三个模式，即：平行、循环和分块循环(chunkwise recurrent)。平行意味着允许平行训练；循环意味着可以在O(1)耗费下推理，这可以在不牺牲性能的情况下提高解码吞吐量、降低延迟和减少GPU内存使用；分块循环意味着便于具有线性复杂度的高效长序列建模，每个chunk都可以并行编码。相关代码见https://aka.ms/retnet。\"]},\"62\":{\"h\":\"1 介绍\",\"t\":[\"现在，Transformer已然成为LLM的首选架构。当时提出Transformer架构是为了克服基于RNN的模型的无法并行训练的问题，然而，Transformer的并行训练是有代价的，即推理时比较低效，因为每个step的复杂度都是O(N)，并且要在内存中缓存key-value。这导致了部署基于Transformer的模型不是很友好，随着序列长度的增加，GPU的内存急剧增加，推理速度急速下降。\",\"因此，也有很多人在努力，希望提出一个在保持平行训练和良好表现的前提下，能够实现具有O(1)复杂度的推理的架构。这是很难的，即所谓“不可能三角”：\",\"RETNET则可以同时实现低成本推理、高效长序列建模、和Transformer相似的性能和并行训练。具体来说，作者提出了多尺度保留机制(multi-scale retention mechanism)代替多头注意力(multi-head attention)。它有三种计算范式，即并行、循环和块递归表示。首先，并行表示使训练并行性能够充分利用GPU设备。其次，递归表示能够在内存和计算方面实现有效的O (1)推断。可以显著降低部署成本和延迟。此外，该实现比较简单，没有键值缓存。第三，分块的循环表示可以执行有效的长序列建模。作者对每个本地块进行并行编码以提高计算速度，同时递归地编码全局块以节省GPU内存。\",\"语言模型的实验结果表明，RetNet在尺度曲线和上下文学习方面都具有竞争力。此外，RetNet的推理耗费是不受序列长度影响的。对于7B型号和8k序列长度，RetNet的解码速度比具有键值缓存的Transformer快8.4倍，节省了70%的内存。在训练过程中，RetNet还比使用了FlashAttention的Transformer节省了25-50%的内存，提升了7倍的速度。此外，RetNet的推理延迟对batch size不敏感，允许巨大的吞吐量。这些特性使RetNet可以成为大型语言模型的Transformer的强大继承者。\"]},\"63\":{\"h\":\"2 Retentive Networks\",\"t\":[\"RETNET由L个相同的block组成，与Transformer相似（residual connection, and pre-LayerNorm）。每个RETNET block包括两个模块：多尺度保留模块(multi-scale retention, MSR)和前馈网络(feed-forward network, FFN)模块。\",\"具体可表示为：给定一个输入序列x=x1​...x∣x∣​，RETNET通过自回归的方式编码这个序列。输入向量{xi​}i=1x​首先被转换为X0=[x1​,...x∣x∣​]∈R∣x∣×dmodel​（dmodel​是隐层维数），说白了应该是这样形状的矩阵：\",\"​x11​...xdmodel​,1​​.........​x1,∣x∣​...xdmodel​,∣x∣​​​\",\"然后，一层一层地计算：Xl=RetNetl​(Xl−1),l∈[1,L]。\"]},\"64\":{\"h\":\"2.1 Retention\",\"t\":[\"给定输入X∈R∣x∣×dmodel​，我们把它投影到一维函数v(n)=Xn​⋅wV​上，现在，通过状态sn​来把v(n)映射到o(n)上，为了简化，我们规定vn​=v(n),on​=o(n)。那么有：\",\"sn​=Asn−1​+KnT​vn​,\",\"其中A∈Rd×d,Kn​∈R1×d,KT表示K的转置\",\"on​=Qn​sn​=m=1∑n​Qn​An−mKmT​vm​,\",\"其中Qn​∈R1×d\",\"（上面两个等式称为(1)）\",\"【注：这个Q和K，应该指的是Query和Key，即Q K V中的】\",\"接下来，我们使用投影Qn​,Kn​进行内容感知：\",\"Q=XWQ​,K=XWK​\",\"（上面的等式称为(2)）\",\"这里的WQ​,WK​指的是可学习的矩阵。\",\"下面，我们把矩阵A对角化：A=Λ(γeiθ)Λ−1，这里的γ,θ∈Rd。这样我们可以得到An−m=Λ(γeiθ)n−mΛ−1。通过吸收Λ到WQ​,WK​中，我们可以重写(1)式：\",\"on​=m=1∑n​Qn​(γeiθ)n−mKmT​vm​\",\"=m=1∑n​(Qn​(γeiθ)n)(Km​(γeiθ)−m)Tvm​\",\"（上面的等式称为(3)）\",\"其中，Qn​(γeiθ)n,Km​(γeiθ)−m称为xPos，这是Transformer的相对位置embedding。我们进一步地把γ简化为一个标量，等式(3)变为：\",\"on​=m=1∑n​γn−m(Qn​einθ)(Km​eimθ)†vm​\",\"其中†表示共轭转置。该公式在训练实例中很容易被并行化。\",\"Retention的平行表示。Retention Layer结构图如下：\",\"Layer的定义如下：\",\"与自注意力类似，并行表示使能够有效地用GPU训练模型。\",\"伪代码如下：\",\"def ParallelRetention( q, # bsz ∗ num_head ∗ len ∗ qk_dim k, # bsz ∗ num_head ∗ len ∗ qk_dim v, # bsz ∗ num_head ∗ len ∗ v_dim decay_mask # num_head ∗ len ∗ len ): retention = q @ k.transpose(−1, −2) retention = retention ∗ decay_mask output = retention @ v output = group_norm(output) return output \",\"Retention的循环表示。如图b，所提出的机制也可以写成RNN，这有利于推理。对于第n个时间步长，我们递归地得到的输出为：\",\"伪代码如下：\",\"def RecurrentRetention( q, k, v, # bsz ∗ num_head ∗ len ∗ qkv_dim past_kv, # bsz ∗ num_head ∗ qk_dim ∗ v_dim decay # num_head ∗ 1 ∗ 1 ): current_kv = decay ∗ past_kv + k.unsqueeze (−1) ∗ v.unsqueeze(−2) output = torch.sum(q.unsqueeze(−1) ∗ current_kv, dim=−2) output = group_norm(output) return output, current_kv \",\"Retention的块循环表示。一种并行表示和循环表示的混合形式可用于加速训练，特别是对于长序列。我们将输入序列划分成块。在每个块中，我们遵循并行表示（公式(5))来进行计算。相反，交叉块信息按照循环表示方式传递（公式(6))。具体来说，设B表示块的长度。我们通过以下方法计算第i个块的Retention输出：\",\"伪代码如下：\",\"def ChunkwiseRetention( q, k, v, # bsz ∗ num_head ∗ chunk_size ∗ qkv_dim past_kv, # bsz ∗ num_head ∗ qk_dim ∗ v_dim decay_mask, # num_head ∗ chunk_size ∗ chunk_size chunk_decay, # num_head ∗ 1 ∗ 1 inner_decay, # num_head ∗ chunk_size ): retention = q @ k.transpose(−1, −2) retention = retention ∗ decay_mask inner_retention = retention @ v cross_retention = (q @ past_kv) ∗ inner_decay retention = inner_retention + cross_retention output = group_norm(retention) current_kv = chunk_decay ∗ past_kv + k.transpose(−1, −2) @ v return output, current_kv \"]},\"65\":{\"h\":\"2.2 Gated Multi-Scale Retention\",\"t\":[\"作者在每个layer中使用h=dmodel​/d，其中d表示头维度(head dimension)，不同的头使用不同的参数矩阵WQ​,WK​,WV​∈Rd×d，而且，多尺度保留(multi-scale retention, MSR)对不同的头指定了不同的γ。为了简单起见，我们在不同的层之间设置了相同的γ，并保持它们不变。此外，作者引入了倾斜门(swish gate)以增加retention layers的非线性。这样，给定X，我们定义layer为：\",\"Retention分数归一化。作者用GroupNorm的尺度不变性来提高retention layers的数值精度。具体来说，在GroupNorm中乘一个标量不会影响输出和反向梯度，即GroupNorm(α∗headi​)=GroupNorm(headi​)。作者在等式(5)中实现了三个归一化因子。第一，正规化QKT为QKT/d​；第二，将D变为D~nm​=Dnm​/∑i=1n​Dni​​；第三，让R表示retention scores R=QKT⨀D，正规化R为R~nm​=Rnm​/max(∣∑i=1n​Rni​∣,1)，这样，retention的输出变为Retention(X)=R~V 。由于尺度不变的性质，上述技巧在稳定正向和反向通道的数值流动的同时，并不影响最终的结果。\"]},\"66\":{\"h\":\"2.3 ❇️Retention网络的整体架构\",\"t\":[\"对于L层的Retention网络，作者堆叠多尺度缩放retention(multi-scale retention, MSR)和前馈网络(FFN)。输入序列{xi​}i=1∣x∣​通过word embedding层转为向量，然后用这个向量X0=[x1​,...x∣x∣​]∈R∣x∣×dmodel​（dmodel​是隐层维数）作为模型的输入，并且通过下列公式计算模型的输出：\",\"上述公式中，LN表示LayerNorm，FFN(X)=gelu(XW1​)W2​，W1​,W2​是参数矩阵。\",\"训练。在训练过程中，作者使用了平行模式（公式5）和块循环模式（公式7）。这两个模式可以利用GPU加速计算。特别地，分块训练对长序列训练特别有用，这在FLOPs和内存消耗方面都是比较好的。\",\"推理。推理过程中，作者使用了循环模式（公式6），这可以较好地拟合自回归解码。并且这可以在获得相同结果的同时，以O(1)复杂度执行。\"]},\"67\":{\"h\":\"3 实验\"},\"68\":{\"h\":\"封装、继承、多态\",\"t\":[\"参考\"]},\"69\":{\"h\":\"一、封装\",\"t\":[\"封装从字面上来理解就是包装的意思，专业点就是信息隐藏，是指利用抽象数据类型将数据和基于数据的操作封装在一起，使其构成一个不可分割的独立实体，数据被保护在抽象数据类型的内部，尽可能地隐藏内部的细节，只保留一些对外接口使之与外部发生联系。系统的其他对象只能通过包裹在数据外面的已经授权的操作来与这个封装的对象进行交流和交互。也就是说用户是无需知道对象内部的细节，但可以通过该对象对外的提供的接口来访问该对象。\"]},\"70\":{\"h\":\"使用封装的优点\",\"t\":[\"良好的封装能够减少耦合\",\"类内部的结构可以自由修改\",\"可以对成员进行更精准的控制\",\"隐藏信息，实现细节\"]},\"71\":{\"h\":\"二、继承\",\"t\":[\"继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承我们能够非常方便地复用以前的代码，能够大大的提高开发的效率。\",\"继承所描述的是“is-a”的关系，如果有两个对象A和B，若可以描述为“A是B”，则可以表示A继承B，其中B是被继承者称之为父类或者超类，A是继承者称之为子类或者派生类。\",\"实际上继承者是被继承者的特殊化，它除了拥有被继承者的特性外，还拥有自己独有得特性。例如猫有抓老鼠、爬树等其他动物没有的特性。同时在继承关系中，继承者完全可以替换被继承者，反之则不可以，例如我们可以说猫是动物，但不能说动物是猫就是这个道理，其实对于这个我们将其称之为“向上转型”。\",\"诚然，继承定义了类如何相互关联，共享特性。对于若干个相同或者相识的类，我们可以抽象出他们共有的行为或者属相并将其定义成一个父类或者超类，然后用这些类继承该父类，他们不仅可以拥有父类的属性、方法还可以定义自己独有的属性或者方法。\",\"子类拥有父类非private的属性和方法\",\"子类可以拥有自己的属性和方法，即子类可以对父类进行扩展\",\"子类可以用自己的方式实现父类的方法\"]},\"72\":{\"h\":\"谨慎继承\",\"t\":[\"继承有以下缺陷\",\"父类变，子类就必须变\",\"继承破坏了封装，对父类而言，它的实现对子类是完全透明的\",\"继承是一种强耦合的关系\"]},\"73\":{\"h\":\"三、多态\",\"t\":[\"所谓多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量倒底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。因为在程序运行时才确定具体的类，这样，不用修改源程序代码，就可以让引用变量绑定到各种不同的类实现上，从而导致该引用调用的具体方法随之改变，即不修改程序代码就可以改变程序运行时所绑定的具体代码，让程序可以选择多个运行状态，这就是多态性。\",\"所以对于多态我们可以总结如下：\",\"指向子类的父类引用由于向上转型了，它只能访问父类中拥有的方法和属性，而对于子类中存在而父类中不存在的方法，该引用是不能使用的，尽管是重载该方法。若子类重写了父类中的某些方法，在调用该些方法的时候，必定是使用子类中定义的这些方法（动态连接、动态调用）。\",\"对于面向对象而言，多态分为编译时多态和运行时多态。其中编辑时多态是静态的，主要是指方法的重载，它是根据参数列表的不同来区分不同的函数，通过编辑之后会变成两个不同的函数，在运行时谈不上多态。而运行时多态是动态的，它是通过动态绑定来实现的，也就是我们所说的多态性。\"]},\"74\":{\"h\":\"多态的实现条件\",\"t\":[\"Java实现多态有三个必要条件：继承、重写、向上转型。\",\"继承：在多态中必须存在有继承关系的子类和父类。\",\"重写：子类对父类中某些方法进行重新定义，在调用这些方法时就会调用子类的方法。\",\"向上转型：在多态中需要将子类的引用赋给父类对象，只有这样该引用才能够具备技能调用父类的方法和子类的方法。\"]},\"75\":{\"h\":\"实现多态的方法\",\"t\":[\"在Java中，有两种方法可以实现多态：继承和接口\",\"在接口的多态中，指向接口的引用必须是指定这实现了该接口的一个类的实例程序，在运行时，根据对象引用的实际类型来执行对应的方法。\"]},\"76\":{\"h\":\"实例分析\",\"t\":[\"public class A { public String show(D obj) { return (\\\"A and D\\\"); } public String show(A obj) { return (\\\"A and A\\\"); } } public class B extends A{ public String show(B obj){ return (\\\"B and B\\\"); } public String show(A obj){ return (\\\"B and A\\\"); } } public class C extends B{ } public class D extends B{ } public class Test { public static void main(String[] args) { A a1 = new A(); A a2 = new B(); B b = new B(); C c = new C(); D d = new D(); System.out.println(\\\"1--\\\" + a1.show(b)); System.out.println(\\\"2--\\\" + a1.show(c)); System.out.println(\\\"3--\\\" + a1.show(d)); System.out.println(\\\"4--\\\" + a2.show(b)); System.out.println(\\\"5--\\\" + a2.show(c)); System.out.println(\\\"6--\\\" + a2.show(d)); System.out.println(\\\"7--\\\" + b.show(b)); System.out.println(\\\"8--\\\" + b.show(c)); System.out.println(\\\"9--\\\" + b.show(d)); } } \",\"当超类对象引用变量引用子类对象时，被引用对象的类型而不是引用变量的类型决定了调用谁的成员方法，但是这个被调用的方法必须是在超类中定义过的，也就是说被子类覆盖的方法。（但是如果强制把超类转换成子类的话，就可以调用子类中新添加而超类没有的方法了。）\",\"在继承链中对象方法的调用存在一个优先级：this.show(O)、super.show(O)、this.show((super)O)、super.show((super)O)。\"]},\"77\":{\"h\":\"Android Studio ADB异常重启问题解决\",\"t\":[\"在新设备上安装了Android Studio，不过其自带的adb一直处于无法使用的状态，因为它处于无限重启状态，每隔几秒钟就会重启一次，导致无法持续连接Android设备。这段时间一直采用在Android Studio启动之前手动启动一个adb程序来临时解决，不过这种办法很不方便。\"]},\"78\":{\"h\":\"解决过程\",\"t\":[\"首先通过Android Studio的菜单->Help->Show Log in Explorer选项打开Android Studio的日志文件夹，找到idea.log文件并打开，发现日志中有关adb的日志如下：\",\"2023-10-10 14:27:43,703 [ 57399] WARN - #com.android.ddmlib - Cannot reach ADB server, attempting to reconnect. \",\"这个问题可以通过Android Studio的菜单->File->Settings，找到Build, Execution, Deployment选项中的Debugger，然后取消勾选Enable adb mDNS for wireless debugging来解决。\"]},\"79\":{\"h\":\"米窗所用技术备忘\",\"t\":[\"androidx.compose.foundation 看一下\"]},\"80\":{\"h\":\"Mi-Freeform 3.0 技术相关\",\"t\":[\"米窗之前的版本一直不够稳定，且使用的VirtualDisplay会有一些问题，比如会时常跳出小窗，且部分应用无法在小窗中启动。\",\"AOSP和部分国产ROM（如MIUI）采用的小窗方式是使用DecorCaptionView，将应用程序DecorView移至DecorCaptionView，从而实现小窗功能。该方式实现最佳，不过需要修改较多的源码，并且经过证明，修改后仍然有较多问题。\",\"米窗3采用了与VirtualDisplayAdapter/OverlayDisplayAdapter平行的自定义适配器：MiFreeformDisplayAdapter，将该类在Android启动时注入framework，为此，开发者做了以下努力：\",\"如何与该自定义适配器进行通信？\",\"在Android中，用户态程序获取系统服务的方式通常是走Binder，米窗3亦是如此。米窗3定义了一个专用系统服务MiFreeformService，该类继承自IMiFreeformService.Stub，该服务是一个Binder，我们可以通过ServiceManager#addService()方法，将其添加到系统服务列表。在此我们会发现，米窗3并不能顺利添加自定义系统服务。\",\"为什么不能顺利添加自定义系统服务？\",\"SELinux限制。在Linux/Android下，除了基础的权限限制，系统还引入了SELinux，SELinux对每个角色可以执行什么操作进行了严格限制，为此，我们需要给米窗3所需要执行的内容编写SELinux规则。Magisk可以在sepolicy.rule中编写自定义的SELinux规则，米窗3所需要的规则如下：\",\"allow untrusted_app default_android_service service_manager find allow system_server default_android_service service_manager add \",\"在添加完自定义服务后，为什么用户程序仍然无法发现？\",\"获取系统服务最终需要调用ServiceManager#getService()方法：\",\"public static IBinder getService(String name) { try { IBinder service = sCache.get(name); if (service != null) { return service; } else { return Binder.allowBlocking(rawGetService(name)); } } catch (RemoteException e) { Log.e(TAG, \\\"error in getService\\\", e); } return null; } \",\"因为我们的自定义系统服务不在sCache中，所以需要走else，不过因为未知原因，这里无法通过else获取到米窗3自定义的系统服务。所以米窗3采用了将自定义系统服务添加到sCache中的做法：\",\"ServiceManager.addService(\\\"mi_freeform\\\", this); Map<String, IBinder> cache = new ArrayMap<>(); cache.put(\\\"mi_freeform\\\", this); ServiceManager.initServiceCache(cache); \",\"如何获取到DisplayManagerService？\",\"实例化MiFreeformDisplayAdapter需要DisplayManagerService的一些字段，为此米窗3需要设法获取到DMS实例。获取DMS实例常用方式是通过Xposed hook，不过这会增加用户成本，为此，米窗3选择使用Riru/Zygisk方式进行获取。因为获取DMS后执行的操作均在Java层完成，所以米窗3选择了ZygoteLoader。该库额外提供了代理SystemService的功能，米窗3利用该功能，监听display系统服务的添加。 不过，display系统服务是一个Binder，并不是DMS，米窗3如何通过display系统服务获取到DMS呢？这里注意到，display系统服务是下面类的实例：\",\"class DisplayManagerService extends SystemService { final class BinderService extends IDisplayManager.Stub { ... } } \",\"我们可以直接通过ServiceManager获取到BinderService，不过注意到，该类是DisplayManagerService的内部类，而在日常使用时，内部类是可以直接访问外部类的变量的，这是因为内部类持有外部类的实例。我们可以通过反射的方式获取到外部类的实例(this$0表示顶层外部类引用)：\",\"// get out class field Field field = service.getClass().getDeclaredField(\\\"this$0\\\"); \",\"为什么通过反射获取DisplayManagerService时会抛出NoClassDefFoundError异常？\",\"当米窗3想要实例化上述字段来获取DMS实例时，发现会抛出NoClassDefFoundError异常。这是因为当前的ClassLoader中不包括/system/framework/services.jar路径，而DMS类在该jar包中。为此，我们需要使用BinderService的实例的ClassLoader来加载DMS类：\",\"// get out class field Field field = service.getClass().getDeclaredField(\\\"this$0\\\"); ClassLoader classLoader = service.getClass().getClassLoader(); assert classLoader != null; //for find dms, we need service`s classloader Class<?> dmsClass = classLoader.loadClass(\\\"com.android.server.display.DisplayManagerService\\\"); // get DisplayManagerService Object displayManagerService = field.get(service); \",\"此时，米窗3实例化了DMS，下面需要加载MiFreeformDisplayAdapter，为了让MDA与DMS可通过同一ClassLoader加载（否则仍然会抛出NoClassDefFoundError），米窗3做了以下操作：\",\"//add MiFreeformServer dex to path classLoader.getClass().getMethod(\\\"addDexPath\\\", String.class).invoke(classLoader, \\\"/system/framework/freeform.dex\\\"); Class<?> mfClass = classLoader.loadClass(\\\"com.android.server.display.MiFreeformDisplayAdapter\\\"); Object mf = mfClass.getConstructors()[0].newInstance(mSyncRoot, mContext, mHandler, mDisplayDeviceRepo, mUiHandler); \",\"用户程序可以通过以下方式获取到mi_freeform服务：\",\"val serviceManager = Class.forName(\\\"android.os.ServiceManager\\\") val binder = HiddenApiBypass.invoke(serviceManager, null, \\\"getService\\\", \\\"mi_freeform\\\") as IBinder Log.e(TAG, \\\"mf binder $binder\\\") val mfs = IMiFreeformService.Stub.asInterface(binder) \",\"此处使用了AndroidHiddenApiBypass，传统的getSystemService(\\\"mi_freeform\\\")无法获取，因为没有注册服务：\",\"//frameworks/base/core/java/android/app/SystemServiceRegistry.java // add for infrare scan registerService(Context.INFRARE_SCAN_SERVICE, InfrareScanManager.class, new CachedServiceFetcher<InfrareScanManager>() { @Override public InfrareScanManager createService(ContextImpl ctx) throws ServiceNotFoundException { IBinder b = ServiceManager.getService(Context.INFRARE_SCAN_SERVICE); IInfrareScanManager service = IInfrareScanManager.Stub.asInterface(b); Log.d(\\\"InfrareScanManager\\\",\\\" \\\"+b+\\\" \\\"+service); return new InfrareScanManager(ctx.getOuterContext(), service); }}); // add end \",\"HiddenApi冲突？\",\"在调用android.jar中提供，但是部分内容被隐藏的类时(如SurfaceControl)，我们很难处理，这里米窗3使用了HiddenApiRefinePlugin来处理，将系统类起一个别名。\",\"在创建完DisplayDevice后，无法立即获得LogicalDisplay从而拿到displayId？\",\"调用DisplayDeviceRepository#addListener()添加监听，在添加成功后给Binder回调即可。\",\"给远程服务设置Surface不生效？\",\"编写AIDL文件时，需要给Surface设置为in，而非inout。如：\",\"void createFreeform(String name, IMiFreeformDisplayCallback callback, int width, int height, int densityDpi, boolean secure, boolean ownContentOnly, boolean shouldShowSystemDecorations, in Surface surface, float refreshRate, long presentationDeadlineNanos) = 1; void resizeFreeform(IBinder appToken, int width, int height, int densityDpi) = 2; \"]},\"81\":{\"h\":\"5.多数元素\",\"t\":[\"这是一道数组题，不过我愿意分类为哈希表题。\",\"给定一个大小为 n 的数组 nums ，返回其中的多数元素。多数元素是指在数组中出现次数 大于⌊ n/2 ⌋ 的元素。\",\"你可以假设数组是非空的，并且给定的数组总是存在多数元素。\",\"示例 1：\",\"输入：nums = [3,2,3] 输出：3\",\"示例 2：\",\"输入：nums = [2,2,1,1,1,2,2] 输出：2 \",\"提示：* n == nums.length\",\"1 <= n <= 5 * 10<sup>4</sup>\",\"-10<sup>9</sup> <= nums[i] <= 10<sup>9</sup>\",\"进阶： 尝试设计时间复杂度为 O(n)、空间复杂度为 O(1) 的算法解决此问题。\"]},\"82\":{\"h\":\"解答\",\"t\":[\"这道题想要做出来并不复杂，只需对其排序，然后取length/2位置即可，但是如果尝试使用O(n)时间复杂度，O(1)空间复杂度来解答，则需要考虑到哈希表。\",\"哈希表操作并不难，只需要考虑到即可。\"]},\"83\":{\"h\":\"3. 删除有序数组中的重复项\",\"t\":[\"该题来自力扣26题，注意是双指针题就可以了。\",\"给你一个 非严格递增排列 的数组 nums ，请你** 原地** 删除重复出现的元素，使每个元素 只出现一次 ，返回删除后数组的新长度。元素的 相对顺序 应该保持 一致 。然后返回 nums 中唯一元素的个数。\",\"考虑 nums 的唯一元素的数量为 k ，你需要做以下事情确保你的题解可以被通过：\",\"更改数组 nums ，使 nums 的前 k 个元素包含唯一元素，并按照它们最初在 nums 中出现的顺序排列。nums 的其余元素与 nums 的大小不重要。\",\"返回 k 。\",\"判题标准:\",\"系统会用下面的代码来测试你的题解:\",\"int[] nums = [...]; // 输入数组 int[] expectedNums = [...]; // 长度正确的期望答案 int k = removeDuplicates(nums); // 调用 assert k == expectedNums.length; for (int i = 0; i < k; i++) { assert nums[i] == expectedNums[i]; } \",\"如果所有断言都通过，那么您的题解将被 通过 。\",\"示例 1：\",\"输入：nums = [1,1,2] 输出：2, nums = [1,2,_] 解释：函数应该返回新的长度 2 ，并且原数组 nums 的前两个元素被修改为 1, 2 。不需要考虑数组中超出新长度后面的元素。 \",\"示例 2：\",\"输入：nums = [0,0,1,1,1,2,2,3,3,4] 输出：5, nums = [0,1,2,3,4] 解释：函数应该返回新的长度 5 ， 并且原数组 nums 的前五个元素被修改为 0, 1, 2, 3, 4 。不需要考虑数组中超出新长度后面的元素。 \",\"提示：\",\"1 <= nums.length <= 3 * 10<sup>4</sup>\",\"-10<sup>4</sup> <= nums[i] <= 10<sup>4</sup>\",\"nums 已按 非严格递增 排列\"]},\"84\":{\"h\":\"2. 移除元素\",\"t\":[\"该题来自力扣27题\",\"给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。\",\"不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组 。\",\"元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。\",\"说明:\",\"为什么返回数值是整数，但输出的答案是数组呢?\",\"请注意，输入数组是以 「引用」 方式传递的，这意味着在函数里修改输入数组对于调用者是可见的。\",\"你可以想象内部操作如下:\",\"// nums 是以“引用”方式传递的。也就是说，不对实参作任何拷贝 int len = removeElement(nums, val); // 在函数里修改输入数组对于调用者是可见的。 // 根据你的函数返回的长度, 它会打印出数组中 该长度范围内 的所有元素。 for (int i = 0; i < len; i++) { print(nums[i]); } \",\"示例 1：\",\"输入：nums = [3,2,2,3], val = 3 输出：2, nums = [2,2] 解释：函数应该返回新的长度 2, 并且 nums中的前两个元素均为 2。你不需要考虑数组中超出新长度后面的元素。例如，函数返回的新长度为 2 ，而 nums = [2,2,3,3] 或 nums = [2,2,0,0]，也会被视作正确答案。 \",\"示例 2：\",\"输入：nums = [0,1,2,2,3,0,4,2], val = 2 输出：5, nums = [0,1,3,0,4] 解释：函数应该返回新的长度 5, 并且 nums 中的前五个元素为 0, 1, 3, 0, 4。注意这五个元素可为任意顺序。你不需要考虑数组中超出新长度后面的元素。 \",\"提示：\",\"0 <= nums.length <= 100\",\"0 <= nums[i] <= 50\",\"0 <= val <= 100\",\"要注意这是一道双指针题目，简单题没啥说的\"]},\"85\":{\"h\":\"4.删除有序数组中的重复项 II\",\"t\":[\"这道题来自力扣80题，这道题其实做完力扣26题后并不难，就是一个双指针问题，但是如果从头开始看，可能觉得稍微困难。\",\"需要具备双指针的思想，逻辑和26题完全一样。\",\"给你一个有序数组 nums ，请你** 原地** 删除重复出现的元素，使得出现次数超过两次的元素只出现两次 ，返回删除后数组的新长度。\",\"不要使用额外的数组空间，你必须在 **原地 修改输入数组 **并在使用 O(1) 额外空间的条件下完成。\",\"说明：\",\"为什么返回数值是整数，但输出的答案是数组呢？\",\"请注意，输入数组是以 「引用」 方式传递的，这意味着在函数里修改输入数组对于调用者是可见的。\",\"你可以想象内部操作如下:\",\"// nums 是以“引用”方式传递的。也就是说，不对实参做任何拷贝 int len = removeDuplicates(nums); // 在函数里修改输入数组对于调用者是可见的。 // 根据你的函数返回的长度, 它会打印出数组中 该长度范围内 的所有元素。 for (int i = 0; i < len; i++) { print(nums[i]); } \",\"示例 1：\",\"输入：nums = [1,1,1,2,2,3] 输出：5, nums = [1,1,2,2,3] 解释：函数应返回新长度 length = 5, 并且原数组的前五个元素被修改为 1, 1, 2, 2, 3。 不需要考虑数组中超出新长度后面的元素。 \",\"示例 2：\",\"输入：nums = [0,0,1,1,1,1,2,3,3] 输出：7, nums = [0,0,1,1,2,3,3] 解释：函数应返回新长度 length = 7, 并且原数组的前五个元素被修改为 0, 0, 1, 1, 2, 3, 3。不需要考虑数组中超出新长度后面的元素。 \",\"提示：\",\"1 <= nums.length <= 3 * 10<sup>4</sup>\",\"-10<sup>4</sup> <= nums[i] <= 10<sup>4</sup>\",\"nums 已按升序排列\"]},\"86\":{\"h\":\"1. 合并两个有序数组（System#arraycopy()介绍)\",\"t\":[\"该题来自力扣第88题。\"]},\"87\":{\"h\":\"题目描述\",\"t\":[\"给你两个按 非递减顺序 排列的整数数组 nums1 和 nums2，另有两个整数 m 和 n ，分别表示 nums1 和 nums2 中的元素数目。\",\"请你 合并nums2 到 nums1 中，使合并后的数组同样按 非递减顺序 排列。\",\"注意： 最终，合并后数组不应由函数返回，而是存储在数组 nums1 中。为了应对这种情况，nums1 的初始长度为 m + n，其中前 m 个元素表示应合并的元素，后 n 个元素为 0 ，应忽略。nums2 的长度为 n 。\",\"示例 1：\",\"输入：nums1 = [1,2,3,0,0,0], m = 3, nums2 = [2,5,6], n = 3 输出：[1,2,2,3,5,6] 解释：需要合并 [1,2,3] 和 [2,5,6] 。 合并结果是 [1,2,2,3,5,6] ，其中斜体加粗标注的为 nums1 中的元素。 \",\"示例 2：\",\"输入：nums1 = [1], m = 1, nums2 = [], n = 0 输出：[1] 解释：需要合并 [1] 和 [] 。 合并结果是 [1] 。 \",\"示例 3：\",\"输入：nums1 = [0], m = 0, nums2 = [1], n = 1 输出：[1] 解释：需要合并的数组是 [] 和 [1] 。 合并结果是 [1] 。 注意，因为 m = 0 ，所以 nums1 中没有元素。nums1 中仅存的 0 仅仅是为了确保合并结果可以顺利存放到 nums1 中。 \",\"提示：\",\"nums1.length == m + n\",\"nums2.length == n\",\"0 <= m, n <= 200\",\"1 <= m + n <= 200\",\"-10<sup>9</sup> <= nums1[i], nums2[j] <= 10<sup>9</sup>\",\"进阶： 你可以设计实现一个时间复杂度为 O(m + n) 的算法解决此问题吗？\"]},\"88\":{\"h\":\"解答\",\"t\":[\"这是一道比较简单的双指针问题。需要注意的是边界问题处理。比如：当nums1处理完之后，如果nums2中仍然还有数据没有处理怎么办？\",\"此外，为了减少处理时间耗费，我们可以针对特殊情况--nums1的实际数组长度为0时，只需要将nums2复制到nums1即可，而无需逐一比较。为了实现快速复制，我们可以调用System#arraycopy()方法。\"]},\"89\":{\"h\":\"关于System#arraycopy()的介绍\",\"t\":[\"该方法位于java.lang包下的System类中，该方法定义如下：\",\"@IntrinsicCandidate public static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length); \",\"可以看到这是一个native方法，效率自然会高一些。不过这个native方法有些特殊，我们稍后介绍。这个方法共接收5个参数：\",\"src：源数组\",\"srcPos：从源数组的哪个位置开始复制\",\"dest：要复制到的数组\",\"destPos：从要复制的数组哪里开始复制\",\"length：复制的长度\",\"使用方法比较简单，比如，现在有两个数组int[] nums1 = {1, 2, 3, 4}, int[] nums2 = {0, 0, 0, 0}。我们现在想要将nums1的内容复制到nums2中，只需要调用 System.arraycopy(nums1, 0, nums2, 0, nums1.length) 即可。\",\"可以看到该方法有一个注解@IntrinsicCandidate（JDK17)，JDK介绍其用于HotSpot VM，这个注解可以标记（但是不一定）这个方法属于HotSpot VM内部，而属于HotSpot VM内部的方法，HotSpot VM会对其进行一些优化，比如手动编写汇编或者手动编写编译器中间语言来替换该方法的实现。\",\"所以，虽然这里被声明为native方法，但是它跟JDK中其他的native方法实现地方不同。这个注解标记的方法会在JVM内部实现，而其他的会在JDK库中实现。在调用方面，由于直接调用JVM内部实现，不走常规的JNI lookup，所以也省了一些开销。\",\"该算法题的实现如下：\",\"class Solution { public void merge(int[] nums1, int m, int[] nums2, int n) { if (m == 0) { System.arraycopy(nums2, 0, nums1, 0, n); return; } int i = m + n - 1; while (m > 0 && n > 0) { if (nums1[m - 1] > nums2[n - 1]) { nums1[i] = nums1[m - 1]; --m; } else { nums1[i] = nums2[n - 1]; --n; } --i; } while (n > 0) { nums1[i--] = nums2[--n]; } } } \"]},\"90\":{\"h\":\"Llm\"},\"91\":{\"h\":\"\"},\"92\":{\"h\":\"Java\"},\"93\":{\"h\":\"Android\"},\"94\":{\"h\":\"Leetcode 150 Shuzu\"},\"95\":{\"h\":\"Leetcode\"}},\"dirtCount\":0,\"index\":[[\"复制的长度\",{\"1\":{\"89\":1}}],[\"复杂度执行\",{\"1\":{\"66\":1}}],[\"复杂度的推理的架构\",{\"1\":{\"62\":1}}],[\"源数组\",{\"1\":{\"89\":1}}],[\"效率自然会高一些\",{\"1\":{\"89\":1}}],[\"效果自然也会好一些\",{\"1\":{\"57\":1}}],[\"效果比较好\",{\"1\":{\"47\":1}}],[\"关于system\",{\"0\":{\"89\":1}}],[\"仅仅是为了确保合并结果可以顺利存放到\",{\"1\":{\"87\":1}}],[\"仅精调0\",{\"1\":{\"57\":1}}],[\"应忽略\",{\"1\":{\"87\":1}}],[\"应该保持\",{\"1\":{\"83\":1}}],[\"应该指的是query和key\",{\"1\":{\"64\":1}}],[\"应该是效果比较不错的一个模型\",{\"1\":{\"51\":1}}],[\"应该贯穿在整个对话中\",{\"1\":{\"15\":1}}],[\"到\",{\"1\":{\"87\":1}}],[\"合并结果是\",{\"1\":{\"87\":3}}],[\"合并后数组不应由函数返回\",{\"1\":{\"87\":1}}],[\"合并nums2\",{\"1\":{\"87\":1}}],[\"合并两个有序数组\",{\"0\":{\"86\":1}}],[\"分别表示\",{\"1\":{\"87\":1}}],[\"分块训练对长序列训练特别有用\",{\"1\":{\"66\":1}}],[\"分块的循环表示可以执行有效的长序列建模\",{\"1\":{\"62\":1}}],[\"分块循环意味着便于具有线性复杂度的高效长序列建模\",{\"1\":{\"61\":1}}],[\"另有两个整数\",{\"1\":{\"87\":1}}],[\"另外的的情况是b为语料中其它的随机句子\",{\"1\":{\"47\":1}}],[\"题目描述\",{\"0\":{\"87\":1}}],[\"逻辑和26题完全一样\",{\"1\":{\"85\":1}}],[\"函数应返回新长度\",{\"1\":{\"85\":2}}],[\"函数应该返回新的长度\",{\"1\":{\"83\":2,\"84\":2}}],[\"函数返回的新长度为\",{\"1\":{\"84\":1}}],[\"方式传递的\",{\"1\":{\"84\":2,\"85\":2}}],[\"方法\",{\"1\":{\"80\":2,\"88\":1}}],[\"方法还可以定义自己独有的属性或者方法\",{\"1\":{\"71\":1}}],[\"引用\",{\"1\":{\"84\":2,\"85\":2}}],[\"引入序列转换模型\",{\"1\":{\"41\":1}}],[\"修改输入数组\",{\"1\":{\"84\":1,\"85\":1}}],[\"修改后仍然有较多问题\",{\"1\":{\"80\":1}}],[\"移除所有数值等于\",{\"1\":{\"84\":1}}],[\"移除元素\",{\"0\":{\"84\":1}}],[\"移除了reparamerization加速训练方式\",{\"1\":{\"57\":1}}],[\"排列的整数数组\",{\"1\":{\"87\":1}}],[\"排列\",{\"1\":{\"83\":1,\"87\":1}}],[\"已按升序排列\",{\"1\":{\"85\":1}}],[\"已按\",{\"1\":{\"83\":1}}],[\"已经是广为应用的做法\",{\"1\":{\"43\":1}}],[\"<\",{\"1\":{\"83\":1,\"84\":1,\"85\":1}}],[\"<=\",{\"1\":{\"81\":4,\"83\":4,\"84\":6,\"85\":4,\"87\":6}}],[\"调用\",{\"1\":{\"83\":1}}],[\"调用displaydevicerepository\",{\"1\":{\"80\":1}}],[\"长度正确的期望答案\",{\"1\":{\"83\":1}}],[\"判题标准\",{\"1\":{\"83\":1}}],[\"个元素为\",{\"1\":{\"87\":1}}],[\"个元素表示应合并的元素\",{\"1\":{\"87\":1}}],[\"个元素包含唯一元素\",{\"1\":{\"83\":1}}],[\"个人猜测\",{\"1\":{\"52\":1}}],[\"考虑\",{\"1\":{\"83\":1}}],[\"元素的顺序可以改变\",{\"1\":{\"84\":1}}],[\"元素的\",{\"1\":{\"83\":1}}],[\"元数据和管道版本控制\",{\"1\":{\"31\":1}}],[\"返回\",{\"1\":{\"83\":1}}],[\"返回删除后数组的新长度\",{\"1\":{\"83\":1,\"85\":1}}],[\"返回其中的多数元素\",{\"1\":{\"81\":1}}],[\"删除重复出现的元素\",{\"1\":{\"83\":1,\"85\":1}}],[\"删除有序数组中的重复项\",{\"0\":{\"83\":1,\"85\":1}}],[\"原地\",{\"1\":{\"83\":1,\"84\":2,\"85\":2}}],[\"请你\",{\"1\":{\"83\":1,\"85\":1,\"87\":1}}],[\"请注意\",{\"1\":{\"14\":1,\"84\":1,\"85\":1}}],[\"非递减顺序\",{\"1\":{\"87\":2}}],[\"非严格递增\",{\"1\":{\"83\":1}}],[\"非严格递增排列\",{\"1\":{\"83\":1}}],[\"非常详细地介绍了llama\",{\"1\":{\"0\":1}}],[\"哈希表操作并不难\",{\"1\":{\"82\":1}}],[\"空间复杂度来解答\",{\"1\":{\"82\":1}}],[\"空间复杂度为\",{\"1\":{\"81\":1}}],[\"时间复杂度\",{\"1\":{\"82\":1}}],[\"尝试设计时间复杂度为\",{\"1\":{\"81\":1}}],[\"进阶\",{\"1\":{\"81\":1,\"87\":1}}],[\"进行了比较\",{\"1\":{\"18\":1}}],[\"示例\",{\"1\":{\"81\":2,\"83\":2,\"84\":2,\"85\":2,\"87\":3}}],[\"需要注意的是边界问题处理\",{\"1\":{\"88\":1}}],[\"需要合并的数组是\",{\"1\":{\"87\":1}}],[\"需要合并\",{\"1\":{\"87\":2}}],[\"需要具备双指针的思想\",{\"1\":{\"85\":1}}],[\"需要给surface设置为in\",{\"1\":{\"80\":1}}],[\"需要10台dgx\",{\"1\":{\"55\":1,\"57\":1}}],[\"编写aidl文件时\",{\"1\":{\"80\":1}}],[\"编码\",{\"1\":{\"51\":1}}],[\"添加监听\",{\"1\":{\"80\":1}}],[\"传统的getsystemservice\",{\"1\":{\"80\":1}}],[\"$binder\",{\"1\":{\"80\":1}}],[\"否则仍然会抛出noclassdeffounderror\",{\"1\":{\"80\":1}}],[\"此处使用了androidhiddenapibypass\",{\"1\":{\"80\":1}}],[\"此时\",{\"1\":{\"80\":1}}],[\"此外\",{\"1\":{\"22\":1,\"27\":1,\"28\":1,\"33\":1,\"35\":1,\"36\":2,\"43\":1,\"46\":1,\"57\":1,\"62\":3,\"65\":1,\"88\":1}}],[\"内部类是可以直接访问外部类的变量的\",{\"1\":{\"80\":1}}],[\"监听display系统服务的添加\",{\"1\":{\"80\":1}}],[\"监控来自已部署ml服务的数据和模型指标\",{\"1\":{\"34\":1}}],[\"监控\",{\"0\":{\"23\":1,\"27\":1,\"34\":1},\"1\":{\"23\":1,\"27\":1,\"34\":1}}],[\"获取dms实例常用方式是通过xposed\",{\"1\":{\"80\":1}}],[\"获取系统服务最终需要调用servicemanager\",{\"1\":{\"80\":1}}],[\"获得最高奖励分数的样本被视为新的金标准\",{\"1\":{\"14\":1}}],[\"除了基础的权限限制\",{\"1\":{\"80\":1}}],[\"除了给参与者一个被迫的选择之外\",{\"1\":{\"12\":1}}],[\"且部分应用无法在小窗中启动\",{\"1\":{\"80\":1}}],[\"且使用的virtualdisplay会有一些问题\",{\"1\":{\"80\":1}}],[\"米窗3做了以下操作\",{\"1\":{\"80\":1}}],[\"米窗3实例化了dms\",{\"1\":{\"80\":1}}],[\"米窗3如何通过display系统服务获取到dms呢\",{\"1\":{\"80\":1}}],[\"米窗3利用该功能\",{\"1\":{\"80\":1}}],[\"米窗3选择使用riru\",{\"1\":{\"80\":1}}],[\"米窗3所需要的规则如下\",{\"1\":{\"80\":1}}],[\"米窗3并不能顺利添加自定义系统服务\",{\"1\":{\"80\":1}}],[\"米窗3定义了一个专用系统服务mifreeformservice\",{\"1\":{\"80\":1}}],[\"米窗3亦是如此\",{\"1\":{\"80\":1}}],[\"米窗3采用了与virtualdisplayadapter\",{\"1\":{\"80\":1}}],[\"米窗之前的版本一直不够稳定\",{\"1\":{\"80\":1}}],[\"米窗所用技术备忘\",{\"0\":{\"79\":1}}],[\"技术相关\",{\"0\":{\"80\":1}}],[\"看一下\",{\"1\":{\"79\":1}}],[\"看哪个更符合标准\",{\"1\":{\"12\":1}}],[\"找到build\",{\"1\":{\"78\":1}}],[\"找到idea\",{\"1\":{\"78\":1}}],[\"发现会抛出noclassdeffounderror异常\",{\"1\":{\"80\":1}}],[\"发现日志中有关adb的日志如下\",{\"1\":{\"78\":1}}],[\"发现训练时间过长会导致过度拟合\",{\"1\":{\"13\":1}}],[\"导致无法持续连接android设备\",{\"1\":{\"77\":1}}],[\"导致序列转换模型的效率不高\",{\"1\":{\"41\":1}}],[\"根据你的函数返回的长度\",{\"1\":{\"84\":1,\"85\":1}}],[\"根据对象引用的实际类型来执行对应的方法\",{\"1\":{\"75\":1}}],[\"根据经验\",{\"1\":{\"47\":1}}],[\"指向接口的引用必须是指定这实现了该接口的一个类的实例程序\",{\"1\":{\"75\":1}}],[\"指向子类的父类引用由于向上转型了\",{\"1\":{\"73\":1}}],[\"重写\",{\"1\":{\"74\":2}}],[\"重新利用\",{\"1\":{\"57\":1}}],[\"重新调整了ln和残差连接的顺序\",{\"1\":{\"54\":1}}],[\"动态调用\",{\"1\":{\"73\":1}}],[\"动态连接\",{\"1\":{\"73\":1}}],[\"必定是使用子类中定义的这些方法\",{\"1\":{\"73\":1}}],[\"必须在由程序运行期间才能决定\",{\"1\":{\"73\":1}}],[\"若子类重写了父类中的某些方法\",{\"1\":{\"73\":1}}],[\"若可以描述为\",{\"1\":{\"71\":1}}],[\"父类变\",{\"1\":{\"72\":1}}],[\"谨慎继承\",{\"0\":{\"72\":1}}],[\"子类对父类中某些方法进行重新定义\",{\"1\":{\"74\":1}}],[\"子类就必须变\",{\"1\":{\"72\":1}}],[\"子类可以用自己的方式实现父类的方法\",{\"1\":{\"71\":1}}],[\"子类可以拥有自己的属性和方法\",{\"1\":{\"71\":1}}],[\"子类拥有父类非private的属性和方法\",{\"1\":{\"71\":1}}],[\"他们不仅可以拥有父类的属性\",{\"1\":{\"71\":1}}],[\"诚然\",{\"1\":{\"71\":1}}],[\"向上转型\",{\"1\":{\"71\":1,\"74\":2}}],[\"反之则不可以\",{\"1\":{\"71\":1}}],[\"反复打磨多年才得以形成的\",{\"1\":{\"38\":1}}],[\"爬树等其他动物没有的特性\",{\"1\":{\"71\":1}}],[\"则需要考虑到哈希表\",{\"1\":{\"82\":1}}],[\"则可以表示a继承b\",{\"1\":{\"71\":1}}],[\"则应该找寻更为合适的框架或者平台\",{\"1\":{\"22\":1}}],[\"新类的定义可以增加新的数据或新的功能\",{\"1\":{\"71\":1}}],[\"隐藏信息\",{\"1\":{\"70\":1}}],[\"良好的封装能够减少耦合\",{\"1\":{\"70\":1}}],[\"尽可能地隐藏内部的细节\",{\"1\":{\"69\":1}}],[\"尽管是重载该方法\",{\"1\":{\"73\":1}}],[\"尽管我们最新的llama\",{\"1\":{\"17\":1}}],[\"尽管前面提到了使用meta的奖励作为逐点衡量标准的相关性\",{\"1\":{\"17\":1}}],[\"专业点就是信息隐藏\",{\"1\":{\"69\":1}}],[\"专为端到端机器学习pipeline而构建\",{\"1\":{\"28\":1}}],[\"继承和接口\",{\"1\":{\"75\":1}}],[\"继承是一种强耦合的关系\",{\"1\":{\"72\":1}}],[\"继承是使用已存在的类的定义作为基础建立新类的技术\",{\"1\":{\"71\":1}}],[\"继承破坏了封装\",{\"1\":{\"72\":1}}],[\"继承有以下缺陷\",{\"1\":{\"72\":1}}],[\"继承定义了类如何相互关联\",{\"1\":{\"71\":1}}],[\"继承者完全可以替换被继承者\",{\"1\":{\"71\":1}}],[\"继承所描述的是\",{\"1\":{\"71\":1}}],[\"继承\",{\"0\":{\"68\":1,\"71\":1},\"1\":{\"74\":2}}],[\"封装从字面上来理解就是包装的意思\",{\"1\":{\"69\":1}}],[\"封装\",{\"0\":{\"68\":1,\"69\":1}}],[\"特别地\",{\"1\":{\"66\":1}}],[\"特别是对于长序列\",{\"1\":{\"64\":1}}],[\"特别是gpt\",{\"1\":{\"48\":1}}],[\"特别是微调的能力\",{\"1\":{\"44\":1}}],[\"特别是\",{\"1\":{\"18\":1}}],[\"❇️retention网络的整体架构\",{\"0\":{\"66\":1}}],[\"∣∑i=1n​rni​∣\",{\"1\":{\"65\":1}}],[\"∣x∣​​​\",{\"1\":{\"63\":1}}],[\"∣x∣​\",{\"1\":{\"63\":1}}],[\"∑i=1n​dni​​\",{\"1\":{\"65\":1}}],[\"α∗headi​\",{\"1\":{\"65\":1}}],[\"交叉块信息按照循环表示方式传递\",{\"1\":{\"64\":1}}],[\"交互式数据漂移\",{\"1\":{\"34\":1}}],[\"交互式仪表板\",{\"1\":{\"34\":1}}],[\"+service\",{\"1\":{\"80\":1}}],[\"+b+\",{\"1\":{\"80\":1}}],[\"+\",{\"1\":{\"64\":3,\"76\":9,\"87\":4,\"89\":1}}],[\"−2\",{\"1\":{\"64\":4}}],[\"−1\",{\"1\":{\"64\":5}}],[\"−m称为xpos\",{\"1\":{\"64\":1}}],[\"−m\",{\"1\":{\"64\":1}}],[\"∗\",{\"1\":{\"64\":37}}],[\"伪代码如下\",{\"1\":{\"64\":3}}],[\"变为\",{\"1\":{\"64\":1}}],[\"变体\",{\"1\":{\"5\":1}}],[\"等式\",{\"1\":{\"64\":1}}],[\"等部分参数微调方法\",{\"1\":{\"39\":1}}],[\"式\",{\"1\":{\"64\":1}}],[\"λ−1\",{\"1\":{\"64\":1}}],[\"γeiθ\",{\"1\":{\"64\":7}}],[\"注意\",{\"1\":{\"87\":2}}],[\"注意这五个元素可为任意顺序\",{\"1\":{\"84\":1}}],[\"注意是双指针题就可以了\",{\"1\":{\"83\":1}}],[\"注意力集中在上述公式中source的内部元素\",{\"1\":{\"42\":1}}],[\"注意力机制体现在模型中是多头注意力机制\",{\"1\":{\"45\":1}}],[\"注意力机制公式如下\",{\"1\":{\"42\":1}}],[\"注意力机制就是给定一个query\",{\"1\":{\"42\":1}}],[\"注意力机制\",{\"0\":{\"42\":1},\"1\":{\"42\":2}}],[\"注\",{\"1\":{\"64\":1}}],[\"映射到o\",{\"1\":{\"64\":1}}],[\"​x1\",{\"1\":{\"63\":1}}],[\"​x11​\",{\"1\":{\"63\":1}}],[\"说明\",{\"1\":{\"84\":1,\"85\":1}}],[\"说白了应该是这样形状的矩阵\",{\"1\":{\"63\":1}}],[\"说到gpt\",{\"1\":{\"50\":1}}],[\"∈r∣x∣×dmodel​\",{\"1\":{\"63\":1,\"66\":1}}],[\"输出\",{\"1\":{\"81\":2,\"83\":2,\"84\":2,\"85\":2,\"87\":3}}],[\"输出进行向量化\",{\"1\":{\"43\":1}}],[\"输入数组是以\",{\"1\":{\"84\":1,\"85\":1}}],[\"输入数组\",{\"1\":{\"83\":1}}],[\"输入\",{\"1\":{\"81\":2,\"83\":2,\"84\":2,\"85\":2,\"87\":3}}],[\"输入序列\",{\"1\":{\"66\":1}}],[\"输入向量\",{\"1\":{\"63\":1}}],[\"模块\",{\"1\":{\"63\":1}}],[\"模型和自编码\",{\"1\":{\"44\":1}}],[\"模型应该是双向的才好\",{\"1\":{\"44\":1}}],[\"模型应该能毫不费力地泛化更长的句子\",{\"1\":{\"43\":1}}],[\"模型就失去了\",{\"1\":{\"43\":1}}],[\"模型需要做的是通过已经有的信息来预测下一个位置会出现什么\",{\"1\":{\"43\":1}}],[\"模型一般包括一个编码器\",{\"1\":{\"41\":1}}],[\"模型监控\",{\"1\":{\"35\":1}}],[\"模型性能和目标虚拟化\",{\"1\":{\"34\":1}}],[\"模型部署与管理\",{\"0\":{\"32\":1,\"33\":1},\"1\":{\"32\":1,\"33\":1}}],[\"模型指标\",{\"1\":{\"31\":1}}],[\"模型等进行版本控制\",{\"1\":{\"31\":1}}],[\"模型\",{\"1\":{\"27\":1,\"31\":1,\"44\":1}}],[\"模型再部署\",{\"0\":{\"23\":1},\"1\":{\"23\":1}}],[\"模型训练和模型服务\",{\"1\":{\"20\":1}}],[\"模型的进展\",{\"1\":{\"17\":1}}],[\"模型中的kv缓存大小相关的内存成本显著增长\",{\"1\":{\"5\":1}}],[\"允许巨大的吞吐量\",{\"1\":{\"62\":1}}],[\"节省了70\",{\"1\":{\"62\":1}}],[\"没有键值缓存\",{\"1\":{\"62\":1}}],[\"没有看出具体用途\",{\"1\":{\"30\":1}}],[\"推理过程中\",{\"1\":{\"66\":1}}],[\"推理\",{\"1\":{\"66\":1}}],[\"推理速度急速下降\",{\"1\":{\"62\":1}}],[\"推断\",{\"1\":{\"62\":1}}],[\"递归表示能够在内存和计算方面实现有效的o\",{\"1\":{\"62\":1}}],[\"代替多头注意力\",{\"1\":{\"62\":1}}],[\"高效长序列建模\",{\"1\":{\"62\":1}}],[\"高质量指令微调数据\",{\"1\":{\"10\":1}}],[\"能够大大的提高开发的效率\",{\"1\":{\"71\":1}}],[\"能够实现具有o\",{\"1\":{\"62\":1}}],[\"能力进一步增强\",{\"1\":{\"50\":1}}],[\"希望提出一个在保持平行训练和良好表现的前提下\",{\"1\":{\"62\":1}}],[\"现在有两个数组int\",{\"1\":{\"89\":1}}],[\"现在有了一个上下文对话和样本\",{\"1\":{\"15\":1}}],[\"现在\",{\"1\":{\"62\":1,\"64\":1}}],[\"降低延迟和减少gpu内存使用\",{\"1\":{\"61\":1}}],[\"降至最大学习率的10\",{\"1\":{\"13\":1}}],[\"耗费下推理\",{\"1\":{\"61\":1}}],[\"循环和块递归表示\",{\"1\":{\"62\":1}}],[\"循环和分块循环\",{\"1\":{\"61\":1}}],[\"循环意味着可以在o\",{\"1\":{\"61\":1}}],[\"低耗费推理和良好表现三大特性\",{\"1\":{\"61\":1}}],[\"低于10b参数\",{\"1\":{\"39\":1}}],[\"同时在继承关系中\",{\"1\":{\"71\":1}}],[\"同时递归地编码全局块以节省gpu内存\",{\"1\":{\"62\":1}}],[\"同时实现了平行训练\",{\"1\":{\"61\":1}}],[\"同样\",{\"1\":{\"50\":1,\"51\":1}}],[\"同样的解码过程来完成所有的nlp任务\",{\"1\":{\"49\":1}}],[\"同样的训练过程\",{\"1\":{\"49\":1}}],[\"同样的损失函数\",{\"1\":{\"49\":1}}],[\"zygisk方式进行获取\",{\"1\":{\"80\":1}}],[\"zettlemoyer\",{\"1\":{\"58\":1}}],[\"z\",{\"1\":{\"58\":1}}],[\"zhu\",{\"1\":{\"58\":1}}],[\"zhuanlan\",{\"1\":{\"22\":1,\"23\":1,\"32\":1,\"34\":1}}],[\"zheng\",{\"1\":{\"58\":1}}],[\"zhengxiao\",{\"1\":{\"58\":2}}],[\"zhilin\",{\"1\":{\"58\":2}}],[\"zhihu\",{\"1\":{\"22\":1,\"23\":1,\"32\":1,\"34\":1}}],[\"zhou\",{\"1\":{\"58\":2}}],[\"zh\",{\"1\":{\"24\":1}}],[\"qkv\",{\"1\":{\"64\":2}}],[\"qk\",{\"1\":{\"64\":4}}],[\"q\",{\"1\":{\"64\":7}}],[\"qn​einθ\",{\"1\":{\"64\":1}}],[\"qn​\",{\"1\":{\"64\":2}}],[\"q=xwq​\",{\"1\":{\"64\":1}}],[\"qiu\",{\"1\":{\"58\":1}}],[\"qian\",{\"1\":{\"58\":2}}],[\"query\",{\"1\":{\"1\":1,\"5\":1}}],[\"jdk介绍其用于hotspot\",{\"1\":{\"89\":1}}],[\"jdk17\",{\"1\":{\"89\":1}}],[\"joshi\",{\"1\":{\"58\":1}}],[\"jones\",{\"1\":{\"58\":1}}],[\"jianfeng\",{\"1\":{\"58\":1}}],[\"jingfei\",{\"1\":{\"58\":1}}],[\"jie\",{\"1\":{\"58\":2}}],[\"jiezhong\",{\"1\":{\"58\":1}}],[\"jmlr\",{\"1\":{\"58\":1}}],[\"j\",{\"1\":{\"58\":3,\"87\":1}}],[\"jar中提供\",{\"1\":{\"80\":1}}],[\"jar路径\",{\"1\":{\"80\":1}}],[\"jacob\",{\"1\":{\"58\":1}}],[\"jakob\",{\"1\":{\"58\":2}}],[\"java实现多态有三个必要条件\",{\"1\":{\"74\":1}}],[\"java\",{\"0\":{\"92\":1},\"1\":{\"36\":1,\"80\":2}}],[\"java和rest\",{\"1\":{\"23\":1}}],[\"参考\",{\"1\":{\"68\":1}}],[\"参考资料\",{\"0\":{\"60\":1}}],[\"参考文献\",{\"0\":{\"58\":1}}],[\"参数量\",{\"1\":{\"57\":1}}],[\"参数\",{\"1\":{\"31\":1,\"57\":1}}],[\"虽然这里被声明为native方法\",{\"1\":{\"89\":1}}],[\"虽然所需设备与p\",{\"1\":{\"57\":1}}],[\"虽然把这个模型放到现在看起来规模不大\",{\"1\":{\"45\":1}}],[\"近似性能下可以将设备减少为1台dgx\",{\"1\":{\"57\":1}}],[\"近端策略优化\",{\"1\":{\"14\":1}}],[\"跟全参数微调一样利用cls或者token的输出做nlu\",{\"1\":{\"57\":1}}],[\"跟踪已部署的ml模型的性能\",{\"1\":{\"36\":1}}],[\"跟踪模型性能\",{\"1\":{\"36\":1}}],[\"舍弃了词汇mapping的verbalizer的使用\",{\"1\":{\"57\":1}}],[\"假设prefix部分由50个token组成\",{\"1\":{\"57\":1}}],[\"假设可以访问两个人\",{\"1\":{\"15\":1}}],[\"每隔几秒钟就会重启一次\",{\"1\":{\"77\":1}}],[\"每一层transformer的embedding输入都需要被微调\",{\"1\":{\"57\":1}}],[\"每个retnet\",{\"1\":{\"63\":1}}],[\"每个chunk都可以并行编码\",{\"1\":{\"61\":1}}],[\"每个kubeflow组件都被包装到一个容器中\",{\"1\":{\"22\":1}}],[\"每个图的左侧对应系统信息\",{\"1\":{\"15\":1}}],[\"每个样本都包含一个提示和一个答案\",{\"1\":{\"10\":1}}],[\"均取得和fine\",{\"1\":{\"57\":1}}],[\"固定语言模型\",{\"1\":{\"57\":1}}],[\"串联起来\",{\"1\":{\"56\":1}}],[\"结构基本一致\",{\"1\":{\"55\":1}}],[\"结果如图12所示\",{\"1\":{\"18\":1}}],[\"受到了大家的关注\",{\"1\":{\"55\":1}}],[\"受到了业内人士和广大群众的注意\",{\"1\":{\"38\":1}}],[\"让程序可以选择多个运行状态\",{\"1\":{\"73\":1}}],[\"让r表示retention\",{\"1\":{\"65\":1}}],[\"让微调的资源消耗降下来了\",{\"1\":{\"55\":1}}],[\"让序列转换模型的效率得以一定的提升\",{\"1\":{\"41\":1}}],[\"研究者着手设计部分参数微调的方法\",{\"1\":{\"55\":1}}],[\"设b表示块的长度\",{\"1\":{\"64\":1}}],[\"设备就需要千万级别\",{\"1\":{\"55\":1}}],[\"设置β=0\",{\"1\":{\"14\":1}}],[\"往往小的企业或者个人应用的\",{\"1\":{\"55\":1}}],[\"往往需要经过下游数据进行微调后才可更好的发挥它的能力\",{\"1\":{\"54\":1}}],[\"六\",{\"0\":{\"55\":1}}],[\"表示共轭转置\",{\"1\":{\"64\":1}}],[\"表示非masked的词\",{\"1\":{\"53\":1}}],[\"表示词在parta中的位置\",{\"1\":{\"53\":1}}],[\"替代\",{\"1\":{\"52\":1}}],[\"替换\",{\"1\":{\"47\":1}}],[\"被引用对象的类型而不是引用变量的类型决定了调用谁的成员方法\",{\"1\":{\"76\":1}}],[\"被\",{\"1\":{\"52\":1}}],[\"沿用了bert和t5的masked的比例\",{\"1\":{\"52\":1}}],[\"沿袭和端到端管道自动化数据转换\",{\"1\":{\"30\":1}}],[\"玩笑\",{\"1\":{\"52\":1}}],[\"玩\",{\"1\":{\"52\":1}}],[\"中仅存的\",{\"1\":{\"87\":1}}],[\"中没有元素\",{\"1\":{\"87\":1}}],[\"中的元素\",{\"1\":{\"87\":1}}],[\"中的元素数目\",{\"1\":{\"87\":1}}],[\"中的前五个元素为\",{\"1\":{\"84\":1}}],[\"中的80\",{\"1\":{\"47\":1}}],[\"中出现的顺序排列\",{\"1\":{\"83\":1}}],[\"中唯一元素的个数\",{\"1\":{\"83\":1}}],[\"中实现了三个归一化因子\",{\"1\":{\"65\":1}}],[\"中可以看到\",{\"1\":{\"52\":1}}],[\"中\",{\"1\":{\"52\":1,\"87\":3}}],[\"~6~\",{\"1\":{\"52\":1}}],[\"~5~\",{\"1\":{\"52\":1}}],[\"~3~\",{\"1\":{\"52\":1}}],[\"~2~\",{\"1\":{\"52\":1}}],[\"~i\",{\"1\":{\"52\":2}}],[\"~都对应x中的连续token\",{\"1\":{\"52\":1}}],[\"~m~\",{\"1\":{\"52\":1}}],[\"~1~\",{\"1\":{\"52\":2}}],[\"~n~\",{\"1\":{\"52\":1}}],[\"解释\",{\"1\":{\"83\":2,\"84\":2,\"85\":2,\"87\":3}}],[\"解释和优化机器学习模型和实验的平台\",{\"1\":{\"26\":1}}],[\"解答\",{\"0\":{\"82\":1,\"88\":1}}],[\"解决过程\",{\"0\":{\"78\":1}}],[\"解码模型\",{\"1\":{\"51\":1}}],[\"五\",{\"0\":{\"51\":1}}],[\"包含了masked\",{\"1\":{\"50\":1}}],[\"包括p\",{\"1\":{\"55\":1}}],[\"包括对话模型\",{\"1\":{\"18\":1}}],[\"包括助手的消息\",{\"1\":{\"15\":1}}],[\"包括gpt\",{\"1\":{\"13\":1}}],[\"包括glm\",{\"1\":{\"4\":1}}],[\"包括指令微调和rlhf\",{\"1\":{\"9\":1}}],[\"转而采用transformer结构\",{\"1\":{\"50\":1}}],[\"给你两个按\",{\"1\":{\"87\":1}}],[\"给你一个有序数组\",{\"1\":{\"85\":1}}],[\"给你一个数组\",{\"1\":{\"84\":1}}],[\"给你一个\",{\"1\":{\"83\":1}}],[\"给远程服务设置surface不生效\",{\"1\":{\"80\":1}}],[\"给定一个大小为\",{\"1\":{\"81\":1}}],[\"给定一个输入序列x=x1​\",{\"1\":{\"63\":1}}],[\"给定x\",{\"1\":{\"65\":1}}],[\"给定输入x∈r∣x∣×dmodel​\",{\"1\":{\"64\":1}}],[\"给我从英语翻译成汉语\",{\"1\":{\"49\":1}}],[\"给出实验时可访问的最佳奖励模型\",{\"1\":{\"14\":1}}],[\"四个基于transformer的预训练语言模型也已经介绍完毕\",{\"1\":{\"54\":1}}],[\"四\",{\"0\":{\"48\":1}}],[\"取得了喜人的成绩\",{\"1\":{\"47\":1}}],[\"标签为notnext\",{\"1\":{\"47\":1}}],[\"标签为isnext\",{\"1\":{\"47\":1}}],[\"具体可表示为\",{\"1\":{\"63\":1}}],[\"具体来说\",{\"1\":{\"62\":1,\"64\":1,\"65\":1}}],[\"具体地\",{\"1\":{\"47\":1}}],[\"具体而言\",{\"1\":{\"2\":1}}],[\"都是在一个良好的预训练语言模型上进行微调\",{\"1\":{\"55\":1}}],[\"都要基于多个句子之间的关系\",{\"1\":{\"47\":1}}],[\"都拿出1000个例子作为测试集来评估模型\",{\"1\":{\"13\":1}}],[\"很多下游任务\",{\"1\":{\"47\":1}}],[\"接下来\",{\"1\":{\"64\":1}}],[\"接下来我们来介绍bert中另外一个部分\",{\"1\":{\"47\":1}}],[\"接下来可以使用最新的rlhf模型对这些合成数据进行采样\",{\"1\":{\"15\":1}}],[\"随着序列长度的增加\",{\"1\":{\"62\":1}}],[\"随着context\",{\"1\":{\"5\":1}}],[\"随机变为其他token\",{\"1\":{\"52\":1}}],[\"随机替换为其他token\",{\"1\":{\"47\":1}}],[\"证明了15\",{\"1\":{\"47\":1}}],[\"既包括token左边的\",{\"1\":{\"47\":1}}],[\"坏\",{\"1\":{\"47\":1,\"56\":1}}],[\"还拥有自己独有得特性\",{\"1\":{\"71\":1}}],[\"还是\",{\"1\":{\"47\":1}}],[\"还提到了一个工具\",{\"1\":{\"35\":1}}],[\"好\",{\"1\":{\"47\":1,\"56\":1}}],[\"遮住之后\",{\"1\":{\"47\":1}}],[\"呀\",{\"1\":{\"47\":1}}],[\"今天天气真\",{\"1\":{\"47\":1}}],[\"今天天气真好呀\",{\"1\":{\"47\":1}}],[\"那么您的题解将被\",{\"1\":{\"83\":1}}],[\"那么有\",{\"1\":{\"64\":1}}],[\"那么自然glm原生地支持p\",{\"1\":{\"57\":1}}],[\"那么p\",{\"1\":{\"57\":1}}],[\"那么什么是text\",{\"1\":{\"49\":1}}],[\"那么具体是怎么做的呢\",{\"1\":{\"47\":1}}],[\"那么对于任意一个序列的每一位置都将用同一个向量来进行表示\",{\"1\":{\"46\":1}}],[\"那么encoder会认为这两个序列完全相同\",{\"1\":{\"43\":1}}],[\"三部分构成\",{\"1\":{\"57\":1}}],[\"三\",{\"0\":{\"44\":1,\"73\":1}}],[\"至此\",{\"1\":{\"43\":1,\"54\":1}}],[\"组织模型看到将要预测的信息\",{\"1\":{\"43\":1}}],[\"单向\",{\"1\":{\"43\":1}}],[\"预测\",{\"1\":{\"43\":1}}],[\"预训练语言模型的方式只有全参数微调\",{\"1\":{\"55\":1}}],[\"预训练语言模型可以分为三种\",{\"1\":{\"51\":1}}],[\"预训练模型基本上属于这个范畴\",{\"1\":{\"49\":1}}],[\"预训练模型llama\",{\"1\":{\"1\":1}}],[\"预训练bert\",{\"0\":{\"47\":1}}],[\"预训练tokenizer\",{\"0\":{\"7\":1}}],[\"预训练超参设置\",{\"0\":{\"6\":1}}],[\"预训练的设置和模型架构和llama\",{\"1\":{\"4\":1}}],[\"预训练方法\",{\"0\":{\"2\":1}}],[\"也会被视作正确答案\",{\"1\":{\"84\":1}}],[\"也有很多人在努力\",{\"1\":{\"62\":1}}],[\"也有研究人员尝试将上述三种模型结合\",{\"1\":{\"51\":1}}],[\"也只能够通过位置编码的形式来获取位置信息\",{\"1\":{\"53\":1}}],[\"也许通过文字描述比较难以理解\",{\"1\":{\"52\":1}}],[\"也包括token右边的\",{\"1\":{\"47\":1}}],[\"也就是说\",{\"1\":{\"84\":1,\"85\":1}}],[\"也就是说被子类覆盖的方法\",{\"1\":{\"76\":1}}],[\"也就是说用户是无需知道对象内部的细节\",{\"1\":{\"69\":1}}],[\"也就是我们所说的多态性\",{\"1\":{\"73\":1}}],[\"也就是单向的\",{\"1\":{\"52\":1}}],[\"也就是在这里\",{\"1\":{\"47\":1}}],[\"也就是某个词既可以看到它之后的词\",{\"1\":{\"43\":1}}],[\"也是bert的核心\",{\"1\":{\"45\":1}}],[\"也可以用父类的功能\",{\"1\":{\"71\":1}}],[\"也可以用于ml工作流程编排\",{\"1\":{\"21\":1}}],[\"也可以看到它之前的词\",{\"1\":{\"43\":1}}],[\"也可以通过公式计算得到\",{\"1\":{\"43\":1}}],[\"也可以让结果很好\",{\"1\":{\"10\":1}}],[\"什么是masked\",{\"1\":{\"43\":1}}],[\"第二\",{\"1\":{\"65\":1}}],[\"第二层为一个线性变换\",{\"1\":{\"43\":1}}],[\"第一\",{\"1\":{\"65\":1}}],[\"第一层有一个relu激活函数\",{\"1\":{\"43\":1}}],[\"第三\",{\"1\":{\"62\":1,\"65\":1}}],[\"再把输出合并起来\",{\"1\":{\"43\":1}}],[\"形成多个子空间\",{\"1\":{\"43\":1}}],[\"缩放点击注意力机制会进行一个缩放\",{\"1\":{\"43\":1}}],[\"缩放点积注意力机制在做完query和key的点积之后\",{\"1\":{\"43\":1}}],[\"之所以要缩放\",{\"1\":{\"43\":1}}],[\"之间的多回合对话数据集\",{\"1\":{\"15\":1}}],[\"会有更多更好的语言模型诞生\",{\"1\":{\"54\":1}}],[\"会导致query和key的点积非常大\",{\"1\":{\"43\":1}}],[\"会进行一个缩放\",{\"1\":{\"43\":1}}],[\"会计算残差和\",{\"1\":{\"43\":1}}],[\"构成\",{\"1\":{\"43\":2}}],[\"采用的小窗方式是使用decorcaptionview\",{\"1\":{\"80\":1}}],[\"采用了多任务学习优化\",{\"1\":{\"57\":1}}],[\"采用了注意力机制\",{\"1\":{\"43\":1}}],[\"采用三角函数来作为位置编码公式\",{\"1\":{\"43\":1}}],[\"公式6\",{\"1\":{\"66\":1}}],[\"公式7\",{\"1\":{\"66\":1}}],[\"公式5\",{\"1\":{\"66\":1}}],[\"公式\",{\"1\":{\"64\":2}}],[\"公式如下\",{\"1\":{\"43\":2,\"52\":1}}],[\"公开的指令微调数据质量参差不齐\",{\"1\":{\"10\":1}}],[\"选择一种合适的方式表示词在序列中的顺序非常重要\",{\"1\":{\"43\":1}}],[\"选择机器学习模型\",{\"1\":{\"37\":1}}],[\"上面的等式称为\",{\"1\":{\"64\":2}}],[\"上面两个等式称为\",{\"1\":{\"64\":1}}],[\"上\",{\"1\":{\"64\":1}}],[\"上述公式中\",{\"1\":{\"66\":1}}],[\"上述技巧在稳定正向和反向通道的数值流动的同时\",{\"1\":{\"65\":1}}],[\"上述我们介绍\",{\"1\":{\"57\":1}}],[\"上述我们介绍p\",{\"1\":{\"56\":1}}],[\"上述我们也提到\",{\"1\":{\"54\":1}}],[\"上述两个句子序列的词完全相同\",{\"1\":{\"43\":1}}],[\"上下文长度\",{\"1\":{\"1\":1,\"5\":1}}],[\"序列的顺序中往往蕴含着一些重要信息\",{\"1\":{\"43\":1}}],[\"序列转换模型一般由循环神经网络\",{\"1\":{\"41\":1}}],[\"序列转换模型并不是transformer首次提出的\",{\"1\":{\"41\":1}}],[\"序列转换模型\",{\"0\":{\"41\":1},\"1\":{\"41\":1}}],[\"拥有更加优秀的能力\",{\"1\":{\"43\":1}}],[\"位置编码采用了预训练的方式训练而得\",{\"1\":{\"53\":1}}],[\"位置编码采用了三角函数计算的方式得到\",{\"1\":{\"53\":1}}],[\"位置编码可以通过训练得到\",{\"1\":{\"43\":1}}],[\"位置编码\",{\"1\":{\"43\":2}}],[\"得到attention\",{\"1\":{\"42\":1}}],[\"得到query和key的相似度\",{\"1\":{\"42\":1}}],[\"由\",{\"1\":{\"57\":1}}],[\"由一个多头注意力机制\",{\"1\":{\"43\":1}}],[\"由query和key做向量比对\",{\"1\":{\"42\":1}}],[\"由于直接调用jvm内部实现\",{\"1\":{\"89\":1}}],[\"由于尺度不变的性质\",{\"1\":{\"65\":1}}],[\"由于bert的主要目的是构建一个通用的预训练模型\",{\"1\":{\"46\":1}}],[\"由于作者应用了迭代模型更新\",{\"1\":{\"14\":1}}],[\"由于注释者的主观性和他们对可能区分反应的细微细节的依赖\",{\"1\":{\"13\":1}}],[\"首先通过android\",{\"1\":{\"78\":1}}],[\"首先\",{\"1\":{\"42\":1,\"43\":1,\"62\":1}}],[\"首先就是要收集大量的高质量sft数据\",{\"1\":{\"10\":1}}],[\"计算attention\",{\"1\":{\"42\":1}}],[\"经过一系列的key来获取value\",{\"1\":{\"42\":1}}],[\"只出现一次\",{\"1\":{\"83\":1}}],[\"只有这样该引用才能够具备技能调用父类的方法和子类的方法\",{\"1\":{\"74\":1}}],[\"只有第一层embedding才需要被微调\",{\"1\":{\"57\":1}}],[\"只保留一些对外接口使之与外部发生联系\",{\"1\":{\"69\":1}}],[\"只保留了masked\",{\"1\":{\"50\":1}}],[\"只不过\",{\"1\":{\"52\":1}}],[\"只不过是某些词的顺序不同\",{\"1\":{\"43\":1}}],[\"只需对其排序\",{\"1\":{\"82\":1}}],[\"只需要调用\",{\"1\":{\"89\":1}}],[\"只需要将nums2复制到nums1即可\",{\"1\":{\"88\":1}}],[\"只需要考虑到即可\",{\"1\":{\"82\":1}}],[\"只需要存储一份模型参数\",{\"1\":{\"56\":1}}],[\"只需要在给模型输入的部分加上前缀\",{\"1\":{\"49\":1}}],[\"只需将前几轮中的所有token\",{\"1\":{\"15\":1}}],[\"只依赖于注意力机制\",{\"1\":{\"41\":1}}],[\"彻底抛弃了复杂的rnn和cnn\",{\"1\":{\"41\":1}}],[\"不走常规的jni\",{\"1\":{\"89\":1}}],[\"不对实参做任何拷贝\",{\"1\":{\"85\":1}}],[\"不对实参作任何拷贝\",{\"1\":{\"84\":1}}],[\"不要使用额外的数组空间\",{\"1\":{\"84\":1,\"85\":1}}],[\"不需要考虑数组中超出新长度后面的元素\",{\"1\":{\"83\":2,\"85\":2}}],[\"不用修改源程序代码\",{\"1\":{\"73\":1}}],[\"不可能三角\",{\"1\":{\"62\":1}}],[\"不同的头使用不同的参数矩阵wq​\",{\"1\":{\"65\":1}}],[\"不同于之前研究的简单结合\",{\"1\":{\"51\":1}}],[\"不同长度的句子之间\",{\"1\":{\"43\":1}}],[\"不变\",{\"1\":{\"47\":1,\"52\":1}}],[\"不过我愿意分类为哈希表题\",{\"1\":{\"81\":1}}],[\"不过注意到\",{\"1\":{\"80\":1}}],[\"不过这个native方法有些特殊\",{\"1\":{\"89\":1}}],[\"不过这会增加用户成本\",{\"1\":{\"80\":1}}],[\"不过这种办法很不方便\",{\"1\":{\"77\":1}}],[\"不过因为未知原因\",{\"1\":{\"80\":1}}],[\"不过因为自回归和自编码在模型结构上相差太多\",{\"1\":{\"51\":1}}],[\"不过需要修改较多的源码\",{\"1\":{\"80\":1}}],[\"不过其自带的adb一直处于无法使用的状态\",{\"1\":{\"77\":1}}],[\"不过parta是看不到partb的\",{\"1\":{\"52\":1}}],[\"不过考虑到span之间可能也有关系\",{\"1\":{\"52\":1}}],[\"不过看到它只用了z<i的部分\",{\"1\":{\"52\":1}}],[\"不过在当时的条件下并没有很出色的能力\",{\"1\":{\"51\":1}}],[\"不过与bert\",{\"1\":{\"50\":1,\"54\":1}}],[\"不过\",{\"1\":{\"47\":1,\"80\":1}}],[\"不过它们仍然没有脱离rnn或者cnn\",{\"1\":{\"41\":1}}],[\"不确定\",{\"1\":{\"12\":1}}],[\"后\",{\"1\":{\"87\":1}}],[\"后来\",{\"1\":{\"41\":1}}],[\"后续的语言模型\",{\"1\":{\"39\":1,\"43\":1}}],[\"后续有详细介绍\",{\"1\":{\"1\":1}}],[\"后续有介绍\",{\"1\":{\"1\":1}}],[\"作为模型的输入\",{\"1\":{\"66\":1}}],[\"作为编码器和解码器\",{\"1\":{\"41\":1}}],[\"作者堆叠多尺度缩放retention\",{\"1\":{\"66\":1}}],[\"作者用groupnorm的尺度不变性来提高retention\",{\"1\":{\"65\":1}}],[\"作者引入了倾斜门\",{\"1\":{\"65\":1}}],[\"作者对每个本地块进行并行编码以提高计算速度\",{\"1\":{\"62\":1}}],[\"作者对模型中的k个输出进行采样\",{\"1\":{\"14\":1}}],[\"作者对模型进行了2个epochs的微调\",{\"1\":{\"10\":1}}],[\"作者提出了多尺度保留机制\",{\"1\":{\"62\":1}}],[\"作者提出了ghost\",{\"1\":{\"15\":1}}],[\"作者也会在一半的时间内修改原始指令\",{\"1\":{\"15\":1}}],[\"作者通过随机组合上述约束来构建最终指令\",{\"1\":{\"15\":1}}],[\"作者通过两个主要的算法来探索rlhf微调\",{\"1\":{\"14\":1}}],[\"作者要求人类评估人员对其有用性和安全性进行评分\",{\"1\":{\"18\":1}}],[\"作者要求llama\",{\"1\":{\"15\":1}}],[\"作者要求注释器首先编写一个提示\",{\"1\":{\"12\":1}}],[\"作者创建了一些综合约束条件\",{\"1\":{\"15\":1}}],[\"作者能够通过在生成之前将模型权重合并到每个节点一次\",{\"1\":{\"14\":1}}],[\"作者为所有模型进行了200到400次迭代的训练\",{\"1\":{\"14\":1}}],[\"作者为每个样本打分\",{\"1\":{\"14\":1}}],[\"作者报告了llama\",{\"1\":{\"14\":1}}],[\"作者从最新的模型中对每个prompt采样k个答案\",{\"1\":{\"14\":1}}],[\"作者只对最大的70b\",{\"1\":{\"14\":1}}],[\"作者只对回答令牌进行反向传播\",{\"1\":{\"10\":1}}],[\"作者在等式\",{\"1\":{\"65\":1}}],[\"作者在每个layer中使用h=dmodel​\",{\"1\":{\"65\":1}}],[\"作者在下图中显示了模型的最大注意力激活\",{\"1\":{\"15\":1}}],[\"作者在图7中说明了拒绝采样的好处\",{\"1\":{\"14\":1}}],[\"作者在给定模型的初始策略的情况下对所有输出进行采样\",{\"1\":{\"14\":1}}],[\"作者在损失中进一步添加了一个margin成分\",{\"1\":{\"13\":1}}],[\"作者更进一步\",{\"1\":{\"14\":1}}],[\"作者强调\",{\"1\":{\"13\":1}}],[\"作者进一步修改它\",{\"1\":{\"13\":1}}],[\"作者使用了循环模式\",{\"1\":{\"66\":1}}],[\"作者使用了平行模式\",{\"1\":{\"66\":1}}],[\"作者使用了二元排名损失\",{\"1\":{\"13\":1}}],[\"作者使用chat\",{\"1\":{\"18\":1}}],[\"作者使用gpt\",{\"1\":{\"17\":1,\"18\":1}}],[\"作者使用pytorch\",{\"1\":{\"14\":1}}],[\"作者使用adamw优化器\",{\"1\":{\"14\":1}}],[\"作者使用自回归目标\",{\"1\":{\"10\":1}}],[\"作者将llama\",{\"1\":{\"18\":1}}],[\"作者将相应测试集的所有提示的并集分别称为\",{\"1\":{\"13\":1}}],[\"作者将收集的成对人类偏好数据转换为二元排名标签格式\",{\"1\":{\"13\":1}}],[\"作者将训练集中的所有提示和答案连接起来\",{\"1\":{\"10\":1}}],[\"作者还要求注释者标注他们更喜欢自己选择的回答而不是选择的程度\",{\"1\":{\"12\":1}}],[\"作者的注释过程如下\",{\"1\":{\"12\":1}}],[\"作者选择了二进制比较协议\",{\"1\":{\"12\":1}}],[\"二维位置编码\",{\"0\":{\"53\":1}}],[\"二\",{\"0\":{\"40\":1,\"71\":1}}],[\"国内外研究者先后提出了p\",{\"1\":{\"39\":1}}],[\"大于\",{\"1\":{\"81\":1}}],[\"大大减少了训练时的存储和内存使用\",{\"1\":{\"56\":1}}],[\"大家首先想起的一定是chatgpt\",{\"1\":{\"50\":1}}],[\"大家的参数量还没有那么夸张\",{\"1\":{\"45\":1}}],[\"大部分个人和团队都已经没有能力去做模型的全参数微调了\",{\"1\":{\"39\":1}}],[\"大模型\",{\"1\":{\"39\":1}}],[\"抛开预训练不谈\",{\"1\":{\"39\":1}}],[\"万亿模型都不足为奇\",{\"1\":{\"39\":1}}],[\"万级别的好的数据足够了\",{\"1\":{\"10\":1}}],[\"千亿\",{\"1\":{\"39\":1}}],[\"百亿\",{\"1\":{\"39\":1}}],[\"小模型\",{\"1\":{\"39\":1}}],[\"目前\",{\"1\":{\"39\":1}}],[\"目标漂移以及回归和分类性能\",{\"1\":{\"34\":1}}],[\"意为通用语言模型\",{\"1\":{\"39\":1}}],[\"清华大学发布的glm\",{\"1\":{\"51\":1}}],[\"清华大学语言模型glm发布\",{\"1\":{\"39\":1}}],[\"清华大学在语言模型上研究较早\",{\"1\":{\"39\":1}}],[\"放眼国内\",{\"1\":{\"39\":1}}],[\"了\",{\"1\":{\"39\":1}}],[\"文本到文本\",{\"1\":{\"39\":1}}],[\"文本和表格\",{\"1\":{\"27\":1}}],[\"全称retentive\",{\"1\":{\"61\":1}}],[\"全参数微调效果相对较好\",{\"1\":{\"55\":1}}],[\"全部把输入的token替换成\",{\"1\":{\"47\":1}}],[\"全能模型\",{\"1\":{\"39\":1}}],[\"全面\",{\"1\":{\"22\":1}}],[\"全面工具集\",{\"0\":{\"22\":1}}],[\"轰动一时\",{\"1\":{\"39\":1}}],[\"基本架构\",{\"1\":{\"61\":1}}],[\"基本上都采用了transformer或者基于transformer修改的模型\",{\"1\":{\"43\":1}}],[\"基本上都与transformer有着千丝万缕的联系\",{\"1\":{\"39\":1}}],[\"基本已经可以确定的是\",{\"1\":{\"39\":1}}],[\"基于多任务数据集的prompt进行预训练\",{\"1\":{\"57\":1}}],[\"基于模型的评估\",{\"0\":{\"17\":1}}],[\"基于消融结果和易于缩放推断\",{\"1\":{\"5\":1}}],[\"早在2017年\",{\"1\":{\"39\":1}}],[\"讯飞的星火等\",{\"1\":{\"39\":1}}],[\"比如手动编写汇编或者手动编写编译器中间语言来替换该方法的实现\",{\"1\":{\"89\":1}}],[\"比如会时常跳出小窗\",{\"1\":{\"80\":1}}],[\"比如自回归模型擅长自然语言生成任务\",{\"1\":{\"51\":1}}],[\"比如问题回答\",{\"1\":{\"47\":1}}],[\"比如\",{\"1\":{\"43\":1,\"44\":1,\"47\":1,\"49\":1,\"55\":1,\"56\":1,\"88\":1,\"89\":1}}],[\"比如百度的文心\",{\"1\":{\"39\":1}}],[\"比较\",{\"1\":{\"26\":1}}],[\"各种语言模型层出不穷\",{\"1\":{\"39\":1}}],[\"通过\",{\"1\":{\"83\":1}}],[\"通过编辑之后会变成两个不同的函数\",{\"1\":{\"73\":1}}],[\"通过使用继承我们能够非常方便地复用以前的代码\",{\"1\":{\"71\":1}}],[\"通过吸收λ到wq​\",{\"1\":{\"64\":1}}],[\"通过状态sn​来把v\",{\"1\":{\"64\":1}}],[\"通过上一节的介绍我们知道\",{\"1\":{\"53\":1}}],[\"通过这样的方式\",{\"1\":{\"49\":1}}],[\"通过以上几个部分\",{\"1\":{\"38\":1}}],[\"通过meta内部的安全和帮助奖励模型进行测量\",{\"1\":{\"17\":1}}],[\"几个方面来介绍\",{\"1\":{\"38\":1}}],[\"自然也没有原生的表示位置信息的能力\",{\"1\":{\"53\":1}}],[\"自然语言处理中常见的翻译任务\",{\"1\":{\"49\":1}}],[\"自然语言推理等\",{\"1\":{\"47\":1}}],[\"自编码模型\",{\"1\":{\"51\":1}}],[\"自回归填空\",{\"0\":{\"52\":1},\"1\":{\"52\":1}}],[\"自回归模型\",{\"1\":{\"51\":1}}],[\"自回归模型对自然语言生成有着天然的优势\",{\"1\":{\"50\":1}}],[\"自回归语言模型更加适合自然语言生成任务\",{\"1\":{\"44\":1}}],[\"自回归解码的标准做法是缓存序列中先前token的key\",{\"1\":{\"5\":1}}],[\"自注意力机制示例\",{\"1\":{\"42\":1}}],[\"自注意力机制正符合这一点\",{\"1\":{\"42\":1}}],[\"自注意力机制得到了应用\",{\"1\":{\"42\":1}}],[\"自注意力机制是注意力机制的一种\",{\"1\":{\"42\":1}}],[\"自动化机器学习\",{\"0\":{\"37\":1},\"1\":{\"37\":1}}],[\"检查点和扩展机器学习模型\",{\"1\":{\"36\":1}}],[\"框架不可知服务\",{\"1\":{\"36\":1}}],[\"易于理解的推论\",{\"1\":{\"36\":1}}],[\"支持所有主要的编程语言和框架\",{\"1\":{\"36\":1}}],[\"支持llama\",{\"1\":{\"17\":1}}],[\"实例化mifreeformdisplayadapter需要displaymanagerservice的一些字段\",{\"1\":{\"80\":1}}],[\"实例分析\",{\"0\":{\"76\":1}}],[\"实现多态的方法\",{\"0\":{\"75\":1}}],[\"实现细节\",{\"1\":{\"70\":1}}],[\"实验\",{\"0\":{\"67\":1}}],[\"实验跟踪\",{\"1\":{\"31\":1}}],[\"实际上继承者是被继承者的特殊化\",{\"1\":{\"71\":1}}],[\"实际上\",{\"1\":{\"42\":1}}],[\"实时监控\",{\"1\":{\"34\":1}}],[\"报告\",{\"1\":{\"34\":1}}],[\"批量模型检查\",{\"1\":{\"34\":1}}],[\"测试\",{\"1\":{\"34\":1}}],[\"测试和交付步骤\",{\"1\":{\"24\":1}}],[\"验证和生产过程中监控ml模型\",{\"1\":{\"34\":1}}],[\"赠款您完全控制模型管理操作\",{\"1\":{\"33\":1}}],[\"多数元素是指在数组中出现次数\",{\"1\":{\"81\":1}}],[\"多数元素\",{\"0\":{\"81\":1}}],[\"多态的实现条件\",{\"0\":{\"74\":1}}],[\"多态分为编译时多态和运行时多态\",{\"1\":{\"73\":1}}],[\"多态\",{\"0\":{\"68\":1,\"73\":1}}],[\"多尺度保留\",{\"1\":{\"65\":1}}],[\"多尺度保留模块\",{\"1\":{\"63\":1}}],[\"多了一个segment\",{\"1\":{\"45\":1}}],[\"多头注意力机制\",{\"1\":{\"43\":1}}],[\"多头注意力机制的公式如下\",{\"1\":{\"43\":1}}],[\"多头注意力机制就是将缩放点积注意力机制的过程做h次\",{\"1\":{\"43\":1}}],[\"多头注意力机制如图2\",{\"1\":{\"43\":1}}],[\"多框架的模型服务和监控工具\",{\"1\":{\"33\":1}}],[\"多轮一致性的指令\",{\"0\":{\"15\":1}}],[\"灵活\",{\"1\":{\"33\":1}}],[\"管理和扩展机器学习模型\",{\"1\":{\"33\":1}}],[\"管道和结果\",{\"1\":{\"27\":1}}],[\"8\",{\"0\":{\"33\":1},\"1\":{\"39\":1,\"45\":1,\"55\":1,\"58\":1,\"76\":1}}],[\"8字符\",{\"1\":{\"7\":1}}],[\"服务和监控提供了完整的解决方案\",{\"1\":{\"32\":1}}],[\"创建\",{\"1\":{\"31\":1}}],[\"流行的机器学习项目工具\",{\"1\":{\"31\":1}}],[\"流程运行和部署\",{\"1\":{\"28\":1}}],[\"集成\",{\"1\":{\"30\":1}}],[\"数千个作业\",{\"1\":{\"30\":1}}],[\"数据被保护在抽象数据类型的内部\",{\"1\":{\"69\":1}}],[\"数据漂移\",{\"1\":{\"34\":1}}],[\"数据和模型注册表\",{\"1\":{\"31\":1}}],[\"数据和模型版本控制\",{\"1\":{\"27\":1}}],[\"数据\",{\"1\":{\"31\":1}}],[\"数据集\",{\"1\":{\"27\":1}}],[\"数据分布检查\",{\"1\":{\"20\":1}}],[\"任务上\",{\"1\":{\"57\":1}}],[\"任务\",{\"1\":{\"49\":1}}],[\"任务都转化为文本到文本\",{\"1\":{\"49\":1}}],[\"任务可以根据有向无环图\",{\"1\":{\"21\":1}}],[\"任何两个时间步之间的距离应该保持一致\",{\"1\":{\"43\":1}}],[\"任何语言\",{\"1\":{\"30\":1}}],[\"视频\",{\"1\":{\"30\":1}}],[\"视觉\",{\"1\":{\"27\":1}}],[\"日志\",{\"1\":{\"30\":1}}],[\"图6\",{\"1\":{\"57\":2}}],[\"图中含有色块部分\",{\"1\":{\"52\":1}}],[\"图5\",{\"1\":{\"52\":2,\"53\":1}}],[\"图4\",{\"1\":{\"49\":1,\"50\":1}}],[\"图3\",{\"1\":{\"45\":1,\"46\":1}}],[\"图2\",{\"1\":{\"41\":1,\"42\":2,\"43\":3}}],[\"图像\",{\"1\":{\"30\":1}}],[\"图11报告了作者针对安全和帮助轴的不同sft和rlhf版本的进展\",{\"1\":{\"17\":1}}],[\"版本控制和监控机器学习模型的平台\",{\"1\":{\"36\":1}}],[\"版本控制\",{\"0\":{\"31\":1},\"1\":{\"30\":1,\"31\":2}}],[\"久经考验的工作流管理工具\",{\"1\":{\"29\":1}}],[\"工作区和团队协作\",{\"1\":{\"28\":1}}],[\"工作流管理\",{\"0\":{\"28\":1},\"1\":{\"28\":1,\"29\":1}}],[\"工作流\",{\"1\":{\"22\":1}}],[\"您还可以管理帐户\",{\"1\":{\"28\":1}}],[\"您可以自动处理原始数据\",{\"1\":{\"37\":1}}],[\"您可以在单个api端点上部署多个模型\",{\"1\":{\"33\":1}}],[\"您可以与任何数据\",{\"1\":{\"30\":1}}],[\"您可以使用它\",{\"1\":{\"31\":1}}],[\"您可以使用它来记录工件\",{\"1\":{\"27\":1}}],[\"您可以使用commit\",{\"1\":{\"30\":1}}],[\"您可以使用cli\",{\"1\":{\"23\":1}}],[\"您可以使用prefect\",{\"1\":{\"28\":1}}],[\"您可以将其与任何机器学习库一起使用\",{\"1\":{\"26\":1}}],[\"协调和编排应用程序之间的工作流\",{\"1\":{\"28\":1}}],[\"音频\",{\"1\":{\"27\":1}}],[\"依赖关系\",{\"1\":{\"27\":1}}],[\"超参数优化和模型管理的机器学习平台\",{\"1\":{\"27\":1}}],[\"提示\",{\"1\":{\"81\":1,\"83\":1,\"84\":1,\"85\":1,\"87\":1}}],[\"提示微调完全不需要训练\",{\"1\":{\"56\":1}}],[\"提示微调冻结了预训练模型的所有参数\",{\"1\":{\"56\":1}}],[\"提示微调只用一个冻结的语言模型来微调连续的提示\",{\"1\":{\"56\":1}}],[\"提示微调\",{\"0\":{\"56\":1}}],[\"提升了7倍的速度\",{\"1\":{\"62\":1}}],[\"提出了对序列模型的记忆力机制\",{\"1\":{\"61\":1}}],[\"提出一种新技术\",{\"1\":{\"9\":1}}],[\"提高了seq2seq的效率\",{\"1\":{\"43\":1}}],[\"提供了一个端到端ml平台\",{\"1\":{\"25\":1}}],[\"微软的azure结合了azure\",{\"1\":{\"25\":1}}],[\"6b\",{\"1\":{\"60\":1}}],[\"652\",{\"1\":{\"58\":1}}],[\"68\",{\"1\":{\"58\":1}}],[\"61\",{\"1\":{\"58\":1}}],[\"67\",{\"1\":{\"58\":1}}],[\"60th\",{\"1\":{\"58\":1}}],[\"6010\",{\"1\":{\"58\":1}}],[\"6000\",{\"1\":{\"58\":1}}],[\"6\",{\"0\":{\"25\":1,\"31\":1,\"56\":1,\"57\":1},\"1\":{\"38\":1,\"39\":1,\"43\":2,\"55\":1,\"58\":1,\"64\":1,\"76\":1,\"87\":4}}],[\"642\",{\"1\":{\"58\":1}}],[\"64的小批量大小\",{\"1\":{\"14\":1}}],[\"64\",{\"1\":{\"10\":1}}],[\"商用\",{\"1\":{\"24\":1,\"25\":1}}],[\"部署和协作的工作流\",{\"1\":{\"31\":1}}],[\"部署和测试来管理机器学习生命周期的开源平台\",{\"1\":{\"23\":1}}],[\"部署和模型注册\",{\"1\":{\"23\":1}}],[\"类内部的结构可以自由修改\",{\"1\":{\"70\":1}}],[\"类型\",{\"1\":{\"23\":1}}],[\"类别\",{\"1\":{\"20\":1,\"21\":1,\"22\":1,\"23\":1,\"24\":1,\"25\":1}}],[\"性能监控\",{\"0\":{\"23\":1,\"36\":1},\"1\":{\"23\":1,\"36\":1}}],[\"主要是指方法的重载\",{\"1\":{\"73\":1}}],[\"主要是因为它使作者能够最大限度地提高收集到的提示的多样性\",{\"1\":{\"12\":1}}],[\"主要研究点\",{\"0\":{\"39\":1}}],[\"主要关注于训练的过程\",{\"1\":{\"22\":1}}],[\"你必须在\",{\"1\":{\"85\":1}}],[\"你必须仅使用\",{\"1\":{\"84\":1}}],[\"你不需要考虑数组中超出新长度后面的元素\",{\"1\":{\"84\":3}}],[\"你需要\",{\"1\":{\"84\":1}}],[\"你需要做以下事情确保你的题解可以被通过\",{\"1\":{\"83\":1}}],[\"你可以设计实现一个时间复杂度为\",{\"1\":{\"87\":1}}],[\"你可以想象内部操作如下\",{\"1\":{\"84\":1,\"85\":1}}],[\"你可以假设数组是非空的\",{\"1\":{\"81\":1}}],[\"你可以使用类似的语法来版本化你的数据\",{\"1\":{\"30\":1}}],[\"你都应该能够运行kubeflow\",{\"1\":{\"22\":1}}],[\"你喜欢例如网球\",{\"1\":{\"15\":1}}],[\"无法立即获得logicaldisplay从而拿到displayid\",{\"1\":{\"80\":1}}],[\"无法获取\",{\"1\":{\"80\":1}}],[\"无论你在哪里运行kubernetes\",{\"1\":{\"22\":1}}],[\"无害和有用>50\",{\"1\":{\"17\":1}}],[\"可微调的参数多了\",{\"1\":{\"57\":1}}],[\"可能觉得稍微困难\",{\"1\":{\"85\":1}}],[\"可能效果会更好一些\",{\"1\":{\"52\":1}}],[\"可能差别很大\",{\"1\":{\"52\":1}}],[\"可能是因为在中文中\",{\"1\":{\"52\":1}}],[\"可能会有一个问题\",{\"1\":{\"47\":1}}],[\"可视化和运行机器学习管道\",{\"1\":{\"31\":1}}],[\"可对数据\",{\"1\":{\"31\":1}}],[\"可让您可视化流程\",{\"1\":{\"28\":1}}],[\"可帮助您管理机器学习生命周期的核心部分\",{\"1\":{\"23\":1}}],[\"可移植和可扩展\",{\"1\":{\"22\":1}}],[\"可以对成员进行更精准的控制\",{\"1\":{\"70\":1}}],[\"可以显著降低部署成本和延迟\",{\"1\":{\"62\":1}}],[\"可以适配到序列标注任务\",{\"1\":{\"57\":1}}],[\"可以让微调后的预训练模型在处理下游任务时得到良好的效果\",{\"1\":{\"55\":1}}],[\"可以让模型去关注不同方面的信息\",{\"1\":{\"43\":1}}],[\"可以体现出bert是双向模型\",{\"1\":{\"47\":1}}],[\"可以看出\",{\"1\":{\"45\":1}}],[\"可以看到该方法有一个注解\",{\"1\":{\"89\":1}}],[\"可以看到这是一个native方法\",{\"1\":{\"89\":1}}],[\"可以看到我们给定的文本序列为\",{\"1\":{\"52\":1}}],[\"可以看到\",{\"1\":{\"43\":1}}],[\"可以在该数据集上微调llama\",{\"1\":{\"15\":1}}],[\"可以在除第一个回合外的所有回合中放弃它\",{\"1\":{\"15\":1}}],[\"可以在类似于拒绝采样的过程中对模型进行微调\",{\"1\":{\"15\":1}}],[\"可以在多个头之间共享key和value预测\",{\"1\":{\"5\":1}}],[\"可以观察到\",{\"1\":{\"14\":1}}],[\"可以使用具有单个kv投影的原始多查询格式\",{\"1\":{\"5\":1}}],[\"简而言之\",{\"1\":{\"32\":1}}],[\"简单题没啥说的\",{\"1\":{\"84\":1}}],[\"简单方便\",{\"1\":{\"36\":1}}],[\"简单\",{\"1\":{\"22\":1}}],[\"简洁地回应\",{\"1\":{\"15\":1}}],[\"靠的是其丰富的工具\",{\"1\":{\"22\":1}}],[\"⭐\",{\"0\":{\"22\":1,\"23\":1,\"27\":1,\"28\":1,\"31\":1,\"32\":1,\"33\":1,\"34\":1}}],[\"偏训练\",{\"0\":{\"22\":1},\"1\":{\"22\":1}}],[\"来进行计算\",{\"1\":{\"64\":1}}],[\"来讨论gpt的基本结构\",{\"1\":{\"50\":1}}],[\"来计算概率的\",{\"1\":{\"47\":1}}],[\"来实现机器学习从数据到模型的一整套端到端的过程\",{\"1\":{\"22\":1}}],[\"来执行\",{\"1\":{\"21\":1}}],[\"来提高llama\",{\"1\":{\"2\":1}}],[\"相对顺序\",{\"1\":{\"83\":1}}],[\"相反\",{\"1\":{\"64\":1}}],[\"相关代码见https\",{\"1\":{\"61\":1}}],[\"相关链接\",{\"1\":{\"20\":1,\"21\":1,\"22\":4,\"23\":2,\"24\":1,\"26\":1,\"27\":1,\"28\":1,\"30\":1,\"31\":1,\"32\":3,\"33\":1,\"34\":2,\"35\":1,\"36\":1,\"37\":1}}],[\"相信在未来\",{\"1\":{\"54\":1}}],[\"相当于看到了未来的信息\",{\"1\":{\"43\":1}}],[\"相比\",{\"1\":{\"15\":1}}],[\"相比llama\",{\"1\":{\"1\":1}}],[\"启动和监控机器学习系统所需的常见组件\",{\"1\":{\"20\":1}}],[\"平行意味着允许平行训练\",{\"1\":{\"61\":1}}],[\"平行\",{\"1\":{\"61\":1}}],[\"平台\",{\"1\":{\"20\":1}}],[\"平局率为31\",{\"1\":{\"18\":1}}],[\"生产级机器学习\",{\"1\":{\"20\":1}}],[\"是以\",{\"1\":{\"84\":1,\"85\":1}}],[\"是指利用抽象数据类型将数据和基于数据的操作封装在一起\",{\"1\":{\"69\":1}}],[\"是微软研究院和清华大学推出的大语言模型\",{\"1\":{\"61\":1}}],[\"是被masked标注的预测概率来预测样本的标签\",{\"1\":{\"56\":1}}],[\"是transfer\",{\"1\":{\"49\":1}}],[\"是效果最好的\",{\"1\":{\"47\":1}}],[\"是\",{\"1\":{\"47\":1}}],[\"是这三个嵌入式张量的和\",{\"1\":{\"46\":1}}],[\"是训练出来的\",{\"1\":{\"46\":1}}],[\"是由三角函数计算出来的\",{\"1\":{\"46\":1}}],[\"是decoder单元中多了一层masked\",{\"1\":{\"43\":1}}],[\"是因为对于输入的d大值\",{\"1\":{\"43\":1}}],[\"是人们在机器学习模型中嵌入的一种特殊结构\",{\"1\":{\"42\":1}}],[\"是bert\",{\"1\":{\"39\":1}}],[\"是其总结前人经验\",{\"1\":{\"38\":1}}],[\"是一个配置框架\",{\"1\":{\"20\":1}}],[\"是一个端到端平台\",{\"1\":{\"20\":1}}],[\"是一种基于\",{\"1\":{\"20\":1}}],[\"是llama\",{\"1\":{\"1\":1}}],[\"开发者做了以下努力\",{\"1\":{\"80\":1}}],[\"开源python库\",{\"1\":{\"34\":1}}],[\"开源\",{\"1\":{\"20\":1,\"21\":1,\"22\":1,\"23\":1}}],[\"开始\",{\"1\":{\"10\":1}}],[\"下面需要加载mifreeformdisplayadapter\",{\"1\":{\"80\":1}}],[\"下面一节\",{\"1\":{\"54\":1}}],[\"下面\",{\"1\":{\"51\":1,\"64\":1}}],[\"下面我们来介绍一下bert\",{\"1\":{\"44\":1}}],[\"下面我们来介绍自注意力机制\",{\"1\":{\"42\":1}}],[\"下面我们讨论位置编码\",{\"1\":{\"43\":1}}],[\"下面挑选介绍\",{\"1\":{\"25\":1}}],[\"下面挑选开源的和azure商用的进行总结\",{\"1\":{\"19\":1}}],[\"下面有介绍\",{\"1\":{\"2\":1}}],[\"知乎\",{\"1\":{\"19\":1}}],[\"系统会用下面的代码来测试你的题解\",{\"1\":{\"83\":1}}],[\"系统还引入了selinux\",{\"1\":{\"80\":1}}],[\"系统的其他对象只能通过包裹在数据外面的已经授权的操作来与这个封装的对象进行交流和交互\",{\"1\":{\"69\":1}}],[\"系统部署\",{\"1\":{\"19\":1}}],[\"系统开发\",{\"1\":{\"19\":1}}],[\"旨在统一\",{\"1\":{\"19\":1}}],[\"703\",{\"1\":{\"78\":1}}],[\"70b模型在很大程度上优于palm\",{\"1\":{\"18\":1}}],[\"70b模型相对于chatgpt的胜率为36\",{\"1\":{\"18\":1}}],[\"70b模型上的ppo每次迭代平均耗时≈330秒\",{\"1\":{\"14\":1}}],[\"70b参数llama\",{\"1\":{\"13\":1}}],[\"70b四种参数规模\",{\"1\":{\"1\":1}}],[\"768\",{\"1\":{\"45\":1}}],[\"7\",{\"0\":{\"32\":1},\"1\":{\"39\":1,\"55\":1,\"58\":1,\"76\":1,\"85\":2}}],[\"784044\",{\"1\":{\"22\":1}}],[\"7b\",{\"1\":{\"18\":1}}],[\"7b模型在60\",{\"1\":{\"18\":1}}],[\"差别很大吗\",{\"1\":{\"15\":1}}],[\"配备gatt的型号\",{\"1\":{\"15\":1}}],[\"王尔德\",{\"1\":{\"15\":1}}],[\"拿破仑\",{\"1\":{\"15\":1}}],[\"人类评价通常被认为是评判自然语言生成模型\",{\"1\":{\"18\":1}}],[\"人类评价\",{\"0\":{\"18\":1}}],[\"人类偏好注释一致率也更高\",{\"1\":{\"13\":1}}],[\"人类偏好数据收集\",{\"0\":{\"12\":1}}],[\"人物\",{\"1\":{\"15\":1}}],[\">settings\",{\"1\":{\"78\":1}}],[\">show\",{\"1\":{\"78\":1}}],[\">file\",{\"1\":{\"78\":1}}],[\">help\",{\"1\":{\"78\":1}}],[\">\",{\"1\":{\"15\":1,\"80\":2,\"89\":4}}],[\"使合并后的数组同样按\",{\"1\":{\"87\":1}}],[\"使得出现次数超过两次的元素只出现两次\",{\"1\":{\"85\":1}}],[\"使\",{\"1\":{\"83\":1}}],[\"使每个元素\",{\"1\":{\"83\":1}}],[\"使其构成一个不可分割的独立实体\",{\"1\":{\"69\":1}}],[\"使其不那么冗长\",{\"1\":{\"15\":1}}],[\"使用方法比较简单\",{\"1\":{\"89\":1}}],[\"使用封装的优点\",{\"0\":{\"70\":1}}],[\"使用automl框架\",{\"1\":{\"37\":1}}],[\"使用cml持续集成和部署机器学习\",{\"1\":{\"31\":1}}],[\"使用选定的输出进行梯度更新\",{\"1\":{\"14\":1}}],[\"使用一个特殊的令牌来分隔提示段和应答段\",{\"1\":{\"10\":1}}],[\"使用了余弦学习率\",{\"1\":{\"10\":1}}],[\"使用了\",{\"1\":{\"10\":1}}],[\"使用了来自sentencepiece的实现\",{\"1\":{\"7\":1}}],[\"使用与llama\",{\"1\":{\"7\":1}}],[\"使用0\",{\"1\":{\"6\":1,\"14\":1}}],[\"要复制到的数组\",{\"1\":{\"89\":1}}],[\"要注意这是一道双指针题目\",{\"1\":{\"84\":1}}],[\"要求预训练语言模型预测被masked的标注\",{\"1\":{\"56\":1}}],[\"要求模型扮演训练中没有遇到的人\",{\"1\":{\"15\":1}}],[\"要么好到可以忽略不计\",{\"1\":{\"12\":1}}],[\"要么稍微好一点\",{\"1\":{\"12\":1}}],[\"要么更好\",{\"1\":{\"12\":1}}],[\"要么他们的选择明显更好\",{\"1\":{\"12\":1}}],[\"语言模型的实验结果表明\",{\"1\":{\"62\":1}}],[\"语言模型\",{\"1\":{\"44\":1,\"50\":1}}],[\"语言\",{\"1\":{\"15\":1}}],[\"爱好\",{\"1\":{\"15\":1}}],[\"但输出的答案是数组呢\",{\"1\":{\"84\":1,\"85\":1}}],[\"但不能说动物是猫就是这个道理\",{\"1\":{\"71\":1}}],[\"但不能选择性地继承父类\",{\"1\":{\"71\":1}}],[\"但可以通过该对象对外的提供的接口来访问该对象\",{\"1\":{\"69\":1}}],[\"但可以说\",{\"1\":{\"17\":1}}],[\"但并不是一个实际的语言模型\",{\"1\":{\"44\":1}}],[\"但是它跟jdk中其他的native方法实现地方不同\",{\"1\":{\"89\":1}}],[\"但是不一定\",{\"1\":{\"89\":1}}],[\"但是如果从头开始看\",{\"1\":{\"85\":1}}],[\"但是如果尝试使用o\",{\"1\":{\"82\":1}}],[\"但是如果强制把超类转换成子类的话\",{\"1\":{\"76\":1}}],[\"但是部分内容被隐藏的类时\",{\"1\":{\"80\":1}}],[\"但是这个被调用的方法必须是在超类中定义过的\",{\"1\":{\"76\":1}}],[\"但是用mps会失败\",{\"1\":{\"60\":1}}],[\"但是最终似乎并没有成功\",{\"1\":{\"60\":1}}],[\"但是最大的t5模型达到了11b\",{\"1\":{\"39\":1}}],[\"但是其性能并没有p\",{\"1\":{\"57\":1}}],[\"但是其性能仍然不如全参数微调\",{\"1\":{\"55\":1}}],[\"但是其自然语言理解能力非常强\",{\"1\":{\"39\":1}}],[\"但是全参数微调的设备需求仍然很大\",{\"1\":{\"55\":1}}],[\"但是都有自己的创新点\",{\"1\":{\"54\":1}}],[\"但是glm没有这样做\",{\"1\":{\"52\":1}}],[\"但是在当时\",{\"1\":{\"45\":1}}],[\"但是在解码阶段\",{\"1\":{\"43\":1}}],[\"但是单纯的multi\",{\"1\":{\"43\":1}}],[\"但是\",{\"1\":{\"43\":1,\"54\":1,\"55\":1}}],[\"但是微调参数量仅为全参数微调的3\",{\"1\":{\"39\":1}}],[\"但是语言模型的研究并不是最近才兴起的\",{\"1\":{\"39\":1}}],[\"但您也可以将其用于再现性\",{\"1\":{\"23\":1}}],[\"但这会导致系统消息\",{\"1\":{\"15\":1}}],[\"但在生成过程中会导致很大的减慢\",{\"1\":{\"14\":1}}],[\"所谓多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定\",{\"1\":{\"73\":1}}],[\"所谓二维编码\",{\"1\":{\"53\":1}}],[\"所提出的机制也可以写成rnn\",{\"1\":{\"64\":1}}],[\"所替代\",{\"1\":{\"52\":1}}],[\"所以也省了一些开销\",{\"1\":{\"89\":1}}],[\"所以米窗3选择了zygoteloader\",{\"1\":{\"80\":1}}],[\"所以米窗3采用了将自定义系统服务添加到scache中的做法\",{\"1\":{\"80\":1}}],[\"所以需要走else\",{\"1\":{\"80\":1}}],[\"所以对于多态我们可以总结如下\",{\"1\":{\"73\":1}}],[\"所以s~z~的顺序是随机打乱的\",{\"1\":{\"52\":1}}],[\"所以masked掉多个字\",{\"1\":{\"52\":1}}],[\"所以效果不是很好\",{\"1\":{\"51\":1}}],[\"所以这里就用了masked自注意力机制\",{\"1\":{\"43\":1}}],[\"所以\",{\"1\":{\"43\":1,\"53\":1,\"87\":1,\"89\":1}}],[\"所以语言模型方向模型参数规模越来越大\",{\"1\":{\"39\":1}}],[\"所示\",{\"1\":{\"15\":1}}],[\"所有较小的模型都根据较大模型的拒绝采样数据进行微调\",{\"1\":{\"14\":1}}],[\"它会打印出数组中\",{\"1\":{\"84\":1,\"85\":1}}],[\"它只能访问父类中拥有的方法和属性\",{\"1\":{\"73\":1}}],[\"它除了拥有被继承者的特性外\",{\"1\":{\"71\":1}}],[\"它有三种计算范式\",{\"1\":{\"62\":1}}],[\"它不仅只在embedding层进行微调\",{\"1\":{\"57\":1}}],[\"它必须是确定性的\",{\"1\":{\"43\":1}}],[\"它的实现对子类是完全透明的\",{\"1\":{\"72\":1}}],[\"它的值应该是有界的\",{\"1\":{\"43\":1}}],[\"它的功能之一\",{\"1\":{\"36\":1}}],[\"它能为每个时间步输出一个独一无二的编码\",{\"1\":{\"43\":1}}],[\"它们均基于prefix\",{\"1\":{\"55\":1}}],[\"它们整体相似\",{\"1\":{\"54\":1}}],[\"它们各有各的擅长之处\",{\"1\":{\"51\":1}}],[\"它们各有优缺点\",{\"1\":{\"44\":1}}],[\"它们分别代表query\",{\"1\":{\"42\":1}}],[\"它们都足够复杂\",{\"1\":{\"41\":1}}],[\"它与语言和框架无关\",{\"1\":{\"36\":1}}],[\"它与git无缝协作\",{\"1\":{\"31\":1}}],[\"它检查数据和模型质量\",{\"1\":{\"34\":1}}],[\"它通过提供可扩展的端点来管理负载\",{\"1\":{\"33\":1}}],[\"它通过运行并行推理和自适应批处理来扩展强大的优化功能\",{\"1\":{\"32\":1}}],[\"它通常用于实验跟踪\",{\"1\":{\"23\":1}}],[\"它是通过动态绑定来实现的\",{\"1\":{\"73\":1}}],[\"它是根据参数列表的不同来区分不同的函数\",{\"1\":{\"73\":1}}],[\"它是t5提出的一个统一框架\",{\"1\":{\"49\":1}}],[\"它是注意力机制的一种\",{\"1\":{\"43\":1}}],[\"它是一个mlops工具\",{\"1\":{\"33\":1}}],[\"它是一个开源\",{\"1\":{\"33\":1}}],[\"它是一个开源的轻量级工具\",{\"1\":{\"28\":1}}],[\"它是一个python优先的工具\",{\"1\":{\"32\":1}}],[\"它是为数据科学家构建的\",{\"1\":{\"29\":1}}],[\"它为您提供了对本地prefect\",{\"1\":{\"28\":1}}],[\"它还允许人们调度和管理一个ml管道的不同阶段\",{\"1\":{\"24\":1}}],[\"它还可用于编排数据工程作业\",{\"1\":{\"21\":1}}],[\"它就像一个仪表盘\",{\"1\":{\"23\":1}}],[\"它提供了一个高级的实验跟踪功能\",{\"1\":{\"23\":1}}],[\"它允许端到端管理ml生命周期\",{\"1\":{\"23\":1}}],[\"它可能偏向于llama\",{\"1\":{\"17\":1}}],[\"它可以破解微调数据\",{\"1\":{\"15\":1}}],[\"它采用了字节对编码\",{\"1\":{\"7\":1}}],[\"某个公众人物\",{\"1\":{\"15\":1}}],[\"扮演奥斯卡\",{\"1\":{\"15\":1}}],[\"扮演例如拿破仑\",{\"1\":{\"15\":1}}],[\"扮演\",{\"1\":{\"15\":2}}],[\"或者说单向模型和双向模型谁好谁坏\",{\"1\":{\"44\":1}}],[\"或卷积神经网络\",{\"1\":{\"41\":1}}],[\"或公众人物\",{\"1\":{\"15\":1}}],[\"或\",{\"1\":{\"15\":1,\"84\":1}}],[\"或具有8kv投影的分组查询注意力\",{\"1\":{\"5\":1}}],[\"一致\",{\"1\":{\"83\":1}}],[\"一种并行表示和循环表示的混合形式可用于加速训练\",{\"1\":{\"64\":1}}],[\"一层一层地计算\",{\"1\":{\"63\":1}}],[\"一般masked掉的是一个词\",{\"1\":{\"52\":1}}],[\"一般会mask掉句子的15\",{\"1\":{\"47\":1}}],[\"一\",{\"0\":{\"39\":1,\"69\":1}}],[\"一个字可能意义不如多个字组成的意义大\",{\"1\":{\"52\":1}}],[\"一个双向编码语言模型\",{\"1\":{\"44\":1}}],[\"一个encoder单元\",{\"1\":{\"43\":1}}],[\"一个好的位置编码方案需要满足以下几个条件\",{\"1\":{\"43\":1}}],[\"一个序列转换\",{\"1\":{\"41\":1}}],[\"一个模型注册表和模型服务组件\",{\"1\":{\"23\":1}}],[\"一个多卡并行训练的论文\",{\"1\":{\"5\":1}}],[\"一些指示应适用于所有的对话轮数中\",{\"1\":{\"15\":1}}],[\"恢复训练循环的其余部分来缓解这种情况\",{\"1\":{\"14\":1}}],[\"≈20×\",{\"1\":{\"14\":1}}],[\"正规化r为r~nm​=rnm​\",{\"1\":{\"65\":1}}],[\"正规化qkt为qkt\",{\"1\":{\"65\":1}}],[\"正是bert\",{\"1\":{\"44\":1}}],[\"正向或反向传播时是有效的\",{\"1\":{\"14\":1}}],[\"正如预期的那样\",{\"1\":{\"14\":1,\"17\":1}}],[\"09685\",{\"1\":{\"58\":1}}],[\"074\",{\"1\":{\"58\":1}}],[\"00190\",{\"1\":{\"58\":1}}],[\"001模型\",{\"1\":{\"18\":1}}],[\"005\",{\"1\":{\"14\":1}}],[\"0301型号\",{\"1\":{\"18\":1}}],[\"01\",{\"1\":{\"14\":1}}],[\"0\",{\"0\":{\"80\":1},\"1\":{\"14\":1,\"53\":1,\"80\":1,\"83\":5,\"84\":12,\"85\":7,\"87\":10,\"89\":12}}],[\"0的梯度剪裁\",{\"1\":{\"6\":1,\"14\":1}}],[\"我们现在想要将nums1的内容复制到nums2中\",{\"1\":{\"89\":1}}],[\"我们稍后介绍\",{\"1\":{\"89\":1}}],[\"我们很难处理\",{\"1\":{\"80\":1}}],[\"我们需要使用binderservice的实例的classloader来加载dms类\",{\"1\":{\"80\":1}}],[\"我们需要给米窗3所需要执行的内容编写selinux规则\",{\"1\":{\"80\":1}}],[\"我们定义layer为\",{\"1\":{\"65\":1}}],[\"我们在不同的层之间设置了相同的γ\",{\"1\":{\"65\":1}}],[\"我们通过以下方法计算第i个块的retention输出\",{\"1\":{\"64\":1}}],[\"我们遵循并行表示\",{\"1\":{\"64\":1}}],[\"我们将输入序列划分成块\",{\"1\":{\"64\":1}}],[\"我们将在下面介绍这一部分\",{\"1\":{\"45\":1}}],[\"我们递归地得到的输出为\",{\"1\":{\"64\":1}}],[\"我们进一步地把γ简化为一个标量\",{\"1\":{\"64\":1}}],[\"我们进一步讨论transformer中应用的注意力机制\",{\"1\":{\"43\":1}}],[\"我们把矩阵a对角化\",{\"1\":{\"64\":1}}],[\"我们把它投影到一维函数v\",{\"1\":{\"64\":1}}],[\"我们使用投影qn​\",{\"1\":{\"64\":1}}],[\"我们使用512的批量大小\",{\"1\":{\"14\":1}}],[\"我们规定vn​=v\",{\"1\":{\"64\":1}}],[\"我们可以调用system\",{\"1\":{\"88\":1}}],[\"我们可以针对特殊情况\",{\"1\":{\"88\":1}}],[\"我们可以通过反射的方式获取到外部类的实例\",{\"1\":{\"80\":1}}],[\"我们可以通过servicemanager\",{\"1\":{\"80\":1}}],[\"我们可以直接通过servicemanager获取到binderservice\",{\"1\":{\"80\":1}}],[\"我们可以抽象出他们共有的行为或者属相并将其定义成一个父类或者超类\",{\"1\":{\"71\":1}}],[\"我们可以重写\",{\"1\":{\"64\":1}}],[\"我们可以使用\",{\"1\":{\"56\":1}}],[\"我们可以将样本与提示\",{\"1\":{\"56\":1}}],[\"我们可以看图5\",{\"1\":{\"52\":1}}],[\"我们可以看到\",{\"1\":{\"13\":1,\"15\":1}}],[\"我们选择p\",{\"1\":{\"55\":1}}],[\"我们介绍微调相关技术\",{\"1\":{\"54\":1}}],[\"我们称之为masked\",{\"1\":{\"52\":1}}],[\"我们给定一个文本序列\",{\"1\":{\"52\":1}}],[\"我们来介绍glm中的自回归填空思想\",{\"1\":{\"51\":1}}],[\"我们来讨论多头注意力机制\",{\"1\":{\"43\":1}}],[\"我们无法评价自回归\",{\"1\":{\"44\":1}}],[\"我们知道\",{\"1\":{\"44\":1,\"51\":1}}],[\"我们希望自注意力机制是\",{\"1\":{\"43\":1}}],[\"我们对注意力机制有了初步了解\",{\"1\":{\"43\":1}}],[\"我们往往会讨论q\",{\"1\":{\"42\":1}}],[\"我们首先讨论一下注意力机制\",{\"1\":{\"41\":1}}],[\"我们的目标不是重新创建其他服务\",{\"1\":{\"22\":1}}],[\"我们设置β=0\",{\"1\":{\"14\":1}}],[\"null\",{\"1\":{\"80\":4}}],[\"nums2\",{\"1\":{\"87\":8,\"89\":7}}],[\"nums1的实际数组长度为0时\",{\"1\":{\"88\":1}}],[\"nums1\",{\"1\":{\"87\":14,\"89\":10}}],[\"nums中的前两个元素均为\",{\"1\":{\"84\":1}}],[\"nums\",{\"1\":{\"81\":5,\"83\":20,\"84\":13,\"85\":11}}],[\"num\",{\"1\":{\"64\":12}}],[\"n−mkmt​vm​\",{\"1\":{\"64\":1}}],[\"n−mλ−1\",{\"1\":{\"64\":1}}],[\"native\",{\"1\":{\"89\":1}}],[\"natural\",{\"1\":{\"58\":2}}],[\"naturally\",{\"1\":{\"13\":1}}],[\"name\",{\"1\":{\"80\":4}}],[\"naman\",{\"1\":{\"58\":1}}],[\"nan\",{\"1\":{\"58\":1}}],[\"narasimhan\",{\"1\":{\"58\":1}}],[\"narang\",{\"1\":{\"58\":1}}],[\"naacl\",{\"1\":{\"58\":1}}],[\"niki\",{\"1\":{\"58\":1}}],[\"nlg\",{\"1\":{\"57\":1}}],[\"nlu\",{\"1\":{\"57\":1}}],[\"nlp\",{\"1\":{\"49\":1,\"58\":1}}],[\"nlp经历了什么\",{\"0\":{\"38\":1}}],[\"nsp的位置在bert模型图中有所体现\",{\"1\":{\"47\":1}}],[\"nsp是一个二分类下句预测任务\",{\"1\":{\"47\":1}}],[\"newinstance\",{\"1\":{\"80\":1}}],[\"new\",{\"1\":{\"76\":5,\"80\":3}}],[\"networks\",{\"0\":{\"63\":1}}],[\"network\",{\"1\":{\"61\":1,\"63\":1}}],[\"neural\",{\"1\":{\"58\":1}}],[\"need\",{\"1\":{\"58\":1,\"80\":1}}],[\"next\",{\"1\":{\"47\":1}}],[\"neptune\",{\"1\":{\"36\":2}}],[\"n\",{\"1\":{\"45\":2,\"58\":1,\"62\":1,\"64\":7,\"81\":5,\"82\":1,\"87\":12,\"89\":9}}],[\"noah\",{\"1\":{\"58\":1}}],[\"noam\",{\"1\":{\"58\":2}}],[\"norm\",{\"1\":{\"43\":1,\"64\":3}}],[\"not\",{\"1\":{\"43\":2}}],[\"n=6\",{\"1\":{\"43\":1}}],[\"n个样本\",{\"1\":{\"14\":1}}],[\"右侧是使用gatt优化后的结果\",{\"1\":{\"15\":1}}],[\"右\",{\"1\":{\"14\":1,\"15\":2}}],[\"左右\",{\"1\":{\"39\":1}}],[\"左\",{\"1\":{\"14\":1,\"15\":1}}],[\"温度参数对勘探也起着重要作用\",{\"1\":{\"14\":1}}],[\"探索和作者能在样本中获得的最大回报之间有着直接的联系\",{\"1\":{\"14\":1}}],[\"产生良好轨迹的机会更多\",{\"1\":{\"14\":1}}],[\"因为\",{\"1\":{\"87\":1}}],[\"因为没有注册服务\",{\"1\":{\"80\":1}}],[\"因为获取dms后执行的操作均在java层完成\",{\"1\":{\"80\":1}}],[\"因为我们的自定义系统服务不在scache中\",{\"1\":{\"80\":1}}],[\"因为它处于无限重启状态\",{\"1\":{\"77\":1}}],[\"因为在程序运行时才确定具体的类\",{\"1\":{\"73\":1}}],[\"因为在微调的过程中\",{\"1\":{\"47\":1}}],[\"因为每个step的复杂度都是o\",{\"1\":{\"62\":1}}],[\"因为gelus效果更好\",{\"1\":{\"54\":1}}],[\"因为这里的上下文\",{\"1\":{\"47\":1}}],[\"因为三角函数具有周期性\",{\"1\":{\"43\":1}}],[\"因为transformer抛弃了rnn和cnn\",{\"1\":{\"43\":1}}],[\"因为transformer需要判断序列中词与词之间的关系强度\",{\"1\":{\"42\":1}}],[\"因为更高的温度使作者能够对更多样的输出进行采样\",{\"1\":{\"14\":1}}],[\"因为最大值增加\",{\"1\":{\"14\":1}}],[\"因此segment\",{\"1\":{\"46\":1}}],[\"因此难免需要兼顾到各种nlp任务场景下的输入\",{\"1\":{\"46\":1}}],[\"因此他们可以专注于构建模型\",{\"1\":{\"29\":1}}],[\"因此\",{\"1\":{\"10\":1,\"14\":1,\"17\":1,\"39\":1,\"43\":1,\"44\":1,\"62\":1}}],[\"拒绝采样的介绍\",{\"1\":{\"14\":1}}],[\"拒绝采样微调\",{\"1\":{\"14\":1}}],[\"两种rl算法之间的基本差异就不那么明显了\",{\"1\":{\"14\":1}}],[\"样本是前一步骤的梯度更新后从t−1更新的模型策略的函数\",{\"1\":{\"14\":1}}],[\"深度\",{\"1\":{\"14\":1}}],[\"而其他的会在jdk库中实现\",{\"1\":{\"89\":1}}],[\"而属于hotspot\",{\"1\":{\"89\":1}}],[\"而无需逐一比较\",{\"1\":{\"88\":1}}],[\"而\",{\"1\":{\"84\":1}}],[\"而非inout\",{\"1\":{\"80\":1}}],[\"而dms类在该jar包中\",{\"1\":{\"80\":1}}],[\"而在日常使用时\",{\"1\":{\"80\":1}}],[\"而在计算方式上\",{\"1\":{\"42\":1}}],[\"而运行时多态是动态的\",{\"1\":{\"73\":1}}],[\"而且\",{\"1\":{\"65\":1}}],[\"而对于子类中存在而父类中不存在的方法\",{\"1\":{\"73\":1}}],[\"而对glm进行微调同样还可以使用lora\",{\"1\":{\"57\":1}}],[\"而对ppo只进行一次生成\",{\"1\":{\"14\":1}}],[\"而如果改为使用p\",{\"1\":{\"57\":1}}],[\"而另外10\",{\"1\":{\"52\":1}}],[\"而另一边的openai也不甘落后\",{\"1\":{\"39\":1}}],[\"而glm中可能会masked掉连续的多个字\",{\"1\":{\"52\":1}}],[\"而gpt模型是自回归模型\",{\"1\":{\"50\":1}}],[\"而与bert等masked不同\",{\"1\":{\"52\":1}}],[\"而每一个文本域都会被一个单独的token\",{\"1\":{\"52\":1}}],[\"而自编码模型擅长自然语言理解任务\",{\"1\":{\"51\":1}}],[\"而自编码模型更加适合自然语言理解任务\",{\"1\":{\"44\":1}}],[\"而bert的位置编码\",{\"1\":{\"46\":1}}],[\"而首个将transformer应用到实际语言模型中的\",{\"1\":{\"44\":1}}],[\"而多头注意力机制是由缩放点积注意力机制\",{\"1\":{\"43\":1}}],[\"而是存储在数组\",{\"1\":{\"87\":1}}],[\"而是在程序运行期间才确定\",{\"1\":{\"73\":1}}],[\"而是在每一层都进行微调\",{\"1\":{\"57\":1}}],[\"而是将其放到了part\",{\"1\":{\"52\":1}}],[\"而是做了一些修改\",{\"1\":{\"50\":1}}],[\"而是其decoder部分\",{\"1\":{\"50\":1}}],[\"而是采用的mlm\",{\"1\":{\"47\":1}}],[\"而是只用到了encoder部分\",{\"1\":{\"45\":1}}],[\"而是用这个向量让每个词具有它在句子序列中的位置信息\",{\"1\":{\"43\":1}}],[\"而是包含句子中特定位置信息的d维向量\",{\"1\":{\"43\":1}}],[\"而是提供一种直接的方法\",{\"1\":{\"22\":1}}],[\"而transformer\",{\"1\":{\"41\":1}}],[\"而2020年\",{\"1\":{\"39\":1}}],[\"而不能看到它之后的token\",{\"1\":{\"44\":1}}],[\"而不是担心mlops工程\",{\"1\":{\"29\":1}}],[\"而不是用指令来增加所有上下文对话回合\",{\"1\":{\"15\":1}}],[\"而不会导致性能大幅下降\",{\"1\":{\"5\":1}}],[\"而中值保持不变\",{\"1\":{\"14\":1}}],[\"广度\",{\"1\":{\"14\":1}}],[\"以o\",{\"1\":{\"66\":1}}],[\"以增加retention\",{\"1\":{\"65\":1}}],[\"以增强通用性\",{\"1\":{\"57\":1}}],[\"以增强奖励\",{\"1\":{\"14\":1}}],[\"以胜任多种自然语言处理任务\",{\"1\":{\"51\":1}}],[\"以下是其其他关键功能\",{\"1\":{\"36\":1}}],[\"以及任何规模\",{\"1\":{\"30\":1}}],[\"以及4000多个单回合和多回合提示的闭源模型\",{\"1\":{\"18\":1}}],[\"以促进构建\",{\"1\":{\"24\":1}}],[\"以标准化过程生产高性能模型的持续交付\",{\"1\":{\"19\":1}}],[\"以避免任何偏差\",{\"1\":{\"17\":1}}],[\"以避免教学和模型知识之间的不匹配\",{\"1\":{\"15\":1}}],[\"以评估哪一代是优选的\",{\"1\":{\"17\":1}}],[\"以帮助在多阶段过程中集中注意力\",{\"1\":{\"15\":1}}],[\"以提前停止\",{\"1\":{\"14\":1}}],[\"以收集新的数据集\",{\"1\":{\"14\":1}}],[\"以上的训练\",{\"1\":{\"2\":1}}],[\"其次\",{\"1\":{\"62\":1}}],[\"其主要结果如下\",{\"1\":{\"57\":1}}],[\"其主要的修改如下\",{\"1\":{\"45\":1}}],[\"其事实上是将文本生成的prefix\",{\"1\":{\"57\":1}}],[\"其在挖掘语言模型的潜在能力上有着不错的成绩\",{\"1\":{\"55\":1}}],[\"其实对于这个我们将其称之为\",{\"1\":{\"71\":1}}],[\"其实在bert中也是这样做的\",{\"1\":{\"52\":1}}],[\"其实multi\",{\"1\":{\"43\":1}}],[\"其通用性体现在哪里\",{\"1\":{\"51\":1}}],[\"其优良的效果源于其创新的思想和持续的研究\",{\"1\":{\"51\":1}}],[\"其参数规模进一步增大\",{\"1\":{\"50\":1}}],[\"其参数量已经达到了175b\",{\"1\":{\"39\":1}}],[\"其参数量有1\",{\"1\":{\"39\":1}}],[\"其参数量有117m\",{\"1\":{\"39\":1}}],[\"其余基本没有变化\",{\"1\":{\"50\":1}}],[\"其余参数为1×10−5\",{\"1\":{\"13\":1}}],[\"其成功的关键在于超大的参数规模\",{\"1\":{\"50\":1}}],[\"其能力大家有目共睹\",{\"1\":{\"48\":1,\"50\":1}}],[\"其本质就是通过一个普通的词嵌入来区分每一个序列所处的位置\",{\"1\":{\"46\":1}}],[\"其计算公式如下\",{\"1\":{\"43\":1}}],[\"其计算过程与注意力机制一致\",{\"1\":{\"43\":1}}],[\"其比独热编码\",{\"1\":{\"43\":1}}],[\"其结构可以分为输入输出嵌入向量\",{\"1\":{\"43\":1}}],[\"其抛弃了rnn和cnn作为encoder和decoder\",{\"1\":{\"43\":1}}],[\"其组件hydrosphere\",{\"1\":{\"36\":1}}],[\"其中斜体加粗标注的为\",{\"1\":{\"87\":1}}],[\"其中前\",{\"1\":{\"87\":1}}],[\"其中编辑时多态是静态的\",{\"1\":{\"73\":1}}],[\"其中b是被继承者称之为父类或者超类\",{\"1\":{\"71\":1}}],[\"其中d表示头维度\",{\"1\":{\"65\":1}}],[\"其中\",{\"1\":{\"64\":2}}],[\"其中qn​∈r1×d\",{\"1\":{\"64\":1}}],[\"其中a∈rd×d\",{\"1\":{\"64\":1}}],[\"其中只有80\",{\"1\":{\"52\":1}}],[\"其中x~corrupt~就是parta\",{\"1\":{\"52\":1}}],[\"其中s~1~对应着\",{\"1\":{\"52\":1}}],[\"其中每个文本域s~i\",{\"1\":{\"52\":1}}],[\"其中的情况b确实为a的下一句话\",{\"1\":{\"47\":1}}],[\"其中蓝色阴影部分\",{\"1\":{\"45\":1}}],[\"其中因为内容相对重复\",{\"1\":{\"38\":1}}],[\"其中transformer是一种全新的序列转换模型\",{\"1\":{\"38\":1}}],[\"其中un和an分别对应于回合n的用户和助手消息\",{\"1\":{\"15\":1}}],[\"其中β1=0\",{\"1\":{\"14\":1}}],[\"其中n∈\",{\"1\":{\"14\":1}}],[\"其中奖励被视为能量函数\",{\"1\":{\"14\":1}}],[\"hiddenapi冲突\",{\"1\":{\"80\":1}}],[\"hiddenapibypass\",{\"1\":{\"80\":1}}],[\"history和provenance来跟踪和版本化数据集\",{\"1\":{\"30\":1}}],[\"hook\",{\"1\":{\"80\":1}}],[\"hon\",{\"1\":{\"58\":1}}],[\"hotspot\",{\"1\":{\"89\":1}}],[\"hot\",{\"1\":{\"43\":1}}],[\"hsiao\",{\"1\":{\"58\":1}}],[\"hangbo\",{\"1\":{\"58\":1}}],[\"harmlessness\",{\"1\":{\"14\":1,\"15\":1}}],[\"hu\",{\"1\":{\"58\":1}}],[\"huang\",{\"1\":{\"58\":1}}],[\"html\",{\"1\":{\"58\":1}}],[\"http\",{\"1\":{\"37\":1,\"58\":1}}],[\"https\",{\"1\":{\"20\":1,\"21\":1,\"22\":4,\"23\":2,\"24\":1,\"26\":1,\"27\":1,\"28\":1,\"30\":1,\"31\":1,\"32\":3,\"33\":1,\"34\":2,\"35\":1,\"36\":2,\"60\":1}}],[\"h\",{\"1\":{\"45\":2}}],[\"height\",{\"1\":{\"80\":2}}],[\"headi​\",{\"1\":{\"65\":1}}],[\"head\",{\"1\":{\"43\":6,\"62\":1,\"64\":12,\"65\":1}}],[\"helpfulness\",{\"1\":{\"13\":2}}],[\"hydrosphere还提供与当前机器学习流程的快速合并\",{\"1\":{\"36\":1}}],[\"hydrosphere允许用户提供在任何框架中开发的模型\",{\"1\":{\"36\":1}}],[\"hydrosphere对贡献发生变化的时间给出了明确的解释\",{\"1\":{\"36\":1}}],[\"hydrosphere提供了模型预测的简单摘要\",{\"1\":{\"36\":1}}],[\"hydrosphere是一个用于在生产环境中部署\",{\"1\":{\"36\":1}}],[\"hydrosphere\",{\"0\":{\"36\":1},\"1\":{\"36\":3}}],[\"hl=zh\",{\"1\":{\"20\":1}}],[\"该算法题的实现如下\",{\"1\":{\"89\":1}}],[\"该算法是rlhf文献的标准\",{\"1\":{\"14\":1}}],[\"该题来自力扣第88题\",{\"1\":{\"86\":1}}],[\"该题来自力扣27题\",{\"1\":{\"84\":1}}],[\"该题来自力扣26题\",{\"1\":{\"83\":1}}],[\"该长度范围内\",{\"1\":{\"84\":1,\"85\":1}}],[\"该类是displaymanagerservice的内部类\",{\"1\":{\"80\":1}}],[\"该类继承自imifreeformservice\",{\"1\":{\"80\":1}}],[\"该库额外提供了代理systemservice的功能\",{\"1\":{\"80\":1}}],[\"该服务是一个binder\",{\"1\":{\"80\":1}}],[\"该方法定义如下\",{\"1\":{\"89\":1}}],[\"该方法位于java\",{\"1\":{\"89\":1}}],[\"该方法微调效果可以与全参数微调媲美\",{\"1\":{\"39\":1}}],[\"该方式实现最佳\",{\"1\":{\"80\":1}}],[\"该引用是不能使用的\",{\"1\":{\"73\":1}}],[\"该引用变量发出的方法调用到底是哪个类中实现的方法\",{\"1\":{\"73\":1}}],[\"该公式在训练实例中很容易被并行化\",{\"1\":{\"64\":1}}],[\"该实现比较简单\",{\"1\":{\"62\":1}}],[\"该issue讨论了glm在apple芯片上微调的内容\",{\"1\":{\"60\":1}}],[\"该编码没有整合进模型\",{\"1\":{\"43\":1}}],[\"该编码不是一个单一的数值\",{\"1\":{\"43\":1}}],[\"该脉络基本涉及了现代语言模型学习的全过程\",{\"1\":{\"39\":1}}],[\"该模型号称是\",{\"1\":{\"39\":1}}],[\"该模型为给定提示探索k个样本\",{\"1\":{\"14\":1}}],[\"该平台提供了一个配置框架和众多共享库\",{\"1\":{\"20\":1}}],[\"该数据集具有消息列表\",{\"1\":{\"15\":1}}],[\"该论文篇幅巨大\",{\"1\":{\"0\":1}}],[\"迭代微调\",{\"0\":{\"14\":1}}],[\"学习对人类偏好进行建模将变得具有挑战性\",{\"1\":{\"13\":1}}],[\"学习率按余弦学习率计划降低\",{\"1\":{\"13\":1}}],[\"当nums1处理完之后\",{\"1\":{\"88\":1}}],[\"当米窗3想要实例化上述字段来获取dms实例时\",{\"1\":{\"80\":1}}],[\"当超类对象引用变量引用子类对象时\",{\"1\":{\"76\":1}}],[\"当时提出transformer架构是为了克服基于rnn的模型的无法并行训练的问题\",{\"1\":{\"62\":1}}],[\"当然\",{\"1\":{\"44\":1,\"51\":1}}],[\"当前的token只能看到它和它之前的token\",{\"1\":{\"44\":1}}],[\"当您想要跟踪机器学习模型的性能时\",{\"1\":{\"23\":1}}],[\"当在10到100个输出之间采样时\",{\"1\":{\"14\":1}}],[\"当在两个相似的模型反应之间做出决定时\",{\"1\":{\"13\":1}}],[\"当作者在表8中按偏好评级对分数进行分组时\",{\"1\":{\"13\":1}}],[\"稍微好一点\",{\"1\":{\"13\":1}}],[\"例如我们可以说猫是动物\",{\"1\":{\"71\":1}}],[\"例如猫有抓老鼠\",{\"1\":{\"71\":1}}],[\"例如在nsp任务中\",{\"1\":{\"46\":1}}],[\"例如keras\",{\"1\":{\"32\":1}}],[\"例如scikit\",{\"1\":{\"26\":1}}],[\"例如\",{\"1\":{\"13\":1,\"15\":5,\"20\":1,\"84\":1}}],[\"的介绍\",{\"0\":{\"89\":1}}],[\"的长度为\",{\"1\":{\"87\":1}}],[\"的初始长度为\",{\"1\":{\"87\":1}}],[\"的所有元素\",{\"1\":{\"84\":1,\"85\":1}}],[\"的大小不重要\",{\"1\":{\"83\":1}}],[\"的其余元素与\",{\"1\":{\"83\":1}}],[\"的前五个元素被修改为\",{\"1\":{\"83\":1}}],[\"的前两个元素被修改为\",{\"1\":{\"83\":1}}],[\"的前\",{\"1\":{\"83\":1}}],[\"的唯一元素的数量为\",{\"1\":{\"83\":1}}],[\"的算法解决此问题吗\",{\"1\":{\"87\":1}}],[\"的算法解决此问题\",{\"1\":{\"81\":1}}],[\"的元素\",{\"1\":{\"81\":1,\"84\":1}}],[\"的数组\",{\"1\":{\"81\":1,\"83\":1}}],[\"的关系\",{\"1\":{\"71\":1}}],[\"的内存\",{\"1\":{\"62\":2}}],[\"的输入\",{\"1\":{\"52\":1}}],[\"的思想\",{\"1\":{\"52\":1}}],[\"的token来进行训练\",{\"1\":{\"47\":1}}],[\"的能力不是很强\",{\"1\":{\"39\":1}}],[\"的任务\",{\"1\":{\"39\":1}}],[\"的开源库\",{\"1\":{\"37\":1}}],[\"的\",{\"1\":{\"20\":1,\"43\":1}}],[\"的提示上优于mpt\",{\"1\":{\"18\":1}}],[\"的黄金标准\",{\"1\":{\"18\":1}}],[\"的胜率\",{\"1\":{\"17\":1}}],[\"的loss设置为0\",{\"1\":{\"15\":1}}],[\"的测试集\",{\"1\":{\"13\":1}}],[\"的warm\",{\"1\":{\"13\":1}}],[\"明显更好\",{\"1\":{\"13\":1}}],[\"总体胜率超过75\",{\"1\":{\"18\":1}}],[\"总体而言\",{\"1\":{\"13\":1}}],[\"总词汇大小为32k个标记\",{\"1\":{\"7\":1}}],[\"按他的来\",{\"1\":{\"13\":1}}],[\"有两种方法可以实现多态\",{\"1\":{\"75\":1}}],[\"有的学者尝试将注意力机制\",{\"1\":{\"41\":1}}],[\"有数据验证\",{\"1\":{\"20\":1}}],[\"有必要逐步重新调整温度\",{\"1\":{\"14\":1}}],[\"有效batch大小固定为512对\",{\"1\":{\"13\":1}}],[\"有用性\",{\"1\":{\"13\":1}}],[\"ui是一个开源\",{\"1\":{\"28\":1}}],[\"ui或prefect\",{\"1\":{\"28\":1}}],[\"untrusted\",{\"1\":{\"80\":1}}],[\"unsqueeze\",{\"1\":{\"64\":3}}],[\"understands\",{\"1\":{\"58\":1}}],[\"understanding\",{\"1\":{\"58\":2}}],[\"unilmv2\",{\"1\":{\"58\":1}}],[\"universally\",{\"1\":{\"58\":1}}],[\"unified\",{\"1\":{\"58\":2}}],[\"un\",{\"1\":{\"15\":1}}],[\"u1\",{\"1\":{\"15\":1}}],[\"up\",{\"1\":{\"13\":1}}],[\"uszkoreit\",{\"1\":{\"58\":2}}],[\"use\",{\"1\":{\"13\":1}}],[\"using\",{\"1\":{\"5\":1}}],[\"dmsclass\",{\"1\":{\"80\":1}}],[\"dms\",{\"1\":{\"80\":1}}],[\"dmodel​是隐层维数\",{\"1\":{\"63\":1,\"66\":1}}],[\"ddmlib\",{\"1\":{\"78\":1}}],[\"d​\",{\"1\":{\"65\":1}}],[\"dimension\",{\"1\":{\"65\":1}}],[\"dim=−2\",{\"1\":{\"64\":1}}],[\"dim\",{\"1\":{\"64\":9}}],[\"dipanjan\",{\"1\":{\"58\":1}}],[\"ding\",{\"1\":{\"58\":2}}],[\"display\",{\"1\":{\"80\":2}}],[\"displaymanagerservice\",{\"1\":{\"80\":4}}],[\"display系统服务是下面类的实例\",{\"1\":{\"80\":1}}],[\"display系统服务是一个binder\",{\"1\":{\"80\":1}}],[\"distinct\",{\"1\":{\"13\":1}}],[\"discrete\",{\"1\":{\"13\":1}}],[\"du\",{\"1\":{\"58\":3}}],[\"d\",{\"1\":{\"43\":1,\"45\":3,\"65\":1,\"76\":9,\"80\":1}}],[\"dong\",{\"1\":{\"58\":1}}],[\"dot\",{\"1\":{\"43\":1}}],[\"do\",{\"1\":{\"43\":4}}],[\"docs\",{\"1\":{\"36\":1}}],[\"dvc不仅仅是一个数据跟踪和版本控制工具\",{\"1\":{\"31\":1}}],[\"dvc\",{\"0\":{\"31\":1},\"1\":{\"31\":1}}],[\"danqi\",{\"1\":{\"58\":1}}],[\"das\",{\"1\":{\"58\":1}}],[\"dags\",{\"1\":{\"21\":1}}],[\"datacamp\",{\"1\":{\"25\":1}}],[\"data\",{\"0\":{\"31\":1},\"1\":{\"14\":1,\"31\":1}}],[\"destpos\",{\"1\":{\"89\":2}}],[\"dest\",{\"1\":{\"89\":2}}],[\"densitydpi\",{\"1\":{\"80\":2}}],[\"dex\",{\"1\":{\"80\":2}}],[\"debugging来解决\",{\"1\":{\"78\":1}}],[\"deployment选项中的debugger\",{\"1\":{\"78\":1}}],[\"default\",{\"1\":{\"80\":2}}],[\"def\",{\"1\":{\"64\":3}}],[\"definition\",{\"1\":{\"19\":1}}],[\"deep\",{\"1\":{\"58\":1}}],[\"decomposable\",{\"1\":{\"58\":1}}],[\"decoder结构\",{\"1\":{\"50\":1}}],[\"decoder中的multi\",{\"1\":{\"43\":1}}],[\"decoder中decoder单元数n=6\",{\"1\":{\"43\":1}}],[\"decoder和encoder最大的区别\",{\"1\":{\"43\":1}}],[\"decoder模块等\",{\"1\":{\"43\":1}}],[\"decoder\",{\"1\":{\"41\":1,\"43\":1}}],[\"decay\",{\"1\":{\"14\":1,\"64\":10}}],[\"devlin\",{\"1\":{\"58\":1}}],[\"devops管道和azure\",{\"1\":{\"25\":1}}],[\"devops管道是一个ci\",{\"1\":{\"24\":1}}],[\"devops\",{\"0\":{\"24\":1},\"1\":{\"24\":2}}],[\"developer\",{\"1\":{\"22\":1}}],[\"dev\",{\"1\":{\"19\":1,\"33\":1}}],[\"detailed\",{\"1\":{\"13\":1}}],[\"owncontentonly\",{\"1\":{\"80\":1}}],[\"os\",{\"1\":{\"80\":1}}],[\"oscar\",{\"1\":{\"15\":1,\"58\":1}}],[\"override\",{\"1\":{\"80\":1}}],[\"overlaydisplayadapter平行的自定义适配器\",{\"1\":{\"80\":1}}],[\"overview\",{\"1\":{\"19\":1}}],[\"o\",{\"1\":{\"76\":4,\"81\":2,\"82\":1,\"84\":1,\"85\":1,\"87\":1}}],[\"out\",{\"1\":{\"76\":9,\"80\":2}}],[\"output\",{\"1\":{\"13\":1,\"64\":10}}],[\"object\",{\"1\":{\"80\":2,\"89\":2}}],[\"obj\",{\"1\":{\"76\":4}}],[\"omer\",{\"1\":{\"58\":1}}],[\"ott\",{\"1\":{\"58\":1}}],[\"orion实例和工作流的深入了解\",{\"1\":{\"28\":1}}],[\"orion\",{\"1\":{\"28\":2}}],[\"org\",{\"1\":{\"21\":1,\"22\":1,\"23\":1,\"31\":1,\"58\":1}}],[\"optimized\",{\"1\":{\"58\":1}}],[\"optimizing\",{\"1\":{\"58\":1}}],[\"optimization\",{\"1\":{\"14\":1}}],[\"open\",{\"1\":{\"36\":1}}],[\"operations\",{\"1\":{\"19\":1}}],[\"ops\",{\"1\":{\"19\":1}}],[\"on​=m=1∑n​γn−m\",{\"1\":{\"64\":1}}],[\"on​=m=1∑n​qn​\",{\"1\":{\"64\":1}}],[\"on​=qn​sn​=m=1∑n​qn​an−mkmt​vm​\",{\"1\":{\"64\":1}}],[\"on​=o\",{\"1\":{\"64\":1}}],[\"onnx\",{\"1\":{\"32\":1}}],[\"on\",{\"1\":{\"13\":1,\"14\":1,\"58\":1}}],[\"one\",{\"1\":{\"13\":1,\"43\":1}}],[\"of\",{\"1\":{\"13\":1,\"43\":2,\"58\":6}}],[\"为什么返回数值是整数\",{\"1\":{\"84\":1,\"85\":1}}],[\"为什么通过反射获取displaymanagerservice时会抛出noclassdeffounderror异常\",{\"1\":{\"80\":1}}],[\"为什么用户程序仍然无法发现\",{\"1\":{\"80\":1}}],[\"为什么不能顺利添加自定义系统服务\",{\"1\":{\"80\":1}}],[\"为效果最好的\",{\"1\":{\"52\":1}}],[\"为bert模型的结构图\",{\"1\":{\"45\":1}}],[\"为一个两层的多层感知机\",{\"1\":{\"43\":1}}],[\"为您提供代码\",{\"1\":{\"31\":1}}],[\"为端到端ml管道的每个任务提供库\",{\"1\":{\"20\":1}}],[\"为此米窗3需要设法获取到dms实例\",{\"1\":{\"80\":1}}],[\"为此\",{\"1\":{\"13\":1,\"80\":4}}],[\"为了实现快速复制\",{\"1\":{\"88\":1}}],[\"为了减少处理时间耗费\",{\"1\":{\"88\":1}}],[\"为了减少微调的设备等资源的消耗\",{\"1\":{\"55\":1}}],[\"为了应对这种情况\",{\"1\":{\"87\":1}}],[\"为了让mda与dms可通过同一classloader加载\",{\"1\":{\"80\":1}}],[\"为了简单起见\",{\"1\":{\"65\":1}}],[\"为了简化\",{\"1\":{\"64\":1}}],[\"为了适应下游任务\",{\"1\":{\"54\":1}}],[\"为了抵消这个效果\",{\"1\":{\"43\":1}}],[\"为了评估主要模型版本的质量\",{\"1\":{\"18\":1}}],[\"为了进行公平的比较\",{\"1\":{\"17\":1}}],[\"为了说明gatt如何在微调过程中帮助重塑注意力\",{\"1\":{\"15\":1}}],[\"为了使指令更加复杂和多样化\",{\"1\":{\"15\":1}}],[\"为了获得兴趣爱好和公众人物的列表\",{\"1\":{\"15\":1}}],[\"为了解决这个问题\",{\"1\":{\"47\":2}}],[\"为了解决这个可能影响训练的问题\",{\"1\":{\"15\":1}}],[\"为了解决这些限制\",{\"1\":{\"15\":1}}],[\"为了快速进行大批量训练\",{\"1\":{\"14\":1}}],[\"为了训练奖励模型\",{\"1\":{\"13\":1}}],[\"为了最大限度地提高多样性\",{\"1\":{\"12\":1}}],[\"为了确保模型序列长度正确填充\",{\"1\":{\"10\":1}}],[\"利用这些信息来明确教导奖励模型为具有更多差异的世代分配更多不一致的分数可能是有用的\",{\"1\":{\"13\":1}}],[\"如surfacecontrol\",{\"1\":{\"80\":1}}],[\"如何获取到displaymanagerservice\",{\"1\":{\"80\":1}}],[\"如何与该自定义适配器进行通信\",{\"1\":{\"80\":1}}],[\"如miui\",{\"1\":{\"80\":1}}],[\"如\",{\"1\":{\"52\":1,\"80\":1}}],[\"如今\",{\"1\":{\"50\":1}}],[\"如果nums2中仍然还有数据没有处理怎么办\",{\"1\":{\"88\":1}}],[\"如果所有断言都通过\",{\"1\":{\"83\":1}}],[\"如果有两个对象a和b\",{\"1\":{\"71\":1}}],[\"如果position\",{\"1\":{\"53\":1}}],[\"如果这15\",{\"1\":{\"47\":1}}],[\"如果此时模型知道了某个词之后的信息\",{\"1\":{\"43\":1}}],[\"如果不考虑词在序列中的位置\",{\"1\":{\"43\":1}}],[\"如果不经过特殊处理\",{\"1\":{\"43\":1}}],[\"如图b\",{\"1\":{\"64\":1}}],[\"如图6\",{\"1\":{\"57\":2}}],[\"如图5\",{\"1\":{\"52\":1,\"53\":1}}],[\"如图4\",{\"1\":{\"50\":1}}],[\"如图3\",{\"1\":{\"45\":1}}],[\"如图2\",{\"1\":{\"41\":1,\"42\":2}}],[\"如图9\",{\"1\":{\"15\":1}}],[\"如第3\",{\"1\":{\"13\":1}}],[\"如下图左侧\",{\"1\":{\"15\":1}}],[\"如下图\",{\"1\":{\"10\":1}}],[\"θ∈rd\",{\"1\":{\"64\":1}}],[\"θ\",{\"1\":{\"13\":1}}],[\"ctx\",{\"1\":{\"80\":2}}],[\"createfreeform\",{\"1\":{\"80\":1}}],[\"createservice\",{\"1\":{\"80\":1}}],[\"cross\",{\"1\":{\"64\":2}}],[\"current\",{\"1\":{\"64\":5}}],[\"callback\",{\"1\":{\"80\":1}}],[\"cachedservicefetcher<infrarescanmanager>\",{\"1\":{\"80\":1}}],[\"cache\",{\"1\":{\"80\":3}}],[\"catch\",{\"1\":{\"80\":1}}],[\"cast\",{\"1\":{\"43\":2}}],[\"cannot\",{\"1\":{\"78\":1}}],[\"can\",{\"1\":{\"13\":2,\"58\":1}}],[\"censius\",{\"0\":{\"35\":1},\"1\":{\"35\":1}}],[\"c++\",{\"1\":{\"30\":1}}],[\"c\",{\"1\":{\"30\":1,\"76\":7}}],[\"csv\",{\"1\":{\"30\":1}}],[\"class<\",{\"1\":{\"80\":2}}],[\"classloader\",{\"1\":{\"80\":8}}],[\"class\",{\"1\":{\"76\":5,\"80\":7,\"89\":1}}],[\"cls\",{\"1\":{\"57\":1}}],[\"cloud是一个托管服务\",{\"1\":{\"28\":1}}],[\"cloud作为数据库\",{\"1\":{\"28\":1}}],[\"clipping\",{\"1\":{\"14\":1}}],[\"cd自动化工具\",{\"1\":{\"24\":1}}],[\"cnn也罢\",{\"1\":{\"41\":1}}],[\"cnn\",{\"1\":{\"41\":1}}],[\"cn\",{\"1\":{\"20\":2,\"24\":1}}],[\"core\",{\"1\":{\"80\":1}}],[\"cortex扩展到docker\",{\"1\":{\"33\":1}}],[\"cortex允许您在生产环境中部署\",{\"1\":{\"33\":1}}],[\"cortex\",{\"0\":{\"33\":1},\"1\":{\"33\":1}}],[\"colin\",{\"1\":{\"58\":1}}],[\"connection\",{\"1\":{\"63\":1}}],[\"conference\",{\"1\":{\"58\":1}}],[\"constant\",{\"1\":{\"58\":1}}],[\"constitutional\",{\"1\":{\"15\":1}}],[\"contextimpl\",{\"1\":{\"80\":1}}],[\"context\",{\"1\":{\"80\":2}}],[\"continuous\",{\"1\":{\"58\":1}}],[\"control是一个开源的\",{\"1\":{\"31\":1}}],[\"control\",{\"0\":{\"31\":1}}],[\"comet\",{\"0\":{\"26\":1},\"1\":{\"26\":2}}],[\"com\",{\"1\":{\"22\":3,\"23\":1,\"24\":1,\"25\":1,\"26\":1,\"30\":1,\"32\":3,\"34\":2,\"37\":1,\"60\":1,\"78\":1,\"80\":2}}],[\"compose\",{\"1\":{\"79\":1}}],[\"component\",{\"1\":{\"13\":1}}],[\"computational\",{\"1\":{\"58\":2}}],[\"comparable\",{\"1\":{\"58\":1}}],[\"completion\",{\"1\":{\"13\":1}}],[\"counterpart\",{\"1\":{\"13\":1}}],[\"chunk\",{\"1\":{\"64\":6}}],[\"chunkwiseretention\",{\"1\":{\"64\":1}}],[\"chunkwise\",{\"1\":{\"61\":1}}],[\"chen\",{\"1\":{\"58\":2}}],[\"chang\",{\"1\":{\"58\":1}}],[\"chatglm\",{\"1\":{\"60\":1}}],[\"chatgpt是基于gpt\",{\"1\":{\"50\":1}}],[\"chatgpt的成功不是偶然的\",{\"1\":{\"38\":1}}],[\"chatgpt悄然进入大众的视线\",{\"1\":{\"38\":1}}],[\"chatgpt和palm\",{\"1\":{\"18\":1}}],[\"chatgpt和llama\",{\"1\":{\"17\":1}}],[\"chat模型与chatgpt具有竞争力\",{\"1\":{\"18\":1}}],[\"chat模型与开源模型\",{\"1\":{\"18\":1}}],[\"chat模型在单回合和多回合提示上都显著优于开源模型\",{\"1\":{\"18\":1}}],[\"chat获得了超过60\",{\"1\":{\"17\":1}}],[\"chat输出在gpt\",{\"1\":{\"17\":1}}],[\"chat生成它\",{\"1\":{\"15\":1}}],[\"chat会忘记指示\",{\"1\":{\"15\":1}}],[\"chat进行拒绝采样\",{\"1\":{\"14\":1}}],[\"chat使用占总步数3\",{\"1\":{\"13\":1}}],[\"chat使用与基本模型相同的优化器参数\",{\"1\":{\"13\":1}}],[\"chat的胜率不那么明显\",{\"1\":{\"17\":1}}],[\"chat的性能\",{\"1\":{\"13\":1}}],[\"chat的最大学习率为5×10−6\",{\"1\":{\"13\":1}}],[\"chat的微调方法\",{\"1\":{\"1\":1}}],[\"chat在训练数据上训练一个epoch\",{\"1\":{\"13\":1}}],[\"chat基于llama\",{\"1\":{\"9\":1}}],[\"chat是基于llama\",{\"1\":{\"1\":1}}],[\"chat\",{\"1\":{\"1\":1,\"14\":3,\"15\":1,\"17\":1,\"18\":5}}],[\"choose\",{\"1\":{\"13\":1}}],[\"float\",{\"1\":{\"80\":1}}],[\"ffn\",{\"1\":{\"63\":1,\"66\":2}}],[\"freeform服务\",{\"1\":{\"80\":1}}],[\"freeform\",{\"0\":{\"80\":1},\"1\":{\"80\":5}}],[\"francine\",{\"1\":{\"58\":1}}],[\"frameworks\",{\"1\":{\"80\":1}}],[\"framework\",{\"1\":{\"58\":1,\"80\":2}}],[\"from\",{\"1\":{\"14\":1,\"15\":1,\"44\":1}}],[\"feed\",{\"1\":{\"43\":1,\"63\":1}}],[\"feedback启发的非常简单的方法\",{\"1\":{\"15\":1}}],[\"feedback保持一致\",{\"1\":{\"14\":1}}],[\"field\",{\"1\":{\"80\":7}}],[\"final\",{\"1\":{\"80\":1}}],[\"find\",{\"1\":{\"80\":2}}],[\"finetuned\",{\"1\":{\"10\":1}}],[\"fine\",{\"0\":{\"9\":1,\"10\":1},\"1\":{\"14\":1,\"55\":1,\"58\":1}}],[\"file\",{\"1\":{\"30\":1}}],[\"falcon\",{\"1\":{\"18\":1}}],[\"furu\",{\"1\":{\"58\":1}}],[\"fully\",{\"1\":{\"14\":1}}],[\"function\",{\"1\":{\"13\":1}}],[\"fsdp\",{\"1\":{\"14\":1}}],[\"foundation\",{\"1\":{\"79\":1}}],[\"found\",{\"1\":{\"13\":2}}],[\"forname\",{\"1\":{\"80\":1}}],[\"forward\",{\"1\":{\"43\":1,\"63\":1}}],[\"for\",{\"1\":{\"13\":3,\"14\":2,\"58\":6,\"78\":1,\"80\":2,\"83\":1,\"84\":1,\"85\":1}}],[\"ii\",{\"0\":{\"85\":1}}],[\"iinfrarescanmanager\",{\"1\":{\"80\":2}}],[\"i++\",{\"1\":{\"83\":1,\"84\":1,\"85\":1}}],[\"imifreeformdisplaycallback\",{\"1\":{\"80\":1}}],[\"imifreeformservice\",{\"1\":{\"80\":1}}],[\"improving\",{\"1\":{\"58\":1}}],[\"improve\",{\"1\":{\"13\":1}}],[\"idisplaymanager\",{\"1\":{\"80\":1}}],[\"if\",{\"1\":{\"80\":1,\"89\":2}}],[\"ibinder>\",{\"1\":{\"80\":1}}],[\"ibinder\",{\"1\":{\"80\":5}}],[\"i=1∣x∣​通过word\",{\"1\":{\"66\":1}}],[\"i=1x​首先被转换为x0=\",{\"1\":{\"63\":1}}],[\"icml\",{\"1\":{\"58\":1}}],[\"ilya\",{\"1\":{\"58\":1}}],[\"illia\",{\"1\":{\"58\":1}}],[\"i\",{\"1\":{\"43\":4,\"81\":1,\"83\":5,\"84\":4,\"85\":4,\"87\":1,\"89\":5}}],[\"io\",{\"1\":{\"28\":1,\"35\":1,\"36\":1}}],[\"intrinsiccandidate\",{\"1\":{\"89\":2}}],[\"int\",{\"1\":{\"80\":6,\"83\":4,\"84\":2,\"85\":2,\"89\":9}}],[\"invoke\",{\"1\":{\"80\":2}}],[\"initservicecache\",{\"1\":{\"80\":1}}],[\"inner\",{\"1\":{\"64\":4}}],[\"infrarescanmanager\",{\"1\":{\"80\":4}}],[\"infrare\",{\"1\":{\"80\":3}}],[\"information\",{\"1\":{\"58\":1}}],[\"infilling\",{\"1\":{\"52\":1}}],[\"input\",{\"0\":{\"46\":1},\"1\":{\"46\":1,\"47\":1}}],[\"inst可以是\",{\"1\":{\"15\":1}}],[\"inst\",{\"1\":{\"15\":1}}],[\"instruction\",{\"1\":{\"10\":1}}],[\"in\",{\"1\":{\"13\":3,\"58\":9,\"78\":1,\"80\":2}}],[\"issues\",{\"1\":{\"60\":1}}],[\"is\",{\"1\":{\"13\":4,\"58\":1,\"71\":1}}],[\"yu\",{\"1\":{\"58\":1}}],[\"yujie\",{\"1\":{\"58\":2}}],[\"yinhan\",{\"1\":{\"58\":1}}],[\"yih\",{\"1\":{\"58\":1}}],[\"yanan\",{\"1\":{\"58\":1}}],[\"yang\",{\"1\":{\"58\":3}}],[\"yanqi\",{\"1\":{\"58\":1}}],[\"you\",{\"1\":{\"58\":1}}],[\"y为输出\",{\"1\":{\"57\":1}}],[\"yr\",{\"1\":{\"13\":1}}],[\"yc\",{\"1\":{\"13\":1}}],[\"y\",{\"1\":{\"13\":2,\"57\":1,\"58\":2}}],[\"xw1​\",{\"1\":{\"66\":1}}],[\"xl−1\",{\"1\":{\"63\":1}}],[\"xl=retnetl​\",{\"1\":{\"63\":1}}],[\"xdmodel​\",{\"1\":{\"63\":2}}],[\"x1​\",{\"1\":{\"63\":1,\"66\":1}}],[\"xi​\",{\"1\":{\"63\":1,\"66\":1}}],[\"xiang\",{\"1\":{\"58\":1}}],[\"xiaodong\",{\"1\":{\"58\":1}}],[\"xiao\",{\"1\":{\"58\":2}}],[\"x∣x∣​\",{\"1\":{\"63\":2,\"66\":1}}],[\"xuanjing\",{\"1\":{\"58\":1}}],[\"x为输入\",{\"1\":{\"57\":1}}],[\"x~6~\",{\"1\":{\"52\":1}}],[\"x~1~\",{\"1\":{\"52\":2}}],[\"x\",{\"1\":{\"13\":2,\"52\":4,\"57\":1,\"58\":1,\"65\":1,\"66\":1}}],[\"就可以调用子类中新添加而超类没有的方法了\",{\"1\":{\"76\":1}}],[\"就可以让引用变量绑定到各种不同的类实现上\",{\"1\":{\"73\":1}}],[\"就可以用同样的模型\",{\"1\":{\"49\":1}}],[\"就可以将nlp任务都转成text\",{\"1\":{\"49\":1}}],[\"就可以在rlhf中优化模型了\",{\"1\":{\"13\":1}}],[\"就是一个双指针问题\",{\"1\":{\"85\":1}}],[\"就是transformer的encoder部分\",{\"1\":{\"45\":1}}],[\"就是给个输入\",{\"1\":{\"12\":1}}],[\"就像git一样\",{\"1\":{\"30\":1}}],[\"安全性等\",{\"1\":{\"13\":1}}],[\"奖励建模的结果\",{\"1\":{\"13\":1}}],[\"奖励建模的训练详情\",{\"1\":{\"13\":1}}],[\"奖励建模就是拿一个模型的结果和它相关的prompt作为输入\",{\"1\":{\"13\":1}}],[\"奖励建模\",{\"0\":{\"13\":1}}],[\"从要复制的数组哪里开始复制\",{\"1\":{\"89\":1}}],[\"从源数组的哪个位置开始复制\",{\"1\":{\"89\":1}}],[\"从论文题目可以看出\",{\"1\":{\"61\":1}}],[\"从前\",{\"1\":{\"55\":1}}],[\"从全称中可以看出\",{\"1\":{\"44\":1}}],[\"从bert到glm\",{\"0\":{\"38\":1}}],[\"从现在起始终充当拿破仑\",{\"1\":{\"15\":1}}],[\"从而实现小窗功能\",{\"1\":{\"80\":1}}],[\"从而导致该引用调用的具体方法随之改变\",{\"1\":{\"73\":1}}],[\"从而得到attention\",{\"1\":{\"42\":1}}],[\"从而将较大模型的能力提取到较小的模型中\",{\"1\":{\"14\":1}}],[\"从而加快注意力计算\",{\"1\":{\"5\":1}}],[\"从两个不同的模型变量中对给定提示的两个响应进行采样\",{\"1\":{\"12\":1}}],[\"然后返回\",{\"1\":{\"83\":1}}],[\"然后取length\",{\"1\":{\"82\":1}}],[\"然后取消勾选enable\",{\"1\":{\"78\":1}}],[\"然后用这些类继承该父类\",{\"1\":{\"71\":1}}],[\"然后用这个向量x0=\",{\"1\":{\"66\":1}}],[\"然后再适配下游任务\",{\"1\":{\"57\":1}}],[\"然后再加上要翻译的内容即可\",{\"1\":{\"49\":1}}],[\"然后\",{\"1\":{\"56\":1,\"63\":1}}],[\"然后模型来预测b是否为a的下一句话\",{\"1\":{\"47\":1}}],[\"然后归一化相似度\",{\"1\":{\"42\":1}}],[\"然后可以将此指令综合连接到会话的所有用户消息\",{\"1\":{\"15\":1}}],[\"然后定义了一个指令\",{\"1\":{\"15\":1}}],[\"然后在生成之后释放内存\",{\"1\":{\"14\":1}}],[\"然后为给定提示选择最佳答案\",{\"1\":{\"14\":1}}],[\"然后作者在新的一组排序样本上微调模型\",{\"1\":{\"14\":1}}],[\"然后输出一个分数来表明这个结果的质量\",{\"1\":{\"13\":1}}],[\"然后有两种输出\",{\"1\":{\"12\":1}}],[\"然后根据提供的标准在两个采样的模型响应之间进行选择\",{\"1\":{\"12\":1}}],[\"然而无论是rnn也好\",{\"1\":{\"41\":1}}],[\"然而\",{\"1\":{\"5\":1,\"14\":1,\"15\":1,\"39\":1,\"62\":1}}],[\"最终\",{\"1\":{\"87\":1}}],[\"最终的input\",{\"1\":{\"46\":1}}],[\"最终希望能够实现一套完整可用的流水线\",{\"1\":{\"22\":1}}],[\"最好的部分是它可以与各种机器学习框架一起使用\",{\"1\":{\"32\":1}}],[\"最大的glm参数量已经达到了130b\",{\"1\":{\"39\":1}}],[\"最大的llama\",{\"1\":{\"18\":1}}],[\"最大曲线和中值曲线之间的增量可以解释为对最佳输出进行微调的潜在增益\",{\"1\":{\"14\":1}}],[\"最佳温度为t∈\",{\"1\":{\"14\":1}}],[\"最佳温度不是恒定的\",{\"1\":{\"14\":1}}],[\"最少5\",{\"1\":{\"13\":1}}],[\"最后\",{\"1\":{\"10\":1,\"43\":1}}],[\"最多支持4k\",{\"1\":{\"1\":1}}],[\"43\",{\"1\":{\"78\":1}}],[\"4倍\",{\"1\":{\"62\":1}}],[\"4186\",{\"1\":{\"58\":1}}],[\"4171\",{\"1\":{\"58\":1}}],[\"495814838\",{\"1\":{\"32\":1}}],[\"40b型号相比\",{\"1\":{\"18\":1}}],[\"4096\",{\"1\":{\"10\":1}}],[\"4提示中出现的顺序是随机交换的\",{\"1\":{\"17\":1}}],[\"4额外计算最终结果\",{\"1\":{\"17\":1}}],[\"4\",{\"0\":{\"16\":1,\"17\":1,\"18\":1,\"23\":1,\"29\":1,\"36\":1,\"49\":1,\"50\":1,\"85\":1},\"1\":{\"13\":1,\"38\":1,\"43\":3,\"45\":1,\"50\":1,\"51\":1,\"58\":1,\"76\":1,\"83\":3,\"84\":3,\"89\":1}}],[\"46\",{\"0\":{\"5\":1}}],[\"权重衰减=0\",{\"1\":{\"10\":1}}],[\"即可\",{\"1\":{\"89\":1}}],[\"即可接受的输入长度\",{\"1\":{\"1\":1}}],[\"即不修改程序代码就可以改变程序运行时所绑定的具体代码\",{\"1\":{\"73\":1}}],[\"即一个引用变量倒底会指向哪个类的实例对象\",{\"1\":{\"73\":1}}],[\"即子类可以对父类进行扩展\",{\"1\":{\"71\":1}}],[\"即groupnorm\",{\"1\":{\"65\":1}}],[\"即q\",{\"1\":{\"64\":1}}],[\"即并行\",{\"1\":{\"62\":1}}],[\"即所谓\",{\"1\":{\"62\":1}}],[\"即所有的自然语言理解任务都可划分为\",{\"1\":{\"39\":1}}],[\"即推理时比较低效\",{\"1\":{\"62\":1}}],[\"即对parta部分和partb部分都进行编码\",{\"1\":{\"53\":1}}],[\"即自回归的\",{\"1\":{\"52\":1}}],[\"即带mask部分的句子\",{\"1\":{\"52\":1}}],[\"即masked\",{\"1\":{\"47\":1}}],[\"即此时segment词表的长度为2\",{\"1\":{\"46\":1}}],[\"即8个缩放点积注意力叠加而成\",{\"1\":{\"45\":1}}],[\"即除以d的开方\",{\"1\":{\"43\":1}}],[\"即通过注入词的顺序信息来增强模型的输入\",{\"1\":{\"43\":1}}],[\"即结构\",{\"1\":{\"38\":1}}],[\"即transformer\",{\"1\":{\"38\":1}}],[\"即最后一个回合之前的所有中间辅助消息\",{\"1\":{\"15\":1}}],[\"即使在使用大批量和kv缓存时也是如此\",{\"1\":{\"14\":1}}],[\"即使是少量的\",{\"1\":{\"10\":1}}],[\"即\",{\"1\":{\"14\":1,\"44\":1,\"52\":1,\"61\":1}}],[\"即每batch\",{\"1\":{\"13\":1}}],[\"即选择和拒绝\",{\"1\":{\"13\":1}}],[\"和块循环模式\",{\"1\":{\"66\":1}}],[\"和前馈网络\",{\"1\":{\"63\":1,\"66\":1}}],[\"和transformer相似的性能和并行训练\",{\"1\":{\"62\":1}}],[\"和字符标签\",{\"1\":{\"57\":1}}],[\"和超多的预训练语料\",{\"1\":{\"50\":1}}],[\"和一个值\",{\"1\":{\"84\":1}}],[\"和一个前馈网络\",{\"1\":{\"43\":1}}],[\"和一个解码器\",{\"1\":{\"41\":1}}],[\"和lora\",{\"1\":{\"39\":1}}],[\"和llama\",{\"1\":{\"10\":1,\"14\":1}}],[\"和p\",{\"1\":{\"38\":1,\"55\":1}}],[\"和10e−6的恒定学习率\",{\"1\":{\"14\":1}}],[\"和\",{\"1\":{\"13\":1,\"19\":1,\"52\":1,\"87\":6}}],[\"和value\",{\"1\":{\"5\":1}}],[\"用cpu可以\",{\"1\":{\"60\":1}}],[\"用\",{\"1\":{\"47\":1}}],[\"用来自动学习和计算输入数据对输出数据的贡献大小\",{\"1\":{\"42\":1}}],[\"用来集成定义\",{\"1\":{\"20\":1}}],[\"用户程序可以通过以下方式获取到mi\",{\"1\":{\"80\":1}}],[\"用户态程序获取系统服务的方式通常是走binder\",{\"1\":{\"80\":1}}],[\"用户可以在开源hydrosphere\",{\"1\":{\"36\":1}}],[\"用户和助手\",{\"1\":{\"15\":1}}],[\"用途\",{\"1\":{\"22\":1,\"27\":1,\"28\":1,\"29\":1,\"30\":1,\"31\":1,\"32\":1,\"33\":1,\"34\":1,\"36\":1,\"37\":1}}],[\"用于将所有的自然语言处理\",{\"1\":{\"49\":1}}],[\"用于执行结构化数据和模型质量检查\",{\"1\":{\"34\":1}}],[\"用于在开发\",{\"1\":{\"34\":1}}],[\"用于在生产中部署和维护api\",{\"1\":{\"32\":1}}],[\"用于数据科学和机器学习项目\",{\"1\":{\"29\":1}}],[\"用于监控\",{\"1\":{\"28\":1}}],[\"用于部署生产环境机器学习流水线\",{\"1\":{\"20\":1}}],[\"用于帮助控制多轮对话流\",{\"1\":{\"9\":1}}],[\"用例如法语说话\",{\"1\":{\"15\":1}}],[\"用这个分数\",{\"1\":{\"13\":1}}],[\"用到的一些人类偏好开源数据集\",{\"1\":{\"12\":1}}],[\"用公开可获得的指令微调数据\",{\"1\":{\"10\":1}}],[\"评测结果如下\",{\"1\":{\"8\":1}}],[\"评测\",{\"0\":{\"8\":1}}],[\"3059\",{\"1\":{\"58\":1}}],[\"3045\",{\"1\":{\"58\":1}}],[\"3公布\",{\"1\":{\"39\":1}}],[\"398651743\",{\"1\":{\"34\":1}}],[\"33b和falcon\",{\"1\":{\"18\":1}}],[\"3\",{\"0\":{\"8\":1,\"9\":1,\"10\":1,\"11\":1,\"12\":1,\"13\":1,\"14\":2,\"15\":2,\"16\":1,\"17\":1,\"18\":1,\"22\":1,\"26\":1,\"27\":1,\"28\":2,\"29\":1,\"30\":1,\"31\":1,\"32\":1,\"33\":1,\"34\":1,\"35\":1,\"43\":1,\"45\":1,\"46\":1,\"47\":2,\"54\":1,\"66\":1,\"67\":1,\"80\":1,\"83\":1},\"1\":{\"13\":2,\"14\":1,\"18\":1,\"38\":1,\"42\":2,\"43\":1,\"45\":1,\"50\":1,\"53\":2,\"54\":1,\"57\":1,\"58\":1,\"64\":2,\"76\":1,\"81\":3,\"83\":5,\"84\":8,\"85\":10,\"87\":7,\"89\":1}}],[\"34b与同等尺寸的vicuna\",{\"1\":{\"18\":1}}],[\"34b\",{\"1\":{\"1\":1}}],[\"算法的主要不同\",{\"1\":{\"14\":1}}],[\"算法\",{\"1\":{\"7\":1}}],[\"boolean\",{\"1\":{\"80\":3}}],[\"bsz\",{\"1\":{\"64\":7}}],[\"brian\",{\"1\":{\"58\":1}}],[\"brain就发布了一个全新的序列转换模型\",{\"1\":{\"39\":1}}],[\"branches\",{\"1\":{\"30\":1}}],[\"by\",{\"1\":{\"58\":1}}],[\"b部分\",{\"1\":{\"52\":1}}],[\"b\",{\"1\":{\"52\":1,\"57\":1,\"76\":17,\"80\":2}}],[\"block包括两个模块\",{\"1\":{\"63\":1}}],[\"blog\",{\"1\":{\"25\":1,\"36\":2}}],[\"blank\",{\"1\":{\"52\":1}}],[\"but\",{\"1\":{\"43\":2}}],[\"bv1g14y1972c\",{\"1\":{\"22\":1}}],[\"binderservice\",{\"1\":{\"80\":1}}],[\"binder\",{\"1\":{\"80\":4}}],[\"bidirectional\",{\"1\":{\"58\":1}}],[\"biases是一个用于实验跟踪\",{\"1\":{\"27\":1}}],[\"biases\",{\"0\":{\"27\":1}}],[\"bilibili\",{\"1\":{\"22\":1}}],[\"billion\",{\"1\":{\"5\":1}}],[\"bison聊天模型\",{\"1\":{\"18\":1}}],[\"bison\",{\"1\":{\"18\":1}}],[\"bao\",{\"1\":{\"58\":1}}],[\"base的参数规模是110m\",{\"1\":{\"45\":1}}],[\"base的100倍大小\",{\"1\":{\"39\":1}}],[\"base\",{\"1\":{\"45\":3,\"80\":1}}],[\"based\",{\"1\":{\"14\":1}}],[\"batch\",{\"1\":{\"10\":1,\"14\":2}}],[\"bert通过这种方式来保留一些被masked的原始信息\",{\"1\":{\"52\":1}}],[\"bert模型是自编码模型\",{\"1\":{\"50\":1}}],[\"bert模型结构图\",{\"1\":{\"45\":1}}],[\"bert在预训练中加入了nsp\",{\"1\":{\"47\":1}}],[\"bert在当时的条件下认为\",{\"1\":{\"44\":1}}],[\"bert把这15\",{\"1\":{\"47\":1}}],[\"bert的效果遥遥领先于同期其他语言模型\",{\"1\":{\"47\":1}}],[\"bert的论文中没有提为什么是15\",{\"1\":{\"47\":1}}],[\"bert的预训练没有采用传统的自左向右或者自右向左语言模型来训练bert\",{\"1\":{\"47\":1}}],[\"bert的基础模型有110m参数\",{\"1\":{\"39\":1}}],[\"bert对positional\",{\"1\":{\"46\":1}}],[\"bert对encoder进行了一些修改\",{\"1\":{\"45\":1}}],[\"bert相对transformer来说\",{\"1\":{\"46\":1}}],[\"bert只用了transformer的encoder部分\",{\"1\":{\"45\":1}}],[\"bert并没有把transformer拿来直接用\",{\"1\":{\"45\":1}}],[\"bert与transformer\",{\"0\":{\"45\":1}}],[\"bert诞生了\",{\"1\":{\"44\":1}}],[\"bert是一个双向编码模型\",{\"1\":{\"44\":1}}],[\"bert全称bidirectional\",{\"1\":{\"44\":1}}],[\"bert和t5都是google的精彩操作\",{\"1\":{\"39\":1}}],[\"bert\",{\"0\":{\"44\":1},\"1\":{\"38\":2,\"45\":8,\"46\":1,\"51\":1,\"58\":2}}],[\"best\",{\"1\":{\"35\":1,\"36\":1}}],[\"bentoml为模型部署\",{\"1\":{\"32\":1}}],[\"bentoml的交互式集中式仪表板可以在部署机器学习模型时轻松组织和监控\",{\"1\":{\"32\":1}}],[\"bentoml使机器学习应用程序的发布变得更简单\",{\"1\":{\"32\":1}}],[\"bentoml\",{\"0\":{\"32\":1},\"1\":{\"32\":3}}],[\"be\",{\"1\":{\"13\":1,\"58\":1}}],[\"bpe\",{\"1\":{\"7\":1}}],[\"将系统类起一个别名\",{\"1\":{\"80\":1}}],[\"将其添加到系统服务列表\",{\"1\":{\"80\":1}}],[\"将该类在android启动时注入framework\",{\"1\":{\"80\":1}}],[\"将应用程序decorview移至decorcaptionview\",{\"1\":{\"80\":1}}],[\"将d变为d~nm​=dnm​\",{\"1\":{\"65\":1}}],[\"将prompt\",{\"1\":{\"57\":1}}],[\"将激活函数由relu调整为gelus\",{\"1\":{\"54\":1}}],[\"将模型分为多个头\",{\"1\":{\"43\":1}}],[\"将ml的最佳开源系统部署到不同的基础设施\",{\"1\":{\"22\":1}}],[\"将所有数字拆分为单个数字\",{\"1\":{\"7\":1}}],[\"将最终学习率降低到峰值学习率的10\",{\"1\":{\"6\":1}}],[\"将上下文长度增加了一倍\",{\"1\":{\"2\":1}}],[\"while\",{\"1\":{\"89\":2}}],[\"where\",{\"1\":{\"13\":3}}],[\"w1​\",{\"1\":{\"66\":1}}],[\"w2​是参数矩阵\",{\"1\":{\"66\":1}}],[\"w2​\",{\"1\":{\"66\":1}}],[\"wv​∈rd×d\",{\"1\":{\"65\":1}}],[\"wk​\",{\"1\":{\"65\":1}}],[\"wk​中\",{\"1\":{\"64\":1}}],[\"wk​指的是可学习的矩阵\",{\"1\":{\"64\":1}}],[\"wuen\",{\"1\":{\"58\":1}}],[\"w\",{\"1\":{\"58\":1}}],[\"warn\",{\"1\":{\"78\":1}}],[\"warmup\",{\"1\":{\"6\":1}}],[\"wang\",{\"1\":{\"58\":4}}],[\"wandb\",{\"0\":{\"27\":1},\"1\":{\"27\":1}}],[\"wallis\",{\"1\":{\"58\":1}}],[\"www\",{\"1\":{\"22\":2,\"25\":1,\"26\":1,\"28\":1,\"30\":1,\"32\":1,\"33\":1,\"34\":1,\"35\":1}}],[\"wenhui\",{\"1\":{\"58\":1}}],[\"wen\",{\"1\":{\"58\":1}}],[\"wei\",{\"1\":{\"58\":3}}],[\"weight\",{\"1\":{\"14\":1}}],[\"weights\",{\"0\":{\"27\":1},\"1\":{\"13\":1,\"27\":1}}],[\"we\",{\"1\":{\"13\":2,\"80\":1}}],[\"width\",{\"1\":{\"80\":2}}],[\"wireless\",{\"1\":{\"78\":1}}],[\"wilde\",{\"1\":{\"15\":1}}],[\"with\",{\"1\":{\"13\":3,\"58\":1}}],[\"window或batch\",{\"1\":{\"5\":1}}],[\"余弦学习率\",{\"1\":{\"6\":1}}],[\"57399\",{\"1\":{\"78\":1}}],[\"574提到了大部分上述已有的工具\",{\"1\":{\"35\":1}}],[\"50\",{\"1\":{\"62\":1,\"84\":1}}],[\"5的对话聊天机器人\",{\"1\":{\"50\":1}}],[\"512\",{\"1\":{\"45\":1}}],[\"5b\",{\"1\":{\"39\":1}}],[\"55840115\",{\"1\":{\"22\":1}}],[\"5\",{\"0\":{\"24\":1,\"30\":1,\"37\":1,\"52\":1,\"53\":1,\"54\":1,\"81\":1},\"1\":{\"6\":1,\"10\":1,\"18\":2,\"38\":1,\"43\":2,\"58\":1,\"64\":1,\"65\":1,\"76\":1,\"81\":1,\"83\":2,\"84\":2,\"85\":2,\"87\":4}}],[\"error\",{\"1\":{\"80\":1}}],[\"else\",{\"1\":{\"80\":1,\"89\":1}}],[\"eds\",{\"1\":{\"58\":1}}],[\"emnlp\",{\"1\":{\"58\":1}}],[\"empirical\",{\"1\":{\"58\":2}}],[\"embedding层转为向量\",{\"1\":{\"66\":1}}],[\"embedding的作用便是用来区分输入序列中的不同序列\",{\"1\":{\"46\":1}}],[\"embedding部分做了一些修改\",{\"1\":{\"46\":1}}],[\"embedding部分有了一些调整\",{\"1\":{\"45\":1}}],[\"embedding也有调整\",{\"1\":{\"45\":1,\"46\":1}}],[\"embedding\",{\"0\":{\"46\":1},\"1\":{\"43\":1,\"45\":1,\"46\":3}}],[\"embeddings\",{\"1\":{\"4\":1}}],[\"efficient\",{\"1\":{\"58\":1}}],[\"et\",{\"1\":{\"58\":1}}],[\"e\",{\"1\":{\"51\":3,\"58\":2,\"80\":4}}],[\"end\",{\"1\":{\"80\":1}}],[\"encoder单元中的另一个部分是一个前馈网络\",{\"1\":{\"43\":1}}],[\"encoder结构图\",{\"1\":{\"43\":1}}],[\"encoder部分由n个encoder单元构成\",{\"1\":{\"43\":1}}],[\"encoder模块\",{\"1\":{\"43\":1}}],[\"encoder\",{\"1\":{\"41\":1,\"43\":1,\"44\":1}}],[\"energy\",{\"1\":{\"14\":1}}],[\"evidentlyai\",{\"1\":{\"34\":1}}],[\"evidently有三个主要组成部分\",{\"1\":{\"34\":1}}],[\"evidently\",{\"0\":{\"34\":1}}],[\"execution\",{\"1\":{\"78\":1}}],[\"extends\",{\"1\":{\"76\":3,\"80\":2}}],[\"extended\",{\"0\":{\"20\":1},\"1\":{\"20\":1}}],[\"expectednums\",{\"1\":{\"83\":3}}],[\"experiences\",{\"1\":{\"14\":1}}],[\"explorer选项打开android\",{\"1\":{\"78\":1}}],[\"exploring\",{\"1\":{\"58\":1}}],[\"eps=10−5\",{\"1\":{\"14\":1}}],[\"eps=10e\",{\"1\":{\"6\":1}}],[\"especially\",{\"1\":{\"13\":1}}],[\"β2=0\",{\"1\":{\"6\":1,\"14\":1}}],[\"β1=0\",{\"1\":{\"6\":1}}],[\"977\",{\"1\":{\"60\":1}}],[\"95\",{\"1\":{\"6\":1,\"14\":1}}],[\"9\",{\"0\":{\"34\":1},\"1\":{\"6\":1,\"14\":1,\"39\":1,\"55\":1,\"58\":1,\"76\":1}}],[\"ln表示layernorm\",{\"1\":{\"66\":1}}],[\"l∈\",{\"1\":{\"63\":1}}],[\"lookup\",{\"1\":{\"89\":1}}],[\"long\",{\"1\":{\"80\":1}}],[\"loadclass\",{\"1\":{\"80\":2}}],[\"log文件并打开\",{\"1\":{\"78\":1}}],[\"log\",{\"1\":{\"78\":1,\"80\":3}}],[\"low\",{\"1\":{\"58\":1}}],[\"lora在文生图领域应用广泛\",{\"1\":{\"55\":1}}],[\"lora同样也是一种部分参数微调的方法\",{\"1\":{\"55\":1}}],[\"lora\",{\"1\":{\"55\":1,\"58\":1}}],[\"l\",{\"1\":{\"58\":1,\"63\":1}}],[\"luke\",{\"1\":{\"58\":1}}],[\"lukasz\",{\"1\":{\"58\":1}}],[\"lucia\",{\"1\":{\"58\":1}}],[\"llm\",{\"0\":{\"90\":1},\"1\":{\"61\":1}}],[\"llion\",{\"1\":{\"58\":1}}],[\"llama\",{\"0\":{\"0\":1},\"1\":{\"1\":4,\"2\":4,\"3\":1,\"5\":2,\"9\":1,\"13\":3,\"14\":1,\"15\":1,\"18\":5}}],[\"lm\",{\"1\":{\"57\":1}}],[\"liang\",{\"1\":{\"58\":1}}],[\"lisa\",{\"1\":{\"58\":1}}],[\"linguistics\",{\"1\":{\"58\":2}}],[\"line\",{\"1\":{\"13\":1}}],[\"limits\",{\"1\":{\"58\":1}}],[\"liu\",{\"1\":{\"58\":6}}],[\"li\",{\"1\":{\"58\":4}}],[\"li~\",{\"1\":{\"52\":1}}],[\"like\",{\"1\":{\"43\":4}}],[\"lightgbm\",{\"1\":{\"32\":1}}],[\"length\",{\"1\":{\"81\":1,\"83\":2,\"84\":1,\"85\":3,\"87\":2,\"89\":3}}],[\"lenght\",{\"1\":{\"10\":1}}],[\"len\",{\"1\":{\"64\":6,\"84\":2,\"85\":2}}],[\"lewis\",{\"1\":{\"58\":1}}],[\"levy\",{\"1\":{\"58\":1}}],[\"lester\",{\"1\":{\"58\":1}}],[\"leetcode\",{\"0\":{\"94\":1,\"95\":1}}],[\"lee\",{\"1\":{\"58\":2}}],[\"learn\",{\"1\":{\"24\":1,\"26\":1,\"32\":1,\"58\":1}}],[\"learning\",{\"1\":{\"19\":1,\"49\":1,\"58\":1}}],[\"lr\",{\"1\":{\"14\":1}}],[\"lr=2e\",{\"1\":{\"10\":1}}],[\"layers的数值精度\",{\"1\":{\"65\":1}}],[\"layers的非线性\",{\"1\":{\"65\":1}}],[\"layer的定义如下\",{\"1\":{\"64\":1}}],[\"layer结构图如下\",{\"1\":{\"64\":1}}],[\"layernorm\",{\"1\":{\"63\":1}}],[\"lang包下的system类中\",{\"1\":{\"89\":1}}],[\"language\",{\"1\":{\"5\":1,\"10\":1,\"39\":1,\"47\":1,\"51\":1,\"52\":1,\"58\":7}}],[\"landscape非常丰富地介绍了mlops\",{\"1\":{\"36\":1}}],[\"large的参数规模是340m\",{\"1\":{\"45\":1}}],[\"large\",{\"1\":{\"13\":1,\"45\":3,\"58\":1}}],[\"额外空间的条件下完成\",{\"1\":{\"85\":1}}],[\"额外空间并\",{\"1\":{\"84\":1}}],[\"额外发现\",{\"1\":{\"5\":1}}],[\"额外的预训练信息之与llama\",{\"0\":{\"5\":1}}],[\"muihandler\",{\"1\":{\"80\":1}}],[\"multi\",{\"0\":{\"65\":1},\"1\":{\"5\":1,\"43\":3,\"50\":2,\"62\":2,\"63\":1,\"65\":1,\"66\":1}}],[\"mdisplaydevicerepo\",{\"1\":{\"80\":1}}],[\"mdns\",{\"1\":{\"78\":1}}],[\"mcontext\",{\"1\":{\"80\":1}}],[\"mfs\",{\"1\":{\"80\":1}}],[\"mf\",{\"1\":{\"80\":2}}],[\"mfclass\",{\"1\":{\"80\":2}}],[\"msyncroot\",{\"1\":{\"80\":1}}],[\"msr\",{\"1\":{\"63\":1,\"65\":1,\"66\":1}}],[\"ms\",{\"1\":{\"61\":1}}],[\"myle\",{\"1\":{\"58\":1}}],[\"merge\",{\"1\":{\"89\":1}}],[\"methods\",{\"1\":{\"58\":2}}],[\"metaflow是一个强大的\",{\"1\":{\"29\":1}}],[\"metaflow\",{\"0\":{\"29\":1}}],[\"meta\",{\"1\":{\"13\":2}}],[\"meta总共收集了27540个好数据\",{\"1\":{\"10\":1}}],[\"meeting\",{\"1\":{\"58\":1}}],[\"mechanism\",{\"1\":{\"41\":1,\"42\":1,\"62\":1}}],[\"mifreeformserver\",{\"1\":{\"80\":1}}],[\"mifreeformdisplayadapter\",{\"1\":{\"80\":2}}],[\"mi\",{\"0\":{\"80\":1},\"1\":{\"80\":4}}],[\"mike\",{\"1\":{\"58\":1}}],[\"michael\",{\"1\":{\"58\":1}}],[\"microsoft\",{\"1\":{\"24\":1}}],[\"ming\",{\"1\":{\"58\":4}}],[\"mini\",{\"1\":{\"14\":1}}],[\"map<string\",{\"1\":{\"80\":1}}],[\"manager\",{\"1\":{\"80\":2}}],[\"mandar\",{\"1\":{\"58\":1}}],[\"magisk可以在sepolicy\",{\"1\":{\"80\":1}}],[\"main\",{\"1\":{\"76\":1}}],[\"max\",{\"1\":{\"65\":1}}],[\"marie\",{\"1\":{\"58\":1}}],[\"margin\",{\"1\":{\"13\":3}}],[\"mach\",{\"1\":{\"58\":1}}],[\"machine\",{\"1\":{\"19\":1}}],[\"matena\",{\"1\":{\"58\":1}}],[\"masked\",{\"1\":{\"58\":1}}],[\"mask掉的15\",{\"1\":{\"52\":1}}],[\"mask\",{\"1\":{\"47\":4,\"52\":3,\"56\":1,\"64\":4}}],[\"mlm根据整个句子信息来推断被遮住的token\",{\"1\":{\"47\":1}}],[\"mlm的要做的事就是根据上下文来预测被遮住的token应该是什么\",{\"1\":{\"47\":1}}],[\"mlm\",{\"1\":{\"47\":1,\"52\":1}}],[\"mlm会随机地遮住输入的某些token\",{\"1\":{\"47\":1}}],[\"ml是一个跟踪\",{\"1\":{\"26\":1}}],[\"mlflow就派上用场了\",{\"1\":{\"23\":1}}],[\"mlflow是机器学习工程师通过实验\",{\"1\":{\"23\":1}}],[\"mlflow是一个开源工具\",{\"1\":{\"23\":1}}],[\"mlflow是一个ml平台\",{\"1\":{\"23\":1}}],[\"mlflow\",{\"0\":{\"23\":1},\"1\":{\"23\":1}}],[\"ml工作流管道中的每个任务都用一个容器来处理\",{\"1\":{\"22\":1}}],[\"ml\",{\"0\":{\"25\":1,\"26\":1},\"1\":{\"19\":2,\"20\":1,\"22\":1,\"25\":1}}],[\"mlops是一门工程学科\",{\"1\":{\"19\":1}}],[\"mlops\",{\"0\":{\"19\":1},\"1\":{\"19\":1,\"25\":1,\"35\":1,\"36\":2}}],[\"mpt\",{\"1\":{\"18\":1}}],[\"moens\",{\"1\":{\"58\":1}}],[\"movie\",{\"1\":{\"43\":2}}],[\"monitoring检查数据的变化\",{\"1\":{\"36\":1}}],[\"monitoring在监控机器学习模型部署方面发挥着最关键的作用\",{\"1\":{\"36\":1}}],[\"monitoring\",{\"1\":{\"34\":1}}],[\"more\",{\"1\":{\"13\":2}}],[\"model即隐层维数\",{\"1\":{\"43\":1}}],[\"model\",{\"1\":{\"5\":1,\"13\":2,\"39\":1,\"47\":1,\"51\":1,\"52\":1,\"58\":2}}],[\"models\",{\"1\":{\"5\":1,\"10\":1,\"14\":1,\"58\":2}}],[\"m\",{\"1\":{\"13\":1,\"87\":11,\"89\":7}}],[\"mqa\",{\"1\":{\"5\":1}}],[\"mhandler\",{\"1\":{\"80\":1}}],[\"mha\",{\"1\":{\"5\":1}}],[\"与自注意力类似\",{\"1\":{\"64\":1}}],[\"与transformer相似\",{\"1\":{\"63\":1}}],[\"与transformer和bert的一维位置编码不同\",{\"1\":{\"53\":1}}],[\"与glm一样\",{\"1\":{\"57\":1}}],[\"与\",{\"1\":{\"56\":1}}],[\"与bert不同的是\",{\"1\":{\"50\":1}}],[\"与encoder一致\",{\"1\":{\"43\":1}}],[\"与传统注意力机制完全相同\",{\"1\":{\"42\":1}}],[\"与wandb类似\",{\"1\":{\"35\":1}}],[\"与没有gatt的模型\",{\"1\":{\"15\":1}}],[\"与样本在训练时间不匹配\",{\"1\":{\"15\":1}}],[\"与discriminative\",{\"1\":{\"14\":1}}],[\"与相似对相比\",{\"1\":{\"13\":1}}],[\"与其他方案相比\",{\"1\":{\"12\":1}}],[\"与多头注意力\",{\"1\":{\"5\":1}}],[\"与llama\",{\"1\":{\"4\":1,\"7\":1}}],[\"srcpos\",{\"1\":{\"89\":2}}],[\"src\",{\"1\":{\"89\":2}}],[\"system\",{\"0\":{\"86\":1},\"1\":{\"76\":9,\"80\":3,\"89\":2}}],[\"systemserviceregistry\",{\"1\":{\"80\":1}}],[\"systemservice\",{\"1\":{\"80\":1}}],[\"systems\",{\"1\":{\"58\":1}}],[\"swish\",{\"1\":{\"65\":1}}],[\"swiglu\",{\"1\":{\"4\":1}}],[\"sn​=asn−1​+knt​vn​\",{\"1\":{\"64\":1}}],[\"solution\",{\"1\":{\"89\":1}}],[\"songhao\",{\"1\":{\"58\":1}}],[\"source\",{\"1\":{\"36\":1}}],[\"specia\",{\"1\":{\"58\":1}}],[\"s~z<i~指的是partb的部分\",{\"1\":{\"52\":1}}],[\"s~2~对应着\",{\"1\":{\"52\":1}}],[\"s\",{\"1\":{\"52\":6,\"58\":1}}],[\"stub\",{\"1\":{\"80\":4}}],[\"studio的日志文件夹\",{\"1\":{\"78\":1}}],[\"studio的菜单\",{\"1\":{\"78\":2}}],[\"studio启动之前手动启动一个adb程序来临时解决\",{\"1\":{\"77\":1}}],[\"studio\",{\"0\":{\"77\":1},\"1\":{\"77\":1}}],[\"static\",{\"1\":{\"76\":1,\"80\":1,\"89\":1}}],[\"string\",{\"1\":{\"76\":5,\"80\":3}}],[\"stoyanov\",{\"1\":{\"58\":1}}],[\"story\",{\"1\":{\"43\":2}}],[\"step\",{\"1\":{\"14\":1}}],[\"steps\",{\"1\":{\"6\":1,\"13\":1}}],[\"sdk支持部署新训练的模型或与已部署的模型链接\",{\"1\":{\"36\":1}}],[\"sql\",{\"1\":{\"30\":1}}],[\"shuzu\",{\"0\":{\"94\":1}}],[\"shouldshowsystemdecorations\",{\"1\":{\"80\":1}}],[\"show\",{\"1\":{\"76\":17}}],[\"shown\",{\"1\":{\"13\":1}}],[\"shen\",{\"1\":{\"58\":1}}],[\"sharan\",{\"1\":{\"58\":1}}],[\"sharded\",{\"1\":{\"14\":1}}],[\"shazeer\",{\"1\":{\"58\":2}}],[\"sup>\",{\"1\":{\"81\":3,\"83\":3,\"85\":3,\"87\":2}}],[\"super\",{\"1\":{\"76\":4}}],[\"supervised\",{\"0\":{\"10\":1}}],[\"surface\",{\"1\":{\"80\":2}}],[\"sum\",{\"1\":{\"64\":1}}],[\"summarization类似\",{\"1\":{\"14\":1}}],[\"sutskever\",{\"1\":{\"58\":1}}],[\"salimans\",{\"1\":{\"58\":1}}],[\"sampling\",{\"1\":{\"14\":1}}],[\"samples\",{\"1\":{\"13\":1}}],[\"safety\",{\"1\":{\"13\":1}}],[\"secure\",{\"1\":{\"80\":1}}],[\"selinux对每个角色可以执行什么操作进行了严格限制\",{\"1\":{\"80\":1}}],[\"selinux限制\",{\"1\":{\"80\":1}}],[\"self\",{\"1\":{\"50\":3}}],[\"servicenotfoundexception\",{\"1\":{\"80\":1}}],[\"service`s\",{\"1\":{\"80\":1}}],[\"services\",{\"1\":{\"80\":1}}],[\"servicemanager\",{\"1\":{\"80\":6}}],[\"service\",{\"1\":{\"80\":15}}],[\"serving集群的帮助下实现\",{\"1\":{\"36\":1}}],[\"serving\",{\"1\":{\"33\":1}}],[\"server\",{\"1\":{\"78\":1,\"80\":3}}],[\"sentence\",{\"1\":{\"47\":1}}],[\"seq2seq\",{\"1\":{\"41\":1}}],[\"sequence\",{\"1\":{\"10\":1,\"41\":2}}],[\"search\",{\"1\":{\"14\":1}}],[\"separable\",{\"1\":{\"13\":1}}],[\"site\",{\"1\":{\"26\":1,\"27\":1}}],[\"similar\",{\"1\":{\"13\":1}}],[\"size不敏感\",{\"1\":{\"62\":1}}],[\"size\",{\"1\":{\"10\":1,\"14\":2,\"64\":4}}],[\"size的增加\",{\"1\":{\"5\":1}}],[\"smaller\",{\"1\":{\"13\":1}}],[\"scan\",{\"1\":{\"80\":3}}],[\"scache\",{\"1\":{\"80\":1}}],[\"scale\",{\"0\":{\"65\":1},\"1\":{\"58\":1,\"62\":1,\"63\":1,\"65\":1,\"66\":1}}],[\"scales\",{\"1\":{\"58\":1}}],[\"scaled\",{\"1\":{\"43\":1}}],[\"scalar\",{\"1\":{\"13\":1}}],[\"scaling\",{\"1\":{\"10\":1,\"14\":1}}],[\"scott\",{\"1\":{\"58\":1}}],[\"scores\",{\"1\":{\"65\":1}}],[\"score的过程如下\",{\"1\":{\"42\":1}}],[\"score\",{\"1\":{\"13\":1,\"42\":2}}],[\"sft\",{\"0\":{\"10\":1},\"1\":{\"14\":1}}],[\"对父类而言\",{\"1\":{\"72\":1}}],[\"对不同的头指定了不同的γ\",{\"1\":{\"65\":1}}],[\"对glm\",{\"1\":{\"57\":1}}],[\"对input\",{\"1\":{\"46\":1}}],[\"对输入\",{\"1\":{\"43\":1}}],[\"对象的最高级别是repository\",{\"1\":{\"30\":1}}],[\"对于面向对象而言\",{\"1\":{\"73\":1}}],[\"对于若干个相同或者相识的类\",{\"1\":{\"71\":1}}],[\"对于l层的retention网络\",{\"1\":{\"66\":1}}],[\"对于llama\",{\"1\":{\"14\":1}}],[\"对于第n个时间步长\",{\"1\":{\"64\":1}}],[\"对于7b型号和8k序列长度\",{\"1\":{\"62\":1}}],[\"对于7b和13b模型\",{\"1\":{\"14\":1}}],[\"对于情感分析问题\",{\"1\":{\"56\":1}}],[\"对于glm\",{\"1\":{\"55\":1}}],[\"对于预训练好的语言模型\",{\"1\":{\"54\":1}}],[\"对于token的预测输出用的是单个的线形层\",{\"1\":{\"54\":1}}],[\"对于position\",{\"1\":{\"53\":1}}],[\"对于palm\",{\"1\":{\"18\":1}}],[\"对于masked掉的词\",{\"1\":{\"52\":1}}],[\"对于相对位置的计算更加方便\",{\"1\":{\"43\":1}}],[\"对于其他方面\",{\"1\":{\"22\":1}}],[\"对于chatgpt\",{\"1\":{\"18\":1}}],[\"对于训练指令\",{\"1\":{\"15\":1}}],[\"对于所有模型\",{\"1\":{\"14\":1}}],[\"对于每个样本来说都是由a和b两句话构成\",{\"1\":{\"47\":1}}],[\"对于每个ppo迭代\",{\"1\":{\"14\":1}}],[\"对于每个prompt\",{\"1\":{\"14\":1}}],[\"对于每个模型\",{\"1\":{\"14\":1}}],[\"对于提高llama\",{\"1\":{\"13\":1}}],[\"对于微调过程\",{\"1\":{\"10\":1}}],[\"对于监督微调\",{\"1\":{\"10\":1}}],[\"对于34b和70b模型\",{\"1\":{\"14\":1}}],[\"对于34b和70b\",{\"1\":{\"5\":1}}],[\"对于kv缓存大小成为瓶颈的大型模型\",{\"1\":{\"5\":1}}],[\"对\",{\"1\":{\"5\":1}}],[\"对总token进行了40\",{\"1\":{\"2\":1}}],[\"vm会对其进行一些优化\",{\"1\":{\"89\":1}}],[\"vm内部的方法\",{\"1\":{\"89\":1}}],[\"vm内部\",{\"1\":{\"89\":1}}],[\"vm\",{\"1\":{\"89\":1}}],[\"vm​\",{\"1\":{\"64\":1}}],[\"void\",{\"1\":{\"76\":1,\"80\":2,\"89\":2}}],[\"volume\",{\"1\":{\"58\":1}}],[\"v中的\",{\"1\":{\"64\":1}}],[\"veselin\",{\"1\":{\"58\":1}}],[\"version\",{\"0\":{\"31\":1},\"1\":{\"31\":1}}],[\"val\",{\"1\":{\"80\":3,\"84\":6}}],[\"value\",{\"1\":{\"42\":1,\"62\":1}}],[\"vaswani\",{\"1\":{\"58\":1}}],[\"v是encoder的输出计算的\",{\"1\":{\"43\":1}}],[\"v21\",{\"1\":{\"58\":1}}],[\"v2好\",{\"1\":{\"57\":1}}],[\"v2几乎一致\",{\"1\":{\"57\":1}}],[\"v2进行微调\",{\"1\":{\"57\":1}}],[\"v2进行介绍\",{\"1\":{\"55\":1}}],[\"v2对glm进行微调\",{\"1\":{\"57\":1}}],[\"v2也是清华大学发布的\",{\"1\":{\"57\":1}}],[\"v2还包括以下改进\",{\"1\":{\"57\":1}}],[\"v2共有50\",{\"1\":{\"57\":1}}],[\"v2可以微调的参数变多了\",{\"1\":{\"57\":1}}],[\"v2实际上就是prefix\",{\"1\":{\"57\":1}}],[\"v2的关键所在就是引入了prefix\",{\"1\":{\"57\":1}}],[\"v2并不是一个全新的方法\",{\"1\":{\"57\":1}}],[\"v2应该属于提示微调\",{\"1\":{\"56\":1}}],[\"v2属于部分参数微调\",{\"1\":{\"56\":1}}],[\"v2基本上是同一时期发布的\",{\"1\":{\"55\":1}}],[\"v2是一种对预训练语言模型进行高效微调的方法\",{\"1\":{\"38\":1}}],[\"v2\",{\"0\":{\"55\":1,\"57\":1},\"1\":{\"38\":1,\"39\":2,\"55\":1,\"57\":2}}],[\"view=azure\",{\"1\":{\"24\":1}}],[\"video\",{\"1\":{\"22\":1}}],[\"vicuna\",{\"1\":{\"18\":1}}],[\"v3之后的两个轴上都优于chatgpt\",{\"1\":{\"17\":1}}],[\"v\",{\"1\":{\"5\":1,\"42\":1,\"64\":10}}],[\"kv\",{\"1\":{\"64\":10}}],[\"km​eimθ\",{\"1\":{\"64\":1}}],[\"km​\",{\"1\":{\"64\":2}}],[\"k=xwk​\",{\"1\":{\"64\":1}}],[\"kn​进行内容感知\",{\"1\":{\"64\":1}}],[\"kn​∈r1×d\",{\"1\":{\"64\":1}}],[\"kt表示k的转置\",{\"1\":{\"64\":1}}],[\"karthik\",{\"1\":{\"58\":1}}],[\"katherine\",{\"1\":{\"58\":1}}],[\"kaiser\",{\"1\":{\"58\":1}}],[\"kristina\",{\"1\":{\"58\":1}}],[\"kenton\",{\"1\":{\"58\":1}}],[\"key\",{\"1\":{\"42\":1}}],[\"kubernetes\",{\"1\":{\"33\":1}}],[\"kubeflow项目致力于在kubernetes上部署机器学习\",{\"1\":{\"22\":1}}],[\"kubeflow是一个基于kubernetes的端到端ml平台\",{\"1\":{\"22\":1}}],[\"kubeflow是一个基于kubernetes的机器学习工具集\",{\"1\":{\"22\":1}}],[\"kubeflow主要是为了简化在kubernetes上面运行机器学习任务的流程\",{\"1\":{\"22\":1}}],[\"kubeflow\",{\"0\":{\"22\":1},\"1\":{\"22\":2}}],[\"kl惩罚\",{\"1\":{\"14\":1}}],[\"k\",{\"1\":{\"5\":1,\"42\":1,\"64\":8,\"83\":6}}],[\"理解更长的文本\",{\"1\":{\"5\":1}}],[\"这道题其实做完力扣26题后并不难\",{\"1\":{\"85\":1}}],[\"这道题来自力扣80题\",{\"1\":{\"85\":1}}],[\"这道题想要做出来并不复杂\",{\"1\":{\"82\":1}}],[\"这意味着在函数里修改输入数组对于调用者是可见的\",{\"1\":{\"84\":1,\"85\":1}}],[\"这段时间一直采用在android\",{\"1\":{\"77\":1}}],[\"这就是多态性\",{\"1\":{\"73\":1}}],[\"这在flops和内存消耗方面都是比较好的\",{\"1\":{\"66\":1}}],[\"这在使用o\",{\"1\":{\"14\":1}}],[\"这两个模式可以利用gpu加速计算\",{\"1\":{\"66\":1}}],[\"这两个强化学习\",{\"1\":{\"14\":1}}],[\"这有利于推理\",{\"1\":{\"64\":1}}],[\"这有助于快速了解数据出了什么问题并设计下一个行动计划\",{\"1\":{\"36\":1}}],[\"这导致了部署基于transformer的模型不是很友好\",{\"1\":{\"62\":1}}],[\"这可以较好地拟合自回归解码\",{\"1\":{\"66\":1}}],[\"这可以在不牺牲性能的情况下提高解码吞吐量\",{\"1\":{\"61\":1}}],[\"这可以让模型支持记住更多对话历史信息\",{\"1\":{\"5\":1}}],[\"这支持三个模式\",{\"1\":{\"61\":1}}],[\"这一点是不同于p\",{\"1\":{\"57\":1}}],[\"这部电影是\",{\"1\":{\"56\":1}}],[\"这对很多企业和个人仍然是不能接受的\",{\"1\":{\"55\":1}}],[\"这会造成预训练和微调之间产生一个不匹配的情况\",{\"1\":{\"47\":1}}],[\"这些特性使retnet可以成为大型语言模型的transformer的强大继承者\",{\"1\":{\"62\":1}}],[\"这些都是根据上下文\",{\"1\":{\"47\":1}}],[\"这些步骤生成了一个sft数据集\",{\"1\":{\"15\":1}}],[\"这限制了预训练\",{\"1\":{\"44\":1}}],[\"这是一道比较简单的双指针问题\",{\"1\":{\"88\":1}}],[\"这是一道数组题\",{\"1\":{\"81\":1}}],[\"这是一种受上下文蒸馏\",{\"1\":{\"15\":1}}],[\"这是因为当前的classloader中不包括\",{\"1\":{\"80\":1}}],[\"这是因为内部类持有外部类的实例\",{\"1\":{\"80\":1}}],[\"这是transformer的相对位置embedding\",{\"1\":{\"64\":1}}],[\"这是很难的\",{\"1\":{\"62\":1}}],[\"这是普通公司和个人难以承受的\",{\"1\":{\"50\":1}}],[\"这是我们不希望发生的\",{\"1\":{\"43\":1}}],[\"这样我们可以得到an−m=λ\",{\"1\":{\"64\":1}}],[\"这样可以进一步提高预测能力\",{\"1\":{\"52\":1}}],[\"这样预测的概率可能不准确\",{\"1\":{\"47\":1}}],[\"这样看来\",{\"1\":{\"45\":1,\"57\":1}}],[\"这样会导致softmax产生非常小的值\",{\"1\":{\"43\":1}}],[\"这样\",{\"1\":{\"43\":1,\"49\":1,\"65\":2,\"73\":1}}],[\"这里米窗3使用了hiddenapirefineplugin来处理\",{\"1\":{\"80\":1}}],[\"这里注意到\",{\"1\":{\"80\":1}}],[\"这里无法通过else获取到米窗3自定义的系统服务\",{\"1\":{\"80\":1}}],[\"这里的γ\",{\"1\":{\"64\":1}}],[\"这里的wq​\",{\"1\":{\"64\":1}}],[\"这里\",{\"1\":{\"55\":1}}],[\"这里我们不做过多介绍\",{\"1\":{\"47\":1}}],[\"这里不再赘述\",{\"1\":{\"43\":1}}],[\"这里补充一些介绍\",{\"1\":{\"36\":1}}],[\"这也是transformer成功的关键\",{\"1\":{\"41\":1}}],[\"这绝对可以称之为\",{\"1\":{\"39\":1}}],[\"这种温度重新缩放都会发生恒定数量的步骤\",{\"1\":{\"14\":1}}],[\"这与constitutional\",{\"1\":{\"14\":1}}],[\"这个注解标记的方法会在jvm内部实现\",{\"1\":{\"89\":1}}],[\"这个注解可以标记\",{\"1\":{\"89\":1}}],[\"这个方法属于hotspot\",{\"1\":{\"89\":1}}],[\"这个方法共接收5个参数\",{\"1\":{\"89\":1}}],[\"这个问题可以通过android\",{\"1\":{\"78\":1}}],[\"这个q和k\",{\"1\":{\"64\":1}}],[\"这个比例在t5模型的论文中证明\",{\"1\":{\"52\":1}}],[\"这个关系是没有办法被语言模型直接捕获到的\",{\"1\":{\"47\":1}}],[\"这个是什么呢\",{\"1\":{\"46\":1}}],[\"这个d其实就是模型最大能接受的token长度\",{\"1\":{\"45\":1}}],[\"这个增量随着样本的增加而增加\",{\"1\":{\"14\":1}}],[\"这个奖励模型优于所有base\",{\"1\":{\"13\":1}}],[\"这个都是可以学习的地方\",{\"1\":{\"13\":1}}],[\"这个现在都在用\",{\"1\":{\"4\":1}}],[\"更改数组\",{\"1\":{\"83\":1}}],[\"更准确地说\",{\"1\":{\"56\":1}}],[\"更是拥有了理解图像的能力\",{\"1\":{\"50\":1}}],[\"更多内容可以阅读原论文\",{\"1\":{\"49\":1}}],[\"更多的样本\",{\"1\":{\"14\":1}}],[\"更多的总结任务\",{\"1\":{\"5\":1}}],[\"更快\",{\"1\":{\"32\":1}}],[\"更明显的响应的准确性最为重要\",{\"1\":{\"13\":1}}],[\"更长的上下文长度可以让模型处理更多信息\",{\"1\":{\"5\":1}}],[\"更新了数据混合\",{\"1\":{\"2\":1}}],[\"put\",{\"1\":{\"80\":1}}],[\"public\",{\"1\":{\"76\":10,\"80\":2,\"89\":2}}],[\"pseudo\",{\"1\":{\"58\":1}}],[\"piao\",{\"1\":{\"58\":1}}],[\"pipelines\",{\"0\":{\"24\":1},\"1\":{\"24\":1}}],[\"percy\",{\"1\":{\"58\":1}}],[\"peter\",{\"1\":{\"58\":1}}],[\"platforms\",{\"1\":{\"36\":1}}],[\"pb数据\",{\"1\":{\"30\":1}}],[\"pytorch等\",{\"1\":{\"36\":1}}],[\"pytorch和scikit\",{\"1\":{\"32\":1}}],[\"pytorch\",{\"1\":{\"26\":1}}],[\"python\",{\"1\":{\"23\":1,\"30\":1,\"36\":1}}],[\"ppo介绍\",{\"1\":{\"14\":1}}],[\"ppo\",{\"1\":{\"14\":1}}],[\"power\",{\"1\":{\"58\":1}}],[\"polosukhin\",{\"1\":{\"58\":1}}],[\"policy\",{\"1\":{\"14\":1}}],[\"position\",{\"1\":{\"53\":1}}],[\"positional\",{\"1\":{\"4\":1,\"45\":1}}],[\"path\",{\"1\":{\"80\":1}}],[\"past\",{\"1\":{\"64\":5}}],[\"papers\",{\"1\":{\"58\":1}}],[\"pages\",{\"1\":{\"58\":3}}],[\"parikh\",{\"1\":{\"58\":1}}],[\"parmar\",{\"1\":{\"58\":1}}],[\"parta和partb\",{\"1\":{\"53\":1}}],[\"partb可以自回归地看到已经走过的partb和全部的parta\",{\"1\":{\"52\":1}}],[\"parallelretention\",{\"1\":{\"64\":1}}],[\"parallel\",{\"1\":{\"14\":1}}],[\"parallelism\",{\"1\":{\"5\":1}}],[\"parameter\",{\"1\":{\"5\":1,\"58\":1}}],[\"pachyderm通过kubernetes上的数据版本化\",{\"1\":{\"30\":1}}],[\"pachyderm\",{\"0\":{\"30\":1},\"1\":{\"30\":1}}],[\"pairs\",{\"1\":{\"13\":1}}],[\"print\",{\"1\":{\"84\":1,\"85\":1}}],[\"println\",{\"1\":{\"76\":9}}],[\"prints\",{\"1\":{\"58\":1}}],[\"presentationdeadlinenanos\",{\"1\":{\"80\":1}}],[\"preprint\",{\"1\":{\"58\":3}}],[\"pretraining\",{\"1\":{\"58\":2}}],[\"pre\",{\"1\":{\"50\":1,\"58\":3,\"63\":1}}],[\"prediction\",{\"1\":{\"47\":1}}],[\"prefixtuning\",{\"1\":{\"58\":1}}],[\"prefix参数进行微调\",{\"1\":{\"57\":1}}],[\"prefix为前缀\",{\"1\":{\"57\":1}}],[\"prefix\",{\"1\":{\"39\":1,\"55\":2,\"57\":4}}],[\"prefect是一个现代化的数据堆栈\",{\"1\":{\"28\":1}}],[\"prefect\",{\"0\":{\"28\":1},\"1\":{\"28\":3}}],[\"preference\",{\"1\":{\"13\":1}}],[\"preferred\",{\"1\":{\"13\":1}}],[\"proceedings\",{\"1\":{\"58\":1}}],[\"processing\",{\"1\":{\"58\":3}}],[\"proc\",{\"1\":{\"58\":1}}],[\"product\",{\"1\":{\"43\":1}}],[\"projectpro\",{\"1\":{\"35\":1}}],[\"proximal\",{\"1\":{\"14\":1}}],[\"prompts\",{\"1\":{\"58\":1}}],[\"prompt\",{\"1\":{\"13\":1,\"39\":1,\"55\":2,\"56\":1,\"58\":2}}],[\"p\",{\"0\":{\"5\":1,\"55\":1,\"57\":1},\"1\":{\"22\":1,\"23\":1,\"32\":1,\"34\":1,\"38\":1,\"39\":1,\"55\":1,\"56\":1,\"57\":7,\"58\":2}}],[\"aosp和部分国产rom\",{\"1\":{\"80\":1}}],[\"attempting\",{\"1\":{\"78\":1}}],[\"attention和multi\",{\"1\":{\"50\":1}}],[\"attention和上述的一致\",{\"1\":{\"43\":1}}],[\"attention的k\",{\"1\":{\"43\":1}}],[\"attention是双向的\",{\"1\":{\"43\":1}}],[\"attention\",{\"1\":{\"5\":1,\"9\":1,\"15\":1,\"41\":1,\"42\":1,\"43\":4,\"50\":2,\"58\":2,\"62\":1}}],[\"a2\",{\"1\":{\"76\":4}}],[\"a是继承者称之为子类或者派生类\",{\"1\":{\"71\":1}}],[\"a是b\",{\"1\":{\"71\":1}}],[\"a=λ\",{\"1\":{\"64\":1}}],[\"aka\",{\"1\":{\"61\":1}}],[\"al\",{\"1\":{\"58\":2}}],[\"alec\",{\"1\":{\"58\":1}}],[\"allowblocking\",{\"1\":{\"80\":1}}],[\"allow\",{\"1\":{\"80\":2}}],[\"allen\",{\"1\":{\"58\":1}}],[\"all\",{\"1\":{\"58\":2}}],[\"aliyun\",{\"1\":{\"22\":1}}],[\"autoregressive\",{\"1\":{\"52\":1}}],[\"autoregression\",{\"1\":{\"44\":2}}],[\"autoencoder\",{\"1\":{\"44\":1}}],[\"automl\",{\"1\":{\"37\":1}}],[\"autokeras是一个用于自动机器学习\",{\"1\":{\"37\":1}}],[\"autokeras\",{\"0\":{\"37\":1},\"1\":{\"37\":1}}],[\"azure\",{\"0\":{\"24\":1,\"25\":1},\"1\":{\"24\":2}}],[\"apptoken\",{\"1\":{\"80\":1}}],[\"app\",{\"1\":{\"80\":2}}],[\"approach\",{\"1\":{\"58\":1}}],[\"appendix\",{\"1\":{\"13\":1}}],[\"api管理机器学习实验和模型元数据\",{\"1\":{\"23\":1}}],[\"apache\",{\"1\":{\"21\":1}}],[\"arraycopy\",{\"0\":{\"86\":1,\"89\":1},\"1\":{\"88\":1,\"89\":3}}],[\"arraymap<>\",{\"1\":{\"80\":1}}],[\"args\",{\"1\":{\"76\":1}}],[\"arxiv\",{\"1\":{\"58\":8}}],[\"article\",{\"1\":{\"22\":1,\"35\":1}}],[\"architecture这篇论文中介绍了11个mlops相关工具\",{\"1\":{\"19\":1}}],[\"are\",{\"1\":{\"13\":1,\"58\":1}}],[\"asinterface\",{\"1\":{\"80\":2}}],[\"assert\",{\"1\":{\"80\":1,\"83\":2}}],[\"association\",{\"1\":{\"58\":2}}],[\"ashish\",{\"1\":{\"58\":1}}],[\"as\",{\"1\":{\"15\":1,\"80\":1}}],[\"across\",{\"1\":{\"58\":1}}],[\"act\",{\"1\":{\"15\":1}}],[\"accuracy\",{\"1\":{\"13\":1}}],[\"a100\",{\"1\":{\"57\":2}}],[\"a100服务器\",{\"1\":{\"55\":1}}],[\"a1\",{\"1\":{\"15\":1,\"76\":4}}],[\"abstractive\",{\"1\":{\"14\":1}}],[\"ablation\",{\"1\":{\"13\":1}}],[\"adb\",{\"1\":{\"78\":2}}],[\"adb异常重启问题解决\",{\"0\":{\"77\":1}}],[\"adaptation\",{\"1\":{\"58\":1}}],[\"adam\",{\"1\":{\"58\":1}}],[\"adamw优化器\",{\"1\":{\"6\":1}}],[\"advances\",{\"1\":{\"58\":1}}],[\"adversarial\",{\"1\":{\"14\":1}}],[\"addlistener\",{\"1\":{\"80\":1}}],[\"adddexpath\",{\"1\":{\"80\":1}}],[\"addservice\",{\"1\":{\"80\":2}}],[\"add\",{\"1\":{\"43\":1,\"80\":4}}],[\"aidan\",{\"1\":{\"58\":1}}],[\"ai的能力在逐步增强\",{\"1\":{\"50\":1}}],[\"airflow是一种任务和工作流程编排工具\",{\"1\":{\"21\":1}}],[\"airflow\",{\"0\":{\"21\":1},\"1\":{\"21\":1}}],[\"ai\",{\"0\":{\"35\":1},\"1\":{\"14\":2,\"15\":2,\"27\":1,\"35\":1,\"36\":2}}],[\"ankur\",{\"1\":{\"58\":1}}],[\"annual\",{\"1\":{\"58\":1}}],[\"annotators\",{\"1\":{\"13\":1}}],[\"an\",{\"1\":{\"15\":1}}],[\"analysis\",{\"1\":{\"13\":1}}],[\"android下\",{\"1\":{\"80\":1}}],[\"androidx\",{\"1\":{\"79\":1}}],[\"android\",{\"0\":{\"77\":1,\"93\":1},\"1\":{\"78\":1,\"80\":6}}],[\"and\",{\"1\":{\"13\":4,\"19\":1,\"58\":13,\"63\":1,\"76\":4}}],[\"a\",{\"0\":{\"5\":1},\"1\":{\"13\":4,\"52\":1,\"58\":4,\"71\":1,\"76\":11}}],[\"增加了一个segment\",{\"1\":{\"46\":1}}],[\"增加了gqa\",{\"1\":{\"4\":1}}],[\"增加了上下文长度\",{\"1\":{\"4\":1}}],[\"增加一倍\",{\"1\":{\"1\":1}}],[\"rule中编写自定义的selinux规则\",{\"1\":{\"80\":1}}],[\"r=qkt⨀d\",{\"1\":{\"65\":1}}],[\"rfou\",{\"1\":{\"58\":1}}],[\"rawgetservice\",{\"1\":{\"80\":1}}],[\"rank\",{\"1\":{\"58\":1}}],[\"rami\",{\"1\":{\"58\":1}}],[\"radford\",{\"1\":{\"58\":1}}],[\"raffel\",{\"1\":{\"58\":1}}],[\"rating\",{\"1\":{\"13\":1}}],[\"rnn\",{\"1\":{\"41\":1}}],[\"rl\",{\"1\":{\"14\":1}}],[\"rlhf结果\",{\"0\":{\"16\":1}}],[\"rlhf对重新缩放温度有直接影响\",{\"1\":{\"14\":1}}],[\"rlhf\",{\"0\":{\"11\":1},\"1\":{\"14\":2,\"17\":1}}],[\"r\",{\"1\":{\"13\":1,\"23\":1,\"30\":1}}],[\"removeelement\",{\"1\":{\"84\":1}}],[\"removeduplicates\",{\"1\":{\"83\":1,\"85\":1}}],[\"remoteexception\",{\"1\":{\"80\":1}}],[\"refreshrate\",{\"1\":{\"80\":1}}],[\"registerservice\",{\"1\":{\"80\":1}}],[\"reconnect\",{\"1\":{\"78\":1}}],[\"recurrentretention\",{\"1\":{\"64\":1}}],[\"recurrent\",{\"1\":{\"61\":1}}],[\"reach\",{\"1\":{\"78\":1}}],[\"real\",{\"1\":{\"34\":1}}],[\"return\",{\"1\":{\"64\":3,\"76\":4,\"80\":4,\"89\":1}}],[\"retentive\",{\"0\":{\"63\":1}}],[\"retention分数归一化\",{\"1\":{\"65\":1}}],[\"retention的输出变为retention\",{\"1\":{\"65\":1}}],[\"retention的块循环表示\",{\"1\":{\"64\":1}}],[\"retention的循环表示\",{\"1\":{\"64\":1}}],[\"retention的平行表示\",{\"1\":{\"64\":1}}],[\"retention\",{\"0\":{\"64\":1,\"65\":1},\"1\":{\"62\":1,\"63\":1,\"64\":15,\"65\":1,\"66\":1}}],[\"retnet通过自回归的方式编码这个序列\",{\"1\":{\"63\":1}}],[\"retnet由l个相同的block组成\",{\"1\":{\"63\":1}}],[\"retnet还比使用了flashattention的transformer节省了25\",{\"1\":{\"62\":1}}],[\"retnet的推理延迟对batch\",{\"1\":{\"62\":1}}],[\"retnet的推理耗费是不受序列长度影响的\",{\"1\":{\"62\":1}}],[\"retnet的解码速度比具有键值缓存的transformer快8\",{\"1\":{\"62\":1}}],[\"retnet的理论来源是连接循环和注意力\",{\"1\":{\"61\":1}}],[\"retnet在尺度曲线和上下文学习方面都具有竞争力\",{\"1\":{\"62\":1}}],[\"retnet在llm上要优于transformer\",{\"1\":{\"61\":1}}],[\"retnet则可以同时实现低成本推理\",{\"1\":{\"62\":1}}],[\"retnet\",{\"0\":{\"61\":1},\"1\":{\"61\":2}}],[\"representations\",{\"1\":{\"44\":1}}],[\"resizefreeform\",{\"1\":{\"80\":1}}],[\"residual\",{\"1\":{\"14\":1,\"63\":1}}],[\"res\",{\"1\":{\"58\":1}}],[\"rest或kafka流将它们链接起来\",{\"1\":{\"36\":1}}],[\"responses\",{\"1\":{\"13\":3}}],[\"response\",{\"1\":{\"13\":1}}],[\"rejection\",{\"1\":{\"14\":1}}],[\"rejected\",{\"1\":{\"13\":1}}],[\"reward\",{\"1\":{\"13\":1}}],[\"rθ\",{\"1\":{\"13\":1}}],[\"robustly\",{\"1\":{\"58\":1}}],[\"roberta\",{\"1\":{\"58\":1}}],[\"roberts\",{\"1\":{\"58\":1}}],[\"rorerta\",{\"1\":{\"51\":1}}],[\"rotary\",{\"1\":{\"4\":1}}],[\"rope\",{\"1\":{\"4\":1}}],[\"rmsnorm\",{\"1\":{\"4\":1}}],[\"旋转位置embedding\",{\"1\":{\"4\":1}}],[\"激活函数\",{\"1\":{\"4\":1}}],[\"激活函数等有变化\",{\"1\":{\"2\":1}}],[\"训练\",{\"1\":{\"66\":1}}],[\"训练语言模型的成本是巨大的\",{\"1\":{\"55\":1}}],[\"训练和微调均进行了介绍\",{\"1\":{\"38\":1}}],[\"训练详情\",{\"0\":{\"4\":1}}],[\"训练数据\",{\"0\":{\"3\":1}}],[\"共享特性\",{\"1\":{\"71\":1}}],[\"共在2t\",{\"1\":{\"3\":1}}],[\"共有7b\",{\"1\":{\"1\":1}}],[\"tvm​\",{\"1\":{\"64\":1}}],[\"täckström\",{\"1\":{\"58\":1}}],[\"tag\",{\"1\":{\"80\":2}}],[\"tau\",{\"1\":{\"58\":1}}],[\"tasks\",{\"1\":{\"58\":3}}],[\"tang\",{\"1\":{\"58\":2}}],[\"table\",{\"1\":{\"13\":2}}],[\"tim\",{\"1\":{\"58\":1}}],[\"time\",{\"1\":{\"34\":1}}],[\"t5一样\",{\"1\":{\"54\":1}}],[\"t5模型相同\",{\"1\":{\"50\":1}}],[\"t5模型\",{\"0\":{\"49\":1},\"1\":{\"49\":1}}],[\"t5和gpt\",{\"0\":{\"48\":1}}],[\"t5论文中有对比实验\",{\"1\":{\"47\":1}}],[\"t5基础模型参数量为220m\",{\"1\":{\"39\":1}}],[\"t5\",{\"1\":{\"38\":2,\"48\":1,\"49\":1}}],[\"torch\",{\"1\":{\"64\":1}}],[\"torchserve和其他ml库\",{\"1\":{\"33\":1}}],[\"too\",{\"1\":{\"58\":1}}],[\"tools和https\",{\"1\":{\"36\":1}}],[\"tools\",{\"1\":{\"35\":1,\"36\":2}}],[\"tools中提到了一些其他的mlops的工具\",{\"1\":{\"25\":1}}],[\"toutanova\",{\"1\":{\"58\":1}}],[\"to\",{\"1\":{\"41\":1,\"49\":4,\"58\":2,\"78\":1,\"80\":1}}],[\"top\",{\"1\":{\"25\":1}}],[\"token上进行训练\",{\"1\":{\"3\":1}}],[\"token\",{\"1\":{\"1\":1,\"52\":1}}],[\"tfx\",{\"1\":{\"20\":4}}],[\"test\",{\"1\":{\"76\":1}}],[\"tensorflow和huggingface\",{\"1\":{\"26\":1}}],[\"tensorflow\",{\"0\":{\"20\":1},\"1\":{\"20\":3,\"33\":1,\"36\":1}}],[\"text的形式\",{\"1\":{\"49\":1}}],[\"text\",{\"1\":{\"14\":1,\"49\":5,\"58\":2}}],[\"turbo\",{\"1\":{\"18\":1}}],[\"tuning与p\",{\"1\":{\"57\":1}}],[\"tuning中\",{\"1\":{\"57\":1}}],[\"tuning的\",{\"1\":{\"57\":1}}],[\"tuning将预训练lm参数固定\",{\"1\":{\"57\":1}}],[\"tuning示意图\",{\"1\":{\"57\":1}}],[\"tuning最开始应用在自然语言生成\",{\"1\":{\"57\":1}}],[\"tuning技术首次拓展到序列标注等复杂自然语言理解\",{\"1\":{\"57\":1}}],[\"tuning技术适配到自然语言理解任务中\",{\"1\":{\"57\":1}}],[\"tuning相似的性能\",{\"1\":{\"57\":1}}],[\"tuning进行了修改和优化\",{\"1\":{\"55\":1}}],[\"tuning和p\",{\"1\":{\"55\":1}}],[\"tuning虽然实现了部分参数调优\",{\"1\":{\"55\":1}}],[\"tuning\",{\"0\":{\"9\":1,\"10\":1,\"55\":1,\"57\":1},\"1\":{\"14\":1,\"38\":2,\"39\":5,\"55\":8,\"56\":3,\"57\":15,\"58\":4}}],[\"two\",{\"1\":{\"13\":1}}],[\"throws\",{\"1\":{\"80\":1}}],[\"thudm\",{\"1\":{\"60\":1}}],[\"this$0\",{\"1\":{\"80\":2}}],[\"this$0表示顶层外部类引用\",{\"1\":{\"80\":1}}],[\"this\",{\"1\":{\"13\":1,\"76\":2,\"80\":2}}],[\"those\",{\"1\":{\"13\":1}}],[\"that\",{\"1\":{\"13\":1}}],[\"the\",{\"1\":{\"13\":5,\"43\":6,\"58\":5}}],[\"try\",{\"1\":{\"80\":1}}],[\"transpose\",{\"1\":{\"64\":3}}],[\"transfer\",{\"1\":{\"58\":1}}],[\"transfer来自transfer\",{\"1\":{\"49\":1}}],[\"transformer已然成为llm的首选架构\",{\"1\":{\"62\":1}}],[\"transformer即我们在第二节中提到的\",{\"1\":{\"49\":1}}],[\"transformers\",{\"1\":{\"44\":1,\"58\":1}}],[\"transformer是一个seq2seq模型\",{\"1\":{\"44\":1}}],[\"transformer是seq2seq的全新尝试\",{\"1\":{\"43\":1}}],[\"transformer对后来语言模型的影响十分深远\",{\"1\":{\"43\":1}}],[\"transformer在这里设计的前馈网络比较简单\",{\"1\":{\"43\":1}}],[\"transformer认为\",{\"1\":{\"43\":1}}],[\"transformer中的位置编码\",{\"1\":{\"46\":1}}],[\"transformer中的位置编码采用公式计算得到\",{\"1\":{\"43\":1}}],[\"transformer中多头注意力机制是由h\",{\"1\":{\"45\":1}}],[\"transformer中对注意力机制的体现在多头注意力机制\",{\"1\":{\"43\":1}}],[\"transformer的并行训练是有代价的\",{\"1\":{\"62\":1}}],[\"transformer的decoder结构中\",{\"1\":{\"50\":1}}],[\"transformer的decoder和encoder十分相似\",{\"1\":{\"43\":1}}],[\"transformer的简写\",{\"1\":{\"49\":1}}],[\"transformer的encoder层是由n=6的单元构成的\",{\"1\":{\"45\":1}}],[\"transformer的encoder模块\",{\"1\":{\"45\":1}}],[\"transformer的模型结构已经介绍完成\",{\"1\":{\"43\":1}}],[\"transformer的编码器结构如图2\",{\"1\":{\"43\":1}}],[\"transformer的位置编码简单但是有创新性\",{\"1\":{\"43\":1}}],[\"transformer没有办法表示序列的顺序\",{\"1\":{\"43\":1}}],[\"transformer模型整体结构如图2\",{\"1\":{\"43\":1}}],[\"transformer模型\",{\"0\":{\"43\":1},\"1\":{\"43\":1}}],[\"transformer\",{\"0\":{\"40\":1},\"1\":{\"39\":1,\"58\":1}}],[\"transformer架构\",{\"1\":{\"4\":1}}],[\"training\",{\"1\":{\"5\":1,\"50\":1,\"58\":3}}],[\"trillion\",{\"1\":{\"2\":1}}],[\"==\",{\"1\":{\"81\":1,\"83\":2,\"87\":2,\"89\":1}}],[\"=gelu\",{\"1\":{\"66\":1}}],[\"=groupnorm\",{\"1\":{\"65\":1}}],[\"=r~v\",{\"1\":{\"65\":1}}],[\"=m=1∑n​\",{\"1\":{\"64\":1}}],[\"=xn​⋅wv​上\",{\"1\":{\"64\":1}}],[\"=\",{\"1\":{\"2\":2,\"10\":2,\"45\":8,\"53\":1,\"64\":14,\"76\":5,\"80\":18,\"81\":2,\"83\":8,\"84\":10,\"85\":8,\"87\":13,\"89\":6}}],[\"getoutercontext\",{\"1\":{\"80\":1}}],[\"getconstructors\",{\"1\":{\"80\":1}}],[\"getclassloader\",{\"1\":{\"80\":1}}],[\"getclass\",{\"1\":{\"80\":4}}],[\"getmethod\",{\"1\":{\"80\":1}}],[\"getdeclaredfield\",{\"1\":{\"80\":2}}],[\"get\",{\"1\":{\"80\":5}}],[\"getservice\",{\"1\":{\"80\":5}}],[\"generation\",{\"1\":{\"58\":2}}],[\"generation也提出了同样的llm重新排序策略\",{\"1\":{\"14\":1}}],[\"generative\",{\"1\":{\"50\":1,\"58\":1}}],[\"general\",{\"1\":{\"39\":1,\"51\":1,\"58\":1}}],[\"gpu的内存急剧增加\",{\"1\":{\"62\":1}}],[\"gpt似乎有能力处理自然语言理解和自然语言生成任务\",{\"1\":{\"51\":1}}],[\"gpt已经迎来了第四个大版本\",{\"1\":{\"50\":1}}],[\"gpt也并没有将transformer的decoder拿过来直接用\",{\"1\":{\"50\":1}}],[\"gpt的核心部分是n=12的transformer\",{\"1\":{\"50\":1}}],[\"gpt采用的不是transformer的encoder部分\",{\"1\":{\"50\":1}}],[\"gpt同样也抛弃了传统的rnn和cnn\",{\"1\":{\"50\":1}}],[\"gpt模型结构\",{\"1\":{\"50\":1}}],[\"gpt模型与bert模型不同\",{\"1\":{\"50\":1}}],[\"gpt模型\",{\"0\":{\"50\":1}}],[\"gpt是一个自回归\",{\"1\":{\"44\":1}}],[\"gpt和glm均为预训练语言模型\",{\"1\":{\"38\":1}}],[\"gpt\",{\"1\":{\"38\":1,\"39\":3,\"50\":1,\"51\":1,\"58\":1}}],[\"gate\",{\"1\":{\"65\":1}}],[\"gated\",{\"0\":{\"65\":1}}],[\"gatt方法\",{\"1\":{\"15\":1}}],[\"gatt允许对多轮进行对话控制\",{\"1\":{\"15\":1}}],[\"gatt\",{\"1\":{\"9\":1,\"15\":1}}],[\"gao\",{\"1\":{\"58\":1}}],[\"goyal\",{\"1\":{\"58\":1}}],[\"gomez\",{\"1\":{\"58\":1}}],[\"google公开了t5模型\",{\"1\":{\"39\":1}}],[\"google公开了以transformer作为基础的语言模型bert\",{\"1\":{\"39\":1}}],[\"google\",{\"1\":{\"20\":2,\"39\":1}}],[\"g\",{\"1\":{\"51\":3}}],[\"glm的基本结构已经介绍完毕\",{\"1\":{\"54\":1}}],[\"glm同样只使用了transformer的encoder部分\",{\"1\":{\"54\":1}}],[\"glm同样对transformer的结构进行了修改\",{\"1\":{\"54\":1}}],[\"glm同样是基于transformer的结构\",{\"1\":{\"54\":1}}],[\"glm与transformer\",{\"0\":{\"54\":1}}],[\"glm二维编码\",{\"1\":{\"53\":1}}],[\"glm采用了二维位置编码\",{\"1\":{\"53\":1}}],[\"glm采用自回归的方式尝试还原它们\",{\"1\":{\"52\":1}}],[\"glm仍然是以transformer为基础的结构\",{\"1\":{\"53\":1}}],[\"glm自回归填空示意图二\",{\"1\":{\"52\":1}}],[\"glm自回归填空示意图之一\",{\"1\":{\"52\":1}}],[\"glm把输入的文本分为两个部分\",{\"1\":{\"53\":1}}],[\"glm把masked掉的信息全部保留在了partb\",{\"1\":{\"52\":1}}],[\"glm把s~1~和s~2~对应的x部分替换为一个\",{\"1\":{\"52\":1}}],[\"glm预测的条件比bert多了一个partb\",{\"1\":{\"52\":1}}],[\"glm随机masked掉的比例为15\",{\"1\":{\"52\":1}}],[\"glm随机masked掉一些文本\",{\"1\":{\"52\":1}}],[\"glm没有选择直接丢失这些x\",{\"1\":{\"52\":1}}],[\"glm模型应用了名为自回归填空\",{\"1\":{\"52\":1}}],[\"glm创新地应用了自回归填空思想\",{\"1\":{\"51\":1}}],[\"glm也尝试能够同时处理自然语言理解和自然语言生成等多种nlp任务\",{\"1\":{\"51\":1}}],[\"glm意为通用语言模型\",{\"1\":{\"51\":1}}],[\"glm\",{\"0\":{\"51\":1},\"1\":{\"38\":1}}],[\"github\",{\"1\":{\"32\":1,\"60\":1}}],[\"group\",{\"1\":{\"64\":3}}],[\"grouped\",{\"1\":{\"1\":1,\"5\":1}}],[\"gradient\",{\"1\":{\"14\":1}}],[\"ghost\",{\"1\":{\"9\":1}}],[\"gqa\",{\"1\":{\"2\":1,\"5\":1}}],[\"并在使用\",{\"1\":{\"85\":1}}],[\"并在数据问题发生时向用户发送通知\",{\"1\":{\"36\":1}}],[\"并返回移除后数组的新长度\",{\"1\":{\"84\":1}}],[\"并按照它们最初在\",{\"1\":{\"83\":1}}],[\"并不是dms\",{\"1\":{\"80\":1}}],[\"并不影响最终的结果\",{\"1\":{\"65\":1}}],[\"并不会出现\",{\"1\":{\"47\":1}}],[\"并保持它们不变\",{\"1\":{\"65\":1}}],[\"并行表示使能够有效地用gpu训练模型\",{\"1\":{\"64\":1}}],[\"并行表示使训练并行性能够充分利用gpu设备\",{\"1\":{\"62\":1}}],[\"并正规化\",{\"1\":{\"43\":1}}],[\"并用相似度与key所对应的value做矩阵运算并求和\",{\"1\":{\"42\":1}}],[\"并用我们的奖励选择最佳候选者\",{\"1\":{\"14\":1}}],[\"并优化学习算法的超参数\",{\"1\":{\"37\":1}}],[\"并通过grpc\",{\"1\":{\"36\":1}}],[\"并提供硬件加速\",{\"1\":{\"32\":1}}],[\"并可视化数据集\",{\"1\":{\"27\":1}}],[\"并由kubernetes协调\",{\"1\":{\"22\":1}}],[\"并对延迟的提示进行了评估\",{\"1\":{\"14\":1}}],[\"并且\",{\"1\":{\"84\":2}}],[\"并且原数组的前五个元素被修改为\",{\"1\":{\"85\":2}}],[\"并且原数组\",{\"1\":{\"83\":2}}],[\"并且给定的数组总是存在多数元素\",{\"1\":{\"81\":1}}],[\"并且经过证明\",{\"1\":{\"80\":1}}],[\"并且这可以在获得相同结果的同时\",{\"1\":{\"66\":1}}],[\"并且通过下列公式计算模型的输出\",{\"1\":{\"66\":1}}],[\"并且要在内存中缓存key\",{\"1\":{\"62\":1}}],[\"并且更推荐使用p\",{\"1\":{\"57\":1}}],[\"并且其资源消耗极低\",{\"1\":{\"55\":1}}],[\"并且做了以下修改\",{\"1\":{\"54\":1}}],[\"并且相对transformer来说\",{\"1\":{\"45\":1}}],[\"并且和transformer有关\",{\"1\":{\"44\":1}}],[\"并且不需要用户查看模型结构\",{\"1\":{\"36\":1}}],[\"并且它支持用于保护api的自动扩展功能\",{\"1\":{\"33\":1}}],[\"并且每个小批量采取一个梯度步骤\",{\"1\":{\"14\":1}}],[\"并且总是从每个新rlhf版本的基本模型开始\",{\"1\":{\"14\":1}}],[\"并且采用了分组查询注意力\",{\"1\":{\"1\":1}}],[\"并随着比较对变得更加相似而逐渐退化\",{\"1\":{\"13\":1}}],[\"并强制选择的响应比对应的响应具有更高的分数\",{\"1\":{\"13\":1}}],[\"并改变温度超参数\",{\"1\":{\"12\":1}}],[\"并从用户提示中消除令牌的损失\",{\"1\":{\"10\":1}}],[\"并使用自然语言提示来查询语言模型\",{\"1\":{\"56\":1}}],[\"并使用户能够通过监控和可解释性分析进行检查\",{\"1\":{\"36\":1}}],[\"并使用字节分解未知的utf\",{\"1\":{\"7\":1}}],[\"并使用分组查询注意力\",{\"1\":{\"2\":1}}],[\"归一化\",{\"1\":{\"2\":1,\"4\":1}}],[\"优化的自回归transformer\",{\"1\":{\"2\":1}}],[\"本文对t5模型的介绍就到这里\",{\"1\":{\"49\":1}}],[\"本文介绍llama\",{\"1\":{\"1\":2}}],[\"本篇文章将回到最初的gpt\",{\"1\":{\"50\":1}}],[\"本篇文章将顺着现代自然语言处理方法和模型的脉络\",{\"1\":{\"38\":1}}],[\"本篇文章中将简单对其进行介绍\",{\"1\":{\"48\":1}}],[\"本篇文章会对上述模型和技术进行简要介绍\",{\"1\":{\"39\":1}}],[\"本篇文章选择了清华大学的p\",{\"1\":{\"39\":1}}],[\"本篇文章对t5和gpt进行简要介绍\",{\"1\":{\"38\":1}}],[\"本篇文章对现代语言模型的学习的全过程\",{\"1\":{\"38\":1}}],[\"本篇笔记对其内容进行简要记录\",{\"1\":{\"0\":1}}],[\"本地托管的编排引擎和api服务器\",{\"1\":{\"28\":1}}],[\"本身没有任何功能\",{\"1\":{\"22\":1}}],[\"本节报告了使用监督微调以及初始和迭代奖励建模和rlhf进行的实验和发现\",{\"1\":{\"9\":1}}],[\"在函数里修改输入数组对于调用者是可见的\",{\"1\":{\"84\":1,\"85\":1}}],[\"在添加成功后给binder回调即可\",{\"1\":{\"80\":1}}],[\"在添加完自定义服务后\",{\"1\":{\"80\":1}}],[\"在创建完displaydevice后\",{\"1\":{\"80\":1}}],[\"在linux\",{\"1\":{\"80\":1}}],[\"在此我们会发现\",{\"1\":{\"80\":1}}],[\"在android中\",{\"1\":{\"80\":1}}],[\"在apple芯片上微调glm模型\",{\"0\":{\"59\":1}}],[\"在新设备上安装了android\",{\"1\":{\"77\":1}}],[\"在继承链中对象方法的调用存在一个优先级\",{\"1\":{\"76\":1}}],[\"在运行时\",{\"1\":{\"75\":1}}],[\"在运行时谈不上多态\",{\"1\":{\"73\":1}}],[\"在接口的多态中\",{\"1\":{\"75\":1}}],[\"在java中\",{\"1\":{\"75\":1}}],[\"在调用方面\",{\"1\":{\"89\":1}}],[\"在调用android\",{\"1\":{\"80\":1}}],[\"在调用这些方法时就会调用子类的方法\",{\"1\":{\"74\":1}}],[\"在调用该些方法的时候\",{\"1\":{\"73\":1}}],[\"在训练过程中\",{\"1\":{\"62\":1,\"66\":1}}],[\"在330m到10b参数规模的语言模型上\",{\"1\":{\"57\":1}}],[\"在文本序列中采样的文本域为\",{\"1\":{\"52\":1}}],[\"在图5\",{\"1\":{\"52\":2}}],[\"在图8中\",{\"1\":{\"14\":1}}],[\"在其中采用多个文本域\",{\"1\":{\"52\":1}}],[\"在现在看\",{\"1\":{\"51\":1}}],[\"在现在看来\",{\"1\":{\"44\":1}}],[\"在groupnorm中乘一个标量不会影响输出和反向梯度\",{\"1\":{\"65\":1}}],[\"在glm之前\",{\"1\":{\"51\":1}}],[\"在gpt中\",{\"1\":{\"50\":1}}],[\"在国内\",{\"1\":{\"51\":1}}],[\"在t5模型中\",{\"1\":{\"49\":1}}],[\"在transformer的介绍中我们提到过\",{\"1\":{\"45\":1}}],[\"在transformer中\",{\"1\":{\"42\":1,\"43\":1,\"45\":2,\"53\":1}}],[\"在transformer之前\",{\"1\":{\"41\":1}}],[\"在实验中\",{\"1\":{\"47\":1}}],[\"在bert中\",{\"1\":{\"45\":3,\"52\":2,\"53\":1}}],[\"在解码阶段\",{\"1\":{\"43\":1}}],[\"在2\",{\"1\":{\"43\":1}}],[\"在多态中需要将子类的引用赋给父类对象\",{\"1\":{\"74\":1}}],[\"在多态中必须存在有继承关系的子类和父类\",{\"1\":{\"74\":1}}],[\"在多头注意力机制和前馈网络完成后\",{\"1\":{\"43\":1}}],[\"在多个公开可获得数据上进行训练\",{\"1\":{\"1\":1}}],[\"在自注意力机制中\",{\"1\":{\"42\":1}}],[\"在注意力机制中\",{\"1\":{\"42\":1}}],[\"在介绍transformer之前\",{\"1\":{\"41\":1}}],[\"在如此大的规模下\",{\"1\":{\"39\":1}}],[\"在当年属于标准大小\",{\"1\":{\"39\":1}}],[\"在chatgpt大火之后\",{\"1\":{\"39\":1}}],[\"在p\",{\"1\":{\"57\":1}}],[\"在prefix部分\",{\"1\":{\"57\":1}}],[\"在pachyderm中\",{\"1\":{\"30\":1}}],[\"在ppo中\",{\"1\":{\"14\":1}}],[\"在https\",{\"1\":{\"25\":1,\"35\":1}}],[\"在我们的提示集上\",{\"1\":{\"18\":1}}],[\"在对话的大部分时间里保持了对系统消息的大量注意力激活\",{\"1\":{\"15\":1}}],[\"在对话设置中\",{\"1\":{\"15\":1}}],[\"在为训练数据构建最终系统消息时\",{\"1\":{\"15\":1}}],[\"在初始版本的rlhf模型中\",{\"1\":{\"15\":1}}],[\"在有限的计算预算下\",{\"1\":{\"14\":1}}],[\"在迭代模型更新过程中\",{\"1\":{\"14\":1}}],[\"在不同温度下的最大回报曲线\",{\"1\":{\"14\":1}}],[\"在每个块中\",{\"1\":{\"64\":1}}],[\"在每个迭代过程\",{\"1\":{\"14\":1}}],[\"在每一batch用于奖励建模的人类偏好注释上\",{\"1\":{\"13\":1}}],[\"在应用类似于sft的微调之前\",{\"1\":{\"14\":1}}],[\"在拒绝采样微调中\",{\"1\":{\"14\":1}}],[\"在拒绝采样中\",{\"1\":{\"14\":1}}],[\"在步骤t的训练期间\",{\"1\":{\"14\":1}}],[\"在这组评估中\",{\"1\":{\"17\":1}}],[\"在这里也可以看出\",{\"1\":{\"52\":1}}],[\"在这里你可以\",{\"1\":{\"23\":1}}],[\"在这里\",{\"1\":{\"14\":1,\"43\":1}}],[\"在这种二元排名损失的基础上\",{\"1\":{\"13\":1}}],[\"在更明显的反应上\",{\"1\":{\"13\":1}}],[\"在早期的实验中\",{\"1\":{\"13\":1}}],[\"在第3节\",{\"1\":{\"1\":1}}],[\"在第2节\",{\"1\":{\"1\":1}}],[\"机制\",{\"1\":{\"1\":1}}],[\"介绍\",{\"0\":{\"1\":1,\"62\":1,\"86\":1}}],[\"150\",{\"0\":{\"94\":1}}],[\"14\",{\"1\":{\"78\":1}}],[\"140\",{\"1\":{\"58\":1}}],[\"1​​\",{\"1\":{\"63\":1}}],[\"1~\",{\"1\":{\"52\":1}}],[\"130b进行全参数微调\",{\"1\":{\"55\":1,\"57\":1}}],[\"13\",{\"1\":{\"51\":1,\"58\":1}}],[\"13b\",{\"1\":{\"1\":1}}],[\"1750亿\",{\"1\":{\"50\":1}}],[\"16\",{\"1\":{\"45\":1}}],[\"161641400\",{\"1\":{\"23\":1}}],[\"12=600个参数需要微调\",{\"1\":{\"57\":1}}],[\"12\",{\"1\":{\"45\":2,\"51\":1,\"58\":1}}],[\"119\",{\"1\":{\"58\":1}}],[\"11\",{\"1\":{\"41\":1,\"58\":1}}],[\"1公开\",{\"1\":{\"39\":1}}],[\"10<sup>9<\",{\"1\":{\"81\":2,\"87\":2}}],[\"10<sup>4<\",{\"1\":{\"81\":1,\"83\":3,\"85\":3}}],[\"10385\",{\"1\":{\"58\":1}}],[\"10360\",{\"1\":{\"58\":1}}],[\"1024\",{\"1\":{\"45\":1}}],[\"1024行\",{\"1\":{\"13\":1}}],[\"10\",{\"0\":{\"35\":1},\"1\":{\"39\":1,\"47\":2,\"52\":1,\"55\":1,\"58\":1,\"78\":2}}],[\"100\",{\"1\":{\"14\":1,\"84\":2}}],[\"1节所示\",{\"1\":{\"13\":1}}],[\"1一致\",{\"1\":{\"10\":1}}],[\"1一样\",{\"1\":{\"7\":1}}],[\"1相同的标记器\",{\"1\":{\"7\":1}}],[\"1差异\",{\"1\":{\"4\":1}}],[\"1基本一致\",{\"1\":{\"4\":1}}],[\"1论文链接\",{\"1\":{\"2\":1}}],[\"1的权重衰减\",{\"1\":{\"14\":1}}],[\"1的权重衰减和1\",{\"1\":{\"6\":1}}],[\"1的变化内容介绍\",{\"0\":{\"5\":1}}],[\"1的训练方法\",{\"1\":{\"2\":1}}],[\"1的升级版本\",{\"1\":{\"1\":1}}],[\"1\",{\"0\":{\"1\":1,\"3\":1,\"5\":1,\"10\":1,\"12\":1,\"17\":1,\"20\":1,\"26\":1,\"36\":1,\"37\":1,\"41\":1,\"45\":1,\"49\":1,\"52\":1,\"56\":1,\"62\":1,\"64\":1,\"86\":1},\"1\":{\"1\":1,\"10\":1,\"14\":5,\"38\":1,\"41\":2,\"43\":1,\"45\":3,\"49\":1,\"52\":4,\"53\":1,\"54\":1,\"57\":5,\"58\":2,\"61\":1,\"62\":2,\"63\":1,\"64\":6,\"65\":1,\"66\":1,\"76\":1,\"80\":1,\"81\":6,\"82\":1,\"83\":11,\"84\":5,\"85\":18,\"87\":16,\"89\":6}}],[\"论文链接\",{\"1\":{\"0\":1,\"14\":1}}],[\"论文笔记\",{\"0\":{\"0\":1,\"61\":1}}],[\"2位置即可\",{\"1\":{\"82\":1}}],[\"2106\",{\"1\":{\"58\":1}}],[\"2101\",{\"1\":{\"58\":1}}],[\"2103\",{\"1\":{\"58\":2}}],[\"21\",{\"1\":{\"58\":2}}],[\"2表示被masked的词在partb中的位置\",{\"1\":{\"53\":1}}],[\"24\",{\"1\":{\"45\":1}}],[\"2节中\",{\"1\":{\"43\":1}}],[\"2公开\",{\"1\":{\"39\":1}}],[\"200\",{\"1\":{\"87\":2}}],[\"2000\",{\"1\":{\"6\":1}}],[\"20\",{\"1\":{\"58\":1}}],[\"2023\",{\"1\":{\"78\":1}}],[\"2022\",{\"1\":{\"58\":1}}],[\"2022年底\",{\"1\":{\"38\":1}}],[\"2021\",{\"1\":{\"58\":5}}],[\"2021年\",{\"1\":{\"39\":1}}],[\"2020\",{\"1\":{\"58\":4}}],[\"2016\",{\"1\":{\"58\":1}}],[\"2018a\",{\"1\":{\"58\":1}}],[\"2018年\",{\"1\":{\"39\":2}}],[\"2019\",{\"1\":{\"58\":3}}],[\"2019年\",{\"1\":{\"39\":2}}],[\"2017\",{\"1\":{\"58\":1}}],[\"28\",{\"1\":{\"13\":1}}],[\"27\",{\"1\":{\"13\":1,\"78\":1}}],[\"2微调而来\",{\"1\":{\"9\":1}}],[\"2选择使用gqa而不是mqa\",{\"1\":{\"5\":1}}],[\"2模型\",{\"1\":{\"5\":1}}],[\"2万亿\",{\"1\":{\"2\":1}}],[\"2t\",{\"1\":{\"2\":1}}],[\"2的ppo剪辑阈值\",{\"1\":{\"14\":1}}],[\"2的训练数据来自混合后的公开数据\",{\"1\":{\"3\":1}}],[\"2的推理可扩展性\",{\"1\":{\"2\":1}}],[\"2的预训练特性如下\",{\"1\":{\"2\":1}}],[\"2的预训练方法\",{\"1\":{\"1\":1}}],[\"2的预训练和微调过程\",{\"1\":{\"0\":1}}],[\"2执行了更稳健的数据清理\",{\"1\":{\"2\":1}}],[\"2基本还是采用llama\",{\"1\":{\"2\":1}}],[\"2预训练模型微调得来的\",{\"1\":{\"1\":1}}],[\"2预训练的语料库增加了40\",{\"1\":{\"1\":1}}],[\"2和基于它的微调模型llama\",{\"1\":{\"1\":1}}],[\"2共包括两大版本\",{\"1\":{\"1\":1}}],[\"2\",{\"0\":{\"0\":1,\"2\":1,\"3\":1,\"4\":2,\"5\":1,\"8\":1,\"11\":1,\"12\":1,\"13\":2,\"14\":1,\"18\":1,\"20\":1,\"21\":2,\"22\":1,\"23\":1,\"24\":1,\"25\":1,\"27\":1,\"41\":1,\"42\":2,\"43\":1,\"46\":1,\"50\":1,\"53\":1,\"57\":1,\"63\":1,\"64\":1,\"65\":2,\"66\":1,\"84\":1},\"1\":{\"1\":4,\"2\":1,\"9\":1,\"13\":6,\"14\":5,\"15\":3,\"17\":4,\"18\":7,\"38\":1,\"42\":2,\"43\":1,\"45\":1,\"46\":1,\"50\":2,\"51\":1,\"52\":2,\"53\":1,\"54\":1,\"57\":4,\"58\":2,\"64\":1,\"76\":1,\"80\":1,\"81\":8,\"83\":10,\"84\":17,\"85\":10,\"87\":9,\"89\":1}}]],\"serializationVersion\":2}";